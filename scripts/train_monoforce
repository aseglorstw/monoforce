#!/usr/bin/env python

import os
import numpy as np
from datetime import datetime
import torch
from torch.utils.data import DataLoader, ConcatDataset
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import matplotlib.pyplot as plt
from monoforce.datasets import MonoDemDataset, seq_paths
from monoforce.config import Config
from monoforce.models import monolayout, Geom2Trav
from monoforce.utils import normalize
from argparse import ArgumentParser


def str2bool(v):
    return v.lower() in ('1', 'yes', 'true', 't', 'y')

def parse_args():
    parser = ArgumentParser(description='Train Monolayout')
    parser.add_argument('--train_mode', type=str,
                        default='regularization', choices=['sequential', 'regularization'],
                        help='Training mode:'
                             '- sequential (Monolayout(img)->HM_geom, Geom2Trav(HM_geom)->HM_trav),'
                             '- or regularization: Monolayout(img)->HM: loss_reg(HM, HM_geom) + loss_trav(HM, HM_trav)')
    parser.add_argument('--visualize', type=str2bool, default=False)
    parser.add_argument('--save', type=str2bool, default=True)
    parser.add_argument('--batch_size', type=int, default=16)
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--n_epochs', type=int, default=500)
    parser.add_argument('--img_size', type=int, default=512,
                        help='Input image size')
    parser.add_argument('--cost_trav', type=float, default=1.,
                        help='Cost for traversed height loss (for regularization mode only)')
    parser.add_argument('--cost_reg', type=float, default=0.2,
                        help='Cost for regularization loss (for regularization mode only)')
    parser.add_argument('--weighted_loss', type=str2bool, default=False,
                        help='Use weighted MSE loss between height maps')
    parser.add_argument('--pretrained_paths', type=str, nargs='+', default=None,
                        help='Paths to pretrained weights for models: encoder, decoder, geom2trav')
    parser.add_argument('--random_camera_selection_prob', type=float, default=0.2,
                        help='Probability of random camera selection')
    return parser.parse_args()


class Trainer(object):
    def __init__(self, train_ds_paths, val_ds_path, img_size=(512, 512),
                 batch_size=1, lr=1e-3,
                 cost_trav=1., cost_reg=0., weighted_loss=False,
                 pretrained_model_paths=None,
                 train_mode='sequential',  # 'sequential' or 'regularization'
                 vis=False, save=True):
        self.cost_trav = cost_trav
        self.cost_reg = cost_reg
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.img_size = img_size
        self.train_mode = train_mode
        self.train_ds_paths = train_ds_paths
        self.val_ds_path = val_ds_path
        self.train_ds, self.val_ds = self.create_datasets(train_ds_paths, val_ds_path)
        self.train_dataloader = DataLoader(self.train_ds, batch_size=batch_size, shuffle=True)
        self.val_dataloader = DataLoader(self.val_ds, batch_size=batch_size, shuffle=False)

        # models
        self.models = self.init_models(pretrained_paths=pretrained_model_paths)

        # optimizer
        self.parameters_to_train = []
        for key in self.models.keys():
            self.models[key].to(self.device)
            self.parameters_to_train += list(self.models[key].parameters())
        self.optimizer = torch.optim.Adam(params=self.parameters_to_train, lr=lr)

        self.weighted_loss = weighted_loss
        if self.weighted_loss:
            # no loss reduction to apply weights first: https://discuss.pytorch.org/t/how-to-weight-the-loss/66372/2
            self.loss_fn = torch.nn.MSELoss(reduction='none')
        else:
            self.loss_fn = torch.nn.MSELoss(reduction='mean')
        self.min_val_loss = np.inf
        self.min_train_loss = np.inf

        self.vis = vis
        self.save = save

        # logging: tensorboard and weights
        path = os.path.dirname(os.path.realpath(__file__))
        train_label = ('%s_mode_%s_travcost_%.1f_regcost_%.1f_weightedloss_%s_lr_%f' %
                       (datetime.now().strftime("%Y_%m_%d-%H:%M:%S"), train_mode,
                        cost_trav, cost_reg, weighted_loss, lr))
        self.writer = SummaryWriter(log_dir=os.path.join(path, '../config/tb_runs/monolayout/%s/' % train_label))
        self.weights_dir_path = os.path.join(path, '../config/weights/monolayout/%s/' % train_label)

    def init_models(self, pretrained_paths=None):
        assert isinstance(pretrained_paths, dict) or pretrained_paths is None
        models = {}
        # MonoLayout encoder and decoder
        models["encoder"] = monolayout.Encoder(num_layers=18, img_ht=self.img_size[0], img_wt=self.img_size[1], pretrained=True)
        models["decoder"] = monolayout.Decoder(models["encoder"].resnet_encoder.num_ch_enc)
        # Geom2Trav
        if self.train_mode == 'sequential':
            models["geom2trav"] = Geom2Trav()

        if pretrained_paths is not None:
            assert "encoder" in pretrained_paths.keys() and "decoder" in pretrained_paths.keys()
            print('Loading pretrained weights for encoder and decoder from:\n%s...' % pretrained_paths)

            encoder_dict = torch.load(pretrained_paths["encoder"], map_location=self.device)
            filtered_dict_enc = {k: v for k, v in encoder_dict.items() if k in models["encoder"].state_dict()}
            models["encoder"].load_state_dict(filtered_dict_enc)
            models["decoder"].load_state_dict(torch.load(pretrained_paths["decoder"], map_location=self.device))
            if self.train_mode == 'sequential':
                assert "geom2trav" in pretrained_paths.keys()
                print('Loading pretrained weights for geom2trav from:\n%s...' % pretrained_paths["geom2trav"])
                models["geom2trav"].load_state_dict(torch.load(pretrained_paths["geom2trav"], map_location=self.device))

        for key in models.keys():
            models[key].train()
            models[key].to(self.device)

        return models

    def create_datasets(self, train_paths, val_path,
                        random_camera_selection_prob=0.2, hm_interp_method='nearest', debug=False):
        # create dataset for MonoLayout training
        datasets = []
        print('Train paths:', train_paths)
        print('Val path:', val_path)
        for path in train_paths:
            assert os.path.exists(path)

            cfg_train = Config()
            cfg_train.from_yaml(os.path.join(path, 'terrain', 'train_log', 'cfg.yaml'))
            cfg_train.hm_interp_method = hm_interp_method

            # create dataset for MonoDEM training
            train_ds = MonoDemDataset(path, img_size=self.img_size, is_train=True,
                                      random_camera_selection_prob=random_camera_selection_prob, cfg=cfg_train)
            # print('Dataset size:', len(train_ds))
            # if args.visualize:
            #     # visualize a data sample from the dataset
            #     for _ in range(1):
            #         i = np.random.choice(len(train_ds))
            #         train_ds.__getitem__(i, visualize=True)

            datasets.append(train_ds)
        train_ds = ConcatDataset(datasets)

        # create validation dataset
        cfg_val = Config()
        cfg_val.from_yaml(os.path.join(val_path, 'terrain', 'train_log', 'cfg.yaml'))
        cfg_val.hm_interp_method = hm_interp_method
        val_ds = MonoDemDataset(val_path, img_size=self.img_size, is_train=False, cfg=cfg_val)

        if debug:
            print('Debug mode: using small datasets')
            train_ds = torch.utils.data.Subset(train_ds, np.random.choice(len(train_ds), 32, replace=False))
            val_ds = torch.utils.data.Subset(val_ds, np.random.choice(len(val_ds), 16, replace=False))
        print('Training dataset size:', len(train_ds))
        print('Validation dataset size:', len(val_ds))

        return train_ds, val_ds

    def visualize(self, img, height_trav, height_geom, weights_trav, weights_geom, height_pred):
        plt.figure(figsize=(20, 5))
        plt.subplot(1, 5, 1)
        plt.title('Input Image')
        img_vis = img[0].detach().cpu().numpy().transpose((1, 2, 0))
        # img_vis = self.val_ds.destandardize_img(img_vis)
        plt.imshow(img_vis)

        plt.subplot(1, 5, 2)
        plt.title('Height Traversed')
        plt.imshow(height_trav[0].detach().squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()
        plt.imshow(weights_trav[0].detach().squeeze().cpu().numpy(), alpha=0.5, cmap='jet')

        plt.subplot(1, 5, 3)
        plt.title('Height Geom (from Lidar)')
        plt.imshow(height_geom[0].detach().squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()

        plt.subplot(1, 5, 4)
        plt.title('Weights Geom')
        plt.imshow(weights_geom[0].detach().squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()

        plt.subplot(1, 5, 5)
        plt.title('Height Prediction')
        plt.imshow(height_pred[0].detach().squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()

        plt.show()

    def epoch(self, dataloader, epoch_n, mode='train'):
        if self.train_mode == 'regularization':
            loss_ds, cash = self.epoch_regularization(dataloader, epoch_n, mode=mode)
        else:
            assert self.train_mode == 'sequential'
            loss_ds, cash = self.epoch_sequential(dataloader, epoch_n, mode=mode)
        # unpack cash
        img, height_trav, height_geom, weights_trav, weights_geom, height_pred = cash

        # visualize
        if self.vis:
            self.visualize(img, height_trav, height_geom, weights_trav, weights_geom, height_pred)

            # add input image to tensorboard logger
            self.writer.add_images(f'Input Image ({mode})', img, 0)
            # add predictions to tensorboard logger
            self.writer.add_images(f'Height Traversed ({mode})', normalize(height_trav), 0)
            self.writer.add_images(f'Height Predicted ({mode})', normalize(height_pred), 0)
            self.writer.add_images(f'Height Geom ({mode})', normalize(height_geom), 0)
            self.writer.add_images(f'Weights Traversed ({mode})', weights_trav, 0)
            self.writer.add_images(f'Weights Geom ({mode})', weights_geom, 0)

        return loss_ds

    def epoch_regularization(self, dataloader, epoch_n, mode='train'):
        assert mode in ['train', 'val']

        loss_ds = torch.as_tensor(0.0, device=self.device)
        img, height_trav, height_geom, weights_trav, weights_geom, height_pred = None, None, None, None, None, None
        for i, batch in tqdm(enumerate(dataloader)):
            # get sample from data loader (front image, height map label and height map regularization)
            img, height_trav, height_geom, weights_trav, weights_geom = batch
            img = img.to(self.device)
            height_trav = height_trav.to(self.device)
            height_geom = height_geom.to(self.device)
            weights_trav = weights_trav.to(self.device)
            weights_geom = weights_geom.to(self.device)

            # model inference
            features = self.models['encoder'](img)
            height_pred = self.models['decoder'](features, is_training=True)

            # loss is computed for the part of the predicted height map covered by robot's trajectory
            loss = torch.as_tensor(0.0, device=self.device)
            if self.cost_trav > 0.:
                # handle NaN values in height_trav
                if torch.any(torch.isnan(height_trav)):
                    print('Warning: NaN values in height TRAV (corrupted label)!')
                    valid_mask = ~torch.isnan(height_trav)
                    height_trav = height_trav[valid_mask]
                    weights_trav = weights_trav[valid_mask]
                    loss_trav = self.loss_fn(height_pred[valid_mask][weights_trav], height_trav[weights_trav])
                else:
                    loss_trav = self.loss_fn(height_pred[weights_trav], height_trav[weights_trav])

                # reduce loss if custom weights are used to height map loss computation
                if self.weighted_loss:
                    loss_trav = loss_trav.mean()

                loss += self.cost_trav * loss_trav
                # print('Loss trav: %f' % loss_trav.item())
                self.writer.add_scalar('Loss_trav(iter)/%s' % mode, loss_trav.item(), i + epoch_n * len(dataloader))

            # add regularization loss
            if self.cost_reg > 0.:
                if self.weighted_loss:
                    loss_reg = self.loss_fn(height_pred, height_geom)
                    loss_reg = loss_reg * weights_geom
                    loss_reg = loss_reg.sum() / (weights_geom.sum() + 1e-6)
                else:
                    loss_reg = self.loss_fn(height_pred, height_geom)
                loss += self.cost_reg * loss_reg
                # print('Loss reg: %f' % loss_reg.item())
                self.writer.add_scalar('Loss_reg(iter)/%s' % mode, loss_reg.item(), i + epoch_n * len(dataloader))

            # add total dataset loss
            loss_ds += loss

            if mode == 'train':
                # backpropagate gradients and update model params
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

        loss_ds /= len(dataloader)
        cash = (img, height_trav, height_geom, weights_trav, weights_geom, height_pred)

        return loss_ds, cash

    def epoch_sequential(self, dataloader, epoch_n, mode='train'):
        assert mode in ['train', 'val']

        loss_ds = torch.as_tensor(0.0, device=self.device)
        img, height_trav, height_geom, weights_trav, weights_geom, height_pred = None, None, None, None, None, None
        for i, batch in tqdm(enumerate(dataloader)):
            # get sample from data loader (front image, height map label and height map regularization)
            img, height_trav, height_geom, weights_trav, weights_geom = batch
            img = img.to(self.device)
            height_trav = height_trav.to(self.device)
            height_geom = height_geom.to(self.device)
            weights_trav = weights_trav.to(self.device)
            weights_geom = weights_geom.to(self.device)

            # model inference
            features = self.models['encoder'](img)
            height_pred_geom = self.models['decoder'](features, is_training=True)

            # loss between MonoLayout prediction and height map estimated from point cloud
            if self.weighted_loss:
                loss_geom = self.loss_fn(height_pred_geom, height_geom)
                loss_geom = loss_geom * weights_geom
                loss_geom = loss_geom.sum() / (weights_geom.sum() + 1e-6)
            else:
                loss_geom = self.loss_fn(height_pred_geom, height_geom)
            # print('Loss geom: %f' % loss_geom.item())
            self.writer.add_scalar('Loss_geom(iter)/%s' % mode, loss_geom.item(), i + epoch_n * len(dataloader))

            # loss is computed for the part of the predicted height map covered by robot's trajectory
            height_pred_trav = self.models['geom2trav'](height_pred_geom)
            height_pred = height_pred_trav

            # hadnle NaN values in height_trav
            if torch.any(torch.isnan(height_trav)):
                print('Warning: NaN values in height TRAV (corrupted label)!')
                valid_mask = ~torch.isnan(height_trav)
                height_trav = height_trav[valid_mask]
                weights_trav = weights_trav[valid_mask]
                loss_trav = self.loss_fn(height_pred[valid_mask][weights_trav], height_trav[weights_trav])
            else:
                loss_trav = self.loss_fn(height_pred[weights_trav], height_trav[weights_trav])

            # reduce loss if custom weights are used to height map loss computation
            if self.weighted_loss:
                loss_trav = loss_trav.mean()
            # print('Loss trav: %f' % loss_trav.item())
            self.writer.add_scalar('Loss_trav(iter)/%s' % mode, loss_trav.item(), i + epoch_n * len(dataloader))

            # add total dataset loss
            loss = loss_trav + loss_geom
            loss_ds += loss

            if mode == 'train':
                # backpropagate gradients and update model params
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

        loss_ds /= len(dataloader)
        cash = (img, height_trav, height_geom, weights_trav, weights_geom, height_pred)

        return loss_ds, cash

    def train(self, n_epochs=1):
        for e in range(n_epochs):
            print('Training epoch %i...' % e)
            train_loss = self.epoch(dataloader=self.train_dataloader, epoch_n=e, mode='train')
            print('Validation epoch %i...' % e)
            with torch.no_grad():
                val_loss = self.epoch(dataloader=self.val_dataloader, epoch_n=e, mode='val')
            print('Train loss: %f' % train_loss.item())
            print('Val loss: %f' % val_loss.item())

            # log losses on the same plot
            self.writer.add_scalars('Loss(epoch)', {'train': train_loss.item(), 'val': val_loss.item()}, e)

            if self.save:
                # save better model
                if self.min_val_loss > val_loss:
                    self.min_val_loss = val_loss
                    print('Saving better val model...')
                    for key in self.models.keys():
                        os.makedirs(self.weights_dir_path, exist_ok=True)
                        torch.save(self.models[key].state_dict(), os.path.join(self.weights_dir_path, '%s_val.pth' % key))

                if self.min_train_loss > train_loss:
                    self.min_train_loss = train_loss
                    print('Saving better train model...')
                    for key in self.models.keys():
                        os.makedirs(self.weights_dir_path, exist_ok=True)
                        torch.save(self.models[key].state_dict(), os.path.join(self.weights_dir_path, '%s_train.pth' % key))

            # log training results: (write to file)
            with open(os.path.join(self.weights_dir_path, 'train_log.txt'), 'w') as f:
                # val loss
                f.write('Val loss: %f\n' % self.min_val_loss.item())
                # train loss
                f.write('Train loss: %f\n' % self.min_train_loss.item())
                # train mode
                f.write('Train mode: %s\n' % self.train_mode)
                # train dataset paths
                f.write('Train datasets: %s\n' % ', '.join([os.path.basename(p) for p in self.train_ds_paths]))
                # val dataset path
                f.write('Val dataset: %s\n' % os.path.basename(self.val_ds_path))
        else:
            print('Training finished!')

            # close tensorboard logger
            self.writer.close()


def main():
    args = parse_args()
    print(args)

    # pretrained weights paths for MonoDEM (encoder and decoder)
    # pretrained_model_paths = {
    #     "encoder": "../config/weights/monolayout/encoder.pth",
    #     "decoder": "../config/weights/monolayout/decoder.pth",
    #     "geom2trav": "../config/weights/monolayout/geom2trav.pth"
    # }
    pretrained_model_paths = args.pretrained_paths

    train_ds_paths = seq_paths[:-1]
    val_ds_path = seq_paths[-1]

    # MonoDEM Training
    trainer = Trainer(train_ds_paths=train_ds_paths, val_ds_path=val_ds_path,
                      img_size=(args.img_size, args.img_size),
                      batch_size=args.batch_size, lr=args.lr,
                      cost_trav=args.cost_trav, cost_reg=args.cost_reg, weighted_loss=args.weighted_loss,
                      pretrained_model_paths=pretrained_model_paths,
                      train_mode=args.train_mode,
                      vis=args.visualize, save=args.save)
    trainer.train(n_epochs=args.n_epochs)


if __name__ == '__main__':
    main()
