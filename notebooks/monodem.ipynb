{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monoforce.vis import show_cloud\n",
    "from monoforce.utils import normalize, create_model\n",
    "from monoforce.datasets import RobinGasDataset\n",
    "from monoforce.segmentation import position\n",
    "from monoforce.config import Config\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81471e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(RobinGasDataset):\n",
    "    def __init__(self, path, cfg=Config()):\n",
    "        super(Dataset, self).__init__(path, cfg)\n",
    "        self.img_size = (512, 512)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        # point cloud\n",
    "        cloud = self.get_cloud(i)\n",
    "        points = position(cloud)\n",
    "\n",
    "        # height map: estimated from point cloud\n",
    "        heightmap = self.estimate_heightmap(points, self.cfg)\n",
    "        height_est = heightmap['z']\n",
    "        x_grid, y_grid = heightmap['x'], heightmap['y']\n",
    "\n",
    "        # height map: optimized from robot-terrain interaction model\n",
    "        terrain = self.get_optimized_terrain(i)\n",
    "        height_opt = terrain['height']\n",
    "        \n",
    "        # images\n",
    "        img_raw = self.get_image(i)\n",
    "        img_raw = img_raw[..., (2, 1, 0)]  # BGR -> RGB\n",
    "        \n",
    "        # resize image\n",
    "        H_raw, W_raw = img_raw.shape[:2]\n",
    "        h, w = self.img_size\n",
    "        img = cv2.resize(img_raw, (int(h/H_raw * W_raw), h))\n",
    "        # crop image\n",
    "        H, W = img.shape[:2]\n",
    "        img = img[H-h:H, W // 2 - w // 2: W // 2 + w // 2]\n",
    "        \n",
    "        return img, img_raw, height_opt, height_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ruslan/data/robingas/data/22-09-27-unhost/husky/husky_2022-09-27-15-01-44_trav/'\n",
    "# path = '/home/ruslan/data/robingas/data/22-08-12-cimicky_haj/marv/ugv_2022-08-12-15-18-34_trav/'\n",
    "\n",
    "cfg = Config()\n",
    "cfg.from_yaml(os.path.join(path, 'terrain', 'train_log', 'cfg.yaml'))\n",
    "\n",
    "assert os.path.exists(path)\n",
    "ds = Dataset(path, cfg=cfg)\n",
    "\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c16472",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "# i = np.random.choice(range(len(ds)))\n",
    "\n",
    "# trajectory poses\n",
    "poses = ds.get_traj(i)['poses']\n",
    "img, img_raw, height_opt, height_est = ds[i]\n",
    "\n",
    "h_hm, w_hm = height_est.shape\n",
    "xy_grid = poses[:, :2, 3] / cfg.grid_res + np.array([h_hm / 2, w_hm / 2])\n",
    "\n",
    "if img is not None:\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img_raw)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(131)\n",
    "plt.imshow(height_est)\n",
    "plt.plot(xy_grid[:, 0], xy_grid[:, 1], 'rx', markersize=4)\n",
    "plt.subplot(132)\n",
    "plt.imshow(height_opt)\n",
    "plt.plot(xy_grid[:, 0], xy_grid[:, 1], 'rx', markersize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc46938",
   "metadata": {},
   "source": [
    "## Monolayout Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5931b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ruslan/workspaces/traversability_ws/src/thridparty/bev-net/monolayout/')\n",
    "import monolayout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d50cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "H, W = img.shape[:2]\n",
    "models[\"encoder\"] = monolayout.Encoder(num_layers=18, img_ht=H, img_wt=W, pretrained=True)\n",
    "models[\"decoder\"] = monolayout.Decoder(models[\"encoder\"].resnet_encoder.num_ch_enc)\n",
    "# models['discriminator'] = monolayout.Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fe618",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "for key in models.keys():\n",
    "    models[key].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad937310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_vis(tv):\n",
    "    tv_np = tv.squeeze().cpu().numpy()\n",
    "    true_top_view = np.zeros((tv_np.shape[1], tv_np.shape[2]))\n",
    "    true_top_view[tv_np[1] > tv_np[0]] = 255\n",
    "    return true_top_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f370f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # calculate mean and std from the entire dataset\n",
    "    means, stds = [], []\n",
    "    for i in tqdm(range(len(ds))):\n",
    "        img, _, _ = ds[i]\n",
    "        img_01 = img / 255.\n",
    "\n",
    "        mean = img_01.reshape([-1, 3]).mean(axis=0)\n",
    "        std = img_01.reshape([-1, 3]).std(axis=0)\n",
    "\n",
    "        means.append(mean)\n",
    "        stds.append(std)\n",
    "\n",
    "    mean = np.asarray(means).mean(axis=0)\n",
    "    std = np.asarray(stds).mean(axis=0)\n",
    "\n",
    "    print(f'Estimated mean: {mean} \\n and std: {std}')\n",
    "    \n",
    "else:\n",
    "    print('Using precalculated mean and std')\n",
    "    \n",
    "    mean = np.array([0.4750956,  0.47310572, 0.42155158] )\n",
    "    std = np.array([0.2212268,  0.23130926, 0.29598755])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993255b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(img, mean, std):\n",
    "    H, W, C = img.shape\n",
    "    img -= img.min()\n",
    "    img = img / img.max()\n",
    "    img_01 = img\n",
    "    img_01_CHW = img_01.transpose((2, 0, 1))\n",
    "    img_CHW_norm = (img_01_CHW - mean.reshape((C, 1, 1))) / std.reshape((C, 1, 1))\n",
    "    return img_CHW_norm\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(img_3HW_norm.transpose((1, 2, 0)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    img_CHW_norm = normalize_img(img, mean, std)\n",
    "    inp = torch.as_tensor(img_CHW_norm[None], device=device, dtype=torch.float32)\n",
    "    features = models['encoder'](inp)\n",
    "    tv = models['decoder'](features, is_training=False)\n",
    "    \n",
    "    tv_np = tv.squeeze().cpu().numpy()\n",
    "    pred = pred_to_vis(tv)\n",
    "    print(tv.shape, height_est.shape)\n",
    "        \n",
    "plt.figure()\n",
    "plt.imshow(pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
