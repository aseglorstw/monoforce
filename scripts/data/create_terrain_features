#!/usr/bin/env python

import torch
from torch import optim
import numpy as np
from monoforce.models import RigidBodySoftTerrain, State
from monoforce.losses import rotation_difference, translation_difference, total_variation, traj_dist
from monoforce.vis import setup_visualization, animate_trajectory, set_axes_equal
from monoforce.datasets.utils import visualize_data
from monoforce.datasets import DEMPathData
from monoforce.config import Config
from monoforce.control import pose_control
from monoforce.transformations import transform_cloud
from mayavi import mlab
from matplotlib import pyplot as plt
import rospy
import os
from copy import deepcopy
from tqdm import tqdm
from argparse import ArgumentParser


torch.set_default_dtype(torch.float64)

def str2bool(v):
    return v.lower() in ('1', 'yes', 'true', 't', 'y')

def arg_parser():
    parser = ArgumentParser(epilog="""Path format uses following placeholders:
    """)
    parser.add_argument('--control-model', type=str, default='diffdrive')
    parser.add_argument('--visualize', type=str2bool, default=False)
    parser.add_argument('--save-data', type=str2bool, default=True)
    parser.add_argument('--dataset-path', type=str)
    parser.add_argument('--grid-res', type=float, default=0.1)
    parser.add_argument('--d-min', type=float, default=1.)
    parser.add_argument('--d-max', type=float, default=12.8)
    parser.add_argument('--total-sim-time', type=float, default=10.)
    parser.add_argument('--n-samples', type=int, default=1000)
    parser.add_argument('--vel-tracks', type=float, default=2.)
    parser.add_argument('--robot-mass', type=float, default=10.)
    parser.add_argument('--robot-inertia', type=float, default=5.)
    parser.add_argument('--lr', type=float, default=0.01)
    parser.add_argument('--n-train-iters', type=int, default=200)
    parser.add_argument('--device', type=str, default='cpu')
    parser.add_argument('--friction', type=float, default=0.9)
    parser.add_argument('--convergence-std', type=float, default=0.001)
    parser.add_argument('--convergence-n-samples', type=int, default=30)
    return parser


def evaluate(system, states_true, tt, cfg, return_states=False, regularization=True, max_vel=np.inf, max_omega=np.inf):
    state = system.state
    n_true_states = len(states_true[0])
    xyz_true, rot_true = states_true[0], states_true[1]
    dt = (tt[1:] - tt[:-1]).mean()

    loss_trans_sum = torch.tensor(0., device=cfg.device)
    loss_rot_sum = torch.tensor(0., device=cfg.device)
    states = []
    tracks_distance = system.robot_points[1].max() - system.robot_points[1].min()

    for i_s in range(n_true_states - 1):
        # print('Going from pose %s -> to waypoint %s' % (state[0].squeeze(), xyz_true[i_s + 1].squeeze()))
        time_interval = tt[i_s * cfg.n_samples // (n_true_states - 1):(i_s + 1) * cfg.n_samples // (n_true_states - 1)]

        pos_x, pos_R, vel_x, vel_omega, forces = state
        pos_x, pos_R, vel_x, vel_omega, forces = [pos_x], [pos_R], [vel_x], [vel_omega], [forces]
        for t in time_interval[1:]:
            goal_pose = torch.eye(4)
            goal_pose[:3, 3:4] = xyz_true[i_s + 1]
            goal_pose[:3, :3] = rot_true[i_s + 1]

            v, w = pose_control(state, goal_pose, allow_backwards=True,
                                Kp_rho=1.5, Kp_theta=20., Kp_yaw=0.5)

            if cfg.robot_terrain_interaction_model in ['rigid_layer', 'rigid_soft_layers']:
                # two tracks (flippers) robot model
                u1 = v - w * tracks_distance / 4.
                u2 = v + w * tracks_distance / 4.
                system.vel_tracks = torch.clip(torch.tensor([u1, u2]), min=-max_vel, max=max_vel)
            else:
                v = torch.clip(torch.as_tensor(v), -max_vel, max_vel)
                w = torch.clip(torch.as_tensor(w), -max_omega, max_omega)
                state[2][0] = v
                state[3][2] = w

            dstate = system.forward(t, state)
            state = state.update(dstate, dt)

            pos_x.append(state[0])
            pos_R.append(state[1])
            vel_x.append(state[2])
            vel_omega.append(state[3])
            forces.append(state[4])

        states_interval = [torch.stack(pos_x), torch.stack(pos_R), torch.stack(vel_x), torch.stack(vel_omega),
                           torch.stack(forces)]

        # compute loss
        loss_trans = translation_difference(pos_x[-1].view(1, 3, 1), states_true[0][i_s + 1].view(1, 3, 1))
        loss_rot = rotation_difference(pos_R[-1].view(1, 3, 3), states_true[1][i_s + 1].view(1, 3, 3))

        loss_trans_sum += loss_trans
        loss_rot_sum += loss_rot

        states.append(states_interval)

    # concatenate states from all time intervals
    pos_x = torch.cat([x[0] for x in states], dim=0)
    pos_R = torch.cat([x[1] for x in states], dim=0)
    vel_x = torch.cat([x[2] for x in states], dim=0)
    vel_omega = torch.cat([x[3] for x in states], dim=0)
    forces = torch.cat([x[4] for x in states], dim=0)
    states = (pos_x, pos_R, vel_x, vel_omega, forces)

    # compute loss
    # loss_rot_sum /= n_true_states
    # loss_trans_sum /= n_true_states
    # loss = loss_trans_sum + loss_rot_sum

    loss = traj_dist(states, states_true, cfg=cfg)

    if regularization:
        loss += total_variation(system.height[None])

    if return_states:
        return loss, states
    else:
        return loss


def learn_terrain(system, states_true, tt, tt_true, cfg, vis_cfg, vis=False):
    optimizer = optim.Adam([
                            {'params': system.height, 'lr': cfg.lr},
                            {'params': system.friction, 'lr': cfg.lr},
                            {'params': system.elasticity, 'lr': cfg.lr},
                            {'params': system.damping, 'lr': cfg.lr},
                            # {'params': system.vel_tracks, 'lr': cfg.lr},
    ])

    k = 0
    fig = plt.figure(figsize=(10, 10))
    ax1 = plt.subplot(221)
    ax1.set_title('Trajectories loss')
    ax1.grid()
    ax1.set_xlabel('Iterations')
    ax1.set_ylabel('Loss')

    ax2 = plt.subplot(222)
    ax2.set_title('Terrain properties Deltas')
    ax2.grid()
    ax2.set_xlabel('Iterations')
    ax2.set_ylabel('Delta terrain properties')

    losses = []
    system_best = None
    log = {'losses': losses, 'converged': False}

    for i_n in tqdm(range(cfg.n_train_iters), desc='Learning terrain from SLAM trajectory', leave='False'):
        if rospy.is_shutdown():
            break

        optimizer.zero_grad()
        # loss, states = control_loss(system, states_true, tt, cfg, return_states=True)
        loss, states = evaluate(system, states_true, tt, cfg, return_states=True, regularization=True)

        loss.backward()
        optimizer.step()
        print('Iter. %i, loss=%.3f' % (i_n, loss.item()))
        losses.append(loss.item())

        if system_best is None or loss.item() < losses[-2]:
            system.update_trajectory(states=states)
            system_best = deepcopy(system)

        # # if converged: loss history does not change much, break
        # if len(losses) > cfg.convergence_n_samples and np.std(losses[-cfg.convergence_n_samples:]) < cfg.convergence_std:
        #     print('Converged')
        #     log['converged'] = True
        #     break

        if i_n % 10 == 0:
            if vis:
                system.update_trajectory(states=states)
                mlab.title("loss = {:.3f}".format(loss.item()), size=0.5)
                k = animate_trajectory(system, vis_cfg, frame_n=k)

        # visualize loss vs iterations
        ax1.plot(i_n, loss.item(), 'r.')

        # visualize mean terrain properties vs iterations
        if i_n == 0:
            mean_friction0 = system.friction.mean().item()
            mean_elasticity0 = system.elasticity.mean().item()
            mean_damping0 = system.damping.mean().item()
        ax2.plot(i_n, system.friction.mean().item() - mean_friction0, 'g.')
        ax2.plot(i_n, system.elasticity.mean().item() - mean_elasticity0, 'b.')
        ax2.plot(i_n, system.damping.mean().item() - mean_damping0, 'k.')
        ax2.legend(['Friction', 'Elasticity', 'Damping'])
        # ax2.legend(['Friction'])

        # print('Mean terrain properties: height=%.3f, friction=%.3f, elasticity=%.3f, damping=%.3f' %
        #       (system.height.mean().item(), system.friction.mean().item(), system.elasticity.mean().item(),
        #        system.damping.mean().item()))

        if vis:
            plt.pause(0.01)

    ax = plt.subplot(223)
    height = system.height.detach().cpu().numpy()
    ax.set_title('Learned height map')
    ax.imshow(height, cmap='viridis')
    # GT trajectory
    x, y = states_true[0][:, 0], states_true[0][:, 1]
    h, w = height.shape
    x_grid, y_grid = x / cfg.grid_res + w / 2, y / cfg.grid_res + h / 2
    plt.plot(y_grid, x_grid, 'r-', label='Robot GT trajectory')
    # learned trajectory
    x, y = system_best.pos_x[:, 0], system_best.pos_x[:, 1]
    x_grid, y_grid = x / cfg.grid_res + w / 2, y / cfg.grid_res + h / 2
    plt.plot(y_grid, x_grid, 'g-', label='Robot learned trajectory')
    plt.legend()

    # visualize heightmap as a surface in 3D
    x, y = np.meshgrid(np.arange(height.shape[0]), np.arange(height.shape[1]))
    z = height[x, y]
    ax = plt.subplot(224, projection='3d')
    ax.plot_surface(x, y, z, rstride=1, cstride=1, cmap='viridis', edgecolor='none')
    ax.set_title('Learned height map surface')
    set_axes_equal(ax)

    if vis:
        plt.show()
        mlab.show()

    log['losses'] = losses
    log['train_fig'] = fig

    return system_best, log


def save_result(system, output_name, log, cfg):
    # save resultant height map, friction, elasticity, damping as structured np array with corresponding field names
    # save initial height map
    height_init = system.height0.detach().cpu().numpy()
    # save height map
    height = system.height.detach().cpu().numpy()
    # save friction
    friction = system.friction.detach().cpu().numpy()
    # save elasticity
    elasticity = system.elasticity.detach().cpu().numpy()
    # save damping
    damping = system.damping.detach().cpu().numpy()
    # create structured array
    result = np.zeros((height.shape[0], height.shape[1]), dtype=[('height_init', np.float64),
                                                                 ('height', np.float64),
                                                                 ('friction', np.float64),
                                                                 ('elasticity', np.float64),
                                                                 ('damping', np.float64)])
    result['height_init'] = height_init
    result['height'] = height
    result['friction'] = friction
    result['elasticity'] = elasticity
    result['damping'] = damping
    # save terrain properties array to file
    output_path = os.path.join(cfg.dataset_path, 'terrain')
    os.makedirs(output_path, exist_ok=True)
    # output_name = '%s_loss_%.3f_loss0_%.3f_train_iter_%i.npy' % \
    #               (output_name, log['losses'][np.argmin(log['losses'])], log['losses'][0], np.argmin(log['losses']).item())
    output_name = '%s.npy' % output_name
    np.save(os.path.join(output_path, output_name), result)

    # save figure
    train_log_path = os.path.join(output_path, 'train_log')
    os.makedirs(train_log_path, exist_ok=True)
    fig = log['train_fig']
    fig.savefig(os.path.join(train_log_path, output_name.replace('.npy', '.png')))

    # save config in yaml file
    # if not os.path.exists(os.path.join(train_log_path, 'cfg.yaml')):
    cfg.to_yaml(os.path.join(train_log_path, 'cfg.yaml'))

    # # save learned trajectory
    # states = (system.pos_x, system.pos_R, system.vel_x, system.vel_omega, system.forces)
    # states = [x.detach().cpu().numpy() for x in states]
    # states = np.stack(states, axis=1)
    # np.save(os.path.join(train_log_path, output_name.replace('.npy', '_states.npy')), states)

    return result


def train(ds, cfg=Config(), vis=False, save_data=False):

    # shuffle indices list
    ids = np.arange(len(ds))
    for data_i in tqdm(ids, desc='Data samples'):
        print('Selected data sample %i/%i' % (data_i, len(ds)))
        if os.path.exists(os.path.join(ds.path, 'terrain/', ds.ids[data_i]+'.npy')):
            print('Already trained')
            continue
        sample = ds[data_i]
        cloud, traj, heightmap = sample
        height = heightmap['z']
        traj['stamps'] = traj['stamps'] - traj['stamps'][0]
        img = ds.get_image(data_i, camera='front')
        poses = traj['poses']
        t_stamps = traj['stamps']

        # transform point cloud and poses to robot frame
        Tr = np.linalg.inv(poses[0])
        cloud = transform_cloud(cloud, Tr)
        poses = np.asarray([Tr @ pose for pose in poses])

        xyz_true = torch.as_tensor(poses[:, :3, 3])
        rot_true = torch.as_tensor(poses[:, :3, :3])

        N = len(xyz_true)
        tt_true = torch.tensor(t_stamps)[None].T

        dps = torch.diff(xyz_true, dim=0)
        dt = torch.diff(tt_true, dim=0)
        theta_true = torch.atan2(dps[:, 1], dps[:, 0]).view(-1, 1)
        theta_true = torch.cat([theta_true[:1], theta_true], dim=0)

        vel_true = torch.zeros_like(xyz_true)
        vel_true[:-1] = dps / dt
        omega_true = torch.zeros_like(xyz_true)
        omega_true[:-1, 2:3] = torch.diff(theta_true, dim=0) / dt  # + torch.diff(angles_true, dim=0)[:, 2:3] / dt

        n_robot_pts = 10  # TODO: 10 is a hack, 10 is the number of contact points
        forces_true = torch.zeros((N, 3, n_robot_pts))

        states_true = (xyz_true.view(-1, 3, 1),
                       rot_true.view(-1, 3, 3),
                       vel_true.view(-1, 3, 1),
                       omega_true.view(-1, 3, 1),
                       forces_true.view(-1, 3, n_robot_pts))

        if vis:
            img_vis = img[..., (2, 1, 0)] if img is not None else None
            visualize_data(heightmap, traj, img=img_vis, cfg=cfg)

        """ Create robot-terrain interaction models """
        system = RigidBodySoftTerrain(height=np.zeros_like(height) + poses[:, 2, 3].min(),
                                      grid_res=cfg.grid_res,
                                      friction=cfg.friction, mass=cfg.robot_mass,
                                      state=State(xyz=xyz_true[0] + torch.tensor([0., 0., 1.]).view(xyz_true[0].shape),
                                                  rot=rot_true[0],
                                                  vel=vel_true[0],
                                                  omega=omega_true[0],
                                                  forces=forces_true[0]),
                                      device=cfg.device, use_ode=False,
                                      interaction_model=cfg.robot_terrain_interaction_model)

        # put models with their params to device
        system = system.to(cfg.device)

        t0, s0 = 0., system.state
        tt = torch.linspace(float(t0), float(t0) + cfg.total_sim_time, cfg.n_samples)
        states = system.sim(s0, tt)

        vis_cfg = setup_visualization(system=system, states=states, states_true=states_true, cfg=cfg) if vis else None
        # mlab.show()
        """ Train """
        system_opt, log = learn_terrain(system, states_true=states_true,
                                        tt=tt, tt_true=tt_true,
                                        cfg=cfg, vis_cfg=vis_cfg, vis=vis)
        if save_data:
            output_name = '%s' % ds.ids[data_i]
            save_result(system_opt, output_name, log, cfg)


def main():
    args = arg_parser().parse_args()
    print(args)

    cfg = Config()
    # cfg.dataset_path = '/home/ruslan/data/robingas/data/22-08-12-cimicky_haj/marv/ugv_2022-08-12-15-18-34_trav/'
    # cfg.dataset_path = '/home/ruslan/data/robingas/data/22-09-27-unhost/husky/husky_2022-09-27-15-01-44_trav/'
    # cfg.dataset_path = '/mnt/personal/agishrus/data/robingas/data/22-08-12-cimicky_haj/marv/ugv_2022-08-12-15-18-34_trav/'
    # cfg.dataset_path = '/mnt/personal/agishrus/data/robingas/data/22-09-27-unhost/husky/husky_2022-09-27-15-01-44_trav/'
    cfg.dataset_path = args.dataset_path
    cfg.grid_res = args.grid_res
    cfg.d_min = args.d_min  # robot points removal
    cfg.d_max = 12.8  # for Monolayout training
    cfg.total_sim_time = args.total_sim_time
    cfg.n_samples = 100 * int(cfg.total_sim_time)
    cfg.vel_tracks = args.vel_tracks * np.asarray([1., 1.])
    cfg.robot_mass = args.robot_mass
    cfg.robot_inertia = np.eye(3) * args.robot_inertia
    cfg.lr = args.lr
    cfg.n_train_iters = args.n_train_iters
    cfg.device = args.device
    cfg.friction = args.friction
    cfg.convergence_std = args.convergence_std
    cfg.convergence_n_samples = args.convergence_n_samples
    # cfg.robot_terrain_interaction_model = 'rigid_layer'
    # cfg.robot_terrain_interaction_model = 'rigid_soft_layers'
    # cfg.robot_terrain_interaction_model = 'diffdrive'
    cfg.robot_terrain_interaction_model = args.control_model

    ds = DEMPathData(path=cfg.dataset_path, cfg=cfg)
    train(ds, cfg=cfg, vis=args.visualize, save_data=args.save_data)


if __name__ == '__main__':
    main()
