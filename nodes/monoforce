#!/usr/bin/env python

import os
import numpy as np
import torch
import rospy
from numpy.lib.recfunctions import unstructured_to_structured
from monoforce.datasets import RobinGasVis, robingas_tradr_seq_paths, robingas_husky_seq_paths
from monoforce.config import DPhysConfig
from monoforce.models import dphysics
from monoforce.ros import height_map_to_gridmap_msg, to_path, to_tf, xyz_to_point
from monoforce.models.lss.model import compile_model
from nav_msgs.msg import Path
from sensor_msgs.msg import PointCloud2, Image, CameraInfo
from grid_map_msgs.msg import GridMap
from ros_numpy import msgify
from monoforce.utils import read_yaml, position
import rospkg
import tf2_ros
from visualization_msgs.msg import Marker, MarkerArray


class MonoForce:
    def __init__(self, name='monoforce'):
        self.robot = rospy.get_param('~robot', 'husky')
        # choose data sample
        seqs = robingas_husky_seq_paths if self.robot == 'husky' else robingas_tradr_seq_paths
        seq_i = rospy.get_param('~seq_i', np.random.choice(range(len(seqs))))
        self.data_seq = seqs[seq_i]

        self.dphys_cfg = DPhysConfig()
        self.pkg_path = rospkg.RosPack().get_path('monoforce')
        self.dphys_config_path = rospy.get_param('~dphys_config_path',
                                                 os.path.join(self.pkg_path, 'config/dphys_cfg.yaml'))
        assert os.path.isfile(self.dphys_config_path), 'Config file %s does not exist' % self.dphys_config_path
        self.dphys_cfg.from_yaml(self.dphys_config_path)
        self.dphys_cfg.from_rosparams(node_name=name)

        # load LSS config
        self.lss_config_path = rospy.get_param('~lss_config_path',
                                               os.path.join(self.pkg_path, f'config/lss_cfg_{self.robot}.yaml'))
        assert os.path.isfile(self.lss_config_path), 'LSS config file %s does not exist' % self.lss_config_path
        self.lss_config = read_yaml(self.lss_config_path)

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        if self.dphys_cfg.n_samples / self.dphys_cfg.total_sim_time != 100:
            rospy.logwarn('Simulated time and number of predicted trajectory samples'
                          'do not match the default rate of 100 Hz.')
        self.rate = rospy.get_param('~rate', self.dphys_cfg.n_samples / self.dphys_cfg.total_sim_time)
        self.map_frame = rospy.get_param('~map_frame', 'map')
        self.robot_initial_frame = rospy.get_param('~robot_initial_frame', 'base_link0')
        self.robot_frame = rospy.get_param('~robot_frame', 'base_link')
        self.camera_frames = None  # will be set from the data sequence
        self.modelf = rospy.get_param('~lss_weights')
        self.model = self.load_model()

        # publishers
        self.cloud_pub = rospy.Publisher('cloud', PointCloud2, queue_size=1)
        self.path_pub = rospy.Publisher('path', Path, queue_size=1)
        self.path_gt_pub = rospy.Publisher('path_gt', Path, queue_size=1)
        self.img_pubs = None
        self.caminfo_pubs = None
        self.tf_broadcast = tf2_ros.TransformBroadcaster()
        self.forces_pub = rospy.Publisher('forces', MarkerArray, queue_size=1)

    def load_model(self):
        model = compile_model(self.lss_config['grid_conf'], self.lss_config['data_aug_conf'], outC=1)
        rospy.loginfo('Loading model from: %s' % self.modelf)
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.load_state_dict(torch.load(self.modelf, map_location=device))
        model.eval()
        return model

    def publish_cloud(self, points, stamp):
        assert points.ndim == 2, 'Points must be of shape (N, 3)'
        assert points.shape[1] == 3, 'Points must be of shape (N, 3)'
        points = np.asarray(points, dtype='float32')
        cloud_struct = unstructured_to_structured(points, names=['x', 'y', 'z'])
        cloud_msg = msgify(PointCloud2, cloud_struct)
        cloud_msg.header.frame_id = self.robot_initial_frame
        cloud_msg.header.stamp = stamp
        self.cloud_pub.publish(cloud_msg)

    def publish_images(self, imgs, Ks, stamp):
        for cam, img, K, img_pub, K_pub in zip(self.camera_frames, imgs, Ks, self.img_pubs, self.caminfo_pubs):
            # images
            img = np.asarray(img, dtype='uint8')
            img_msg = msgify(Image, img, encoding='rgb8')
            img_msg.header.stamp = stamp
            img_msg.header.frame_id = cam.lower()
            img_pub.publish(img_msg)
            # cameras info
            K_msg = CameraInfo()
            P = np.zeros((3, 4))
            P[:3, :3] = K
            R = np.eye(3)
            K_msg.K = K.flatten().tolist()
            K_msg.P = P.flatten().tolist()
            K_msg.R = R.flatten().tolist()
            K_msg.header.stamp = stamp
            K_msg.header.frame_id = cam.lower()
            K_msg.height = img.shape[0]
            K_msg.width = img.shape[1]
            K_pub.publish(K_msg)

    def publish_gridmap(self, height, stamp, topic, mask=None):
        assert isinstance(height, np.ndarray) or isinstance(height, torch.Tensor)
        assert isinstance(mask, np.ndarray) or isinstance(mask, torch.Tensor) or mask is None
        assert isinstance(stamp, rospy.Time)
        assert isinstance(topic, str)

        if isinstance(height, torch.Tensor):
            height = height.squeeze().cpu().numpy()
        if isinstance(mask, torch.Tensor):
            mask = mask.squeeze().cpu().numpy()
        grid_msg = height_map_to_gridmap_msg(height, grid_res=self.dphys_cfg.grid_res, mask=mask)
        grid_msg.info.header.frame_id = self.robot_initial_frame
        grid_msg.info.header.stamp = stamp
        pub = rospy.Publisher(topic, GridMap, queue_size=1)
        pub.publish(grid_msg)

    def publish_forces(self, robot_forces, robot_points, stamp):
        assert robot_forces.shape == robot_points.shape
        assert robot_forces.shape[0] == 3
        # publish forces as arrows with MarkerArray
        markers = MarkerArray()
        for i in range(robot_forces.shape[1]):
            force = robot_forces[:, i]
            xyz = robot_points[:, i]
            marker = Marker()
            marker.header.frame_id = self.robot_frame
            marker.header.stamp = stamp
            marker.id = i
            marker.type = Marker.ARROW
            marker.action = Marker.ADD
            marker.pose.position.x = xyz[0]
            marker.pose.position.y = xyz[1]
            marker.pose.position.z = xyz[2]
            marker.points.append(xyz_to_point([0, 0, 0]))
            marker.points.append(xyz_to_point(force / self.dphys_cfg.robot_mass / 9.8))
            marker.scale.x = 0.05
            marker.scale.y = 0.10
            marker.scale.z = 0.05
            marker.color.a = 1.0
            marker.color.r = 1.0
            marker.color.g = 0.0
            marker.color.b = 0.0
            markers.markers.append(marker)
        self.forces_pub.publish(markers)

    def poses_from_states(self, states):
        xyz = states[0].cpu().numpy()
        Rs = states[1].cpu().numpy()
        poses = np.stack([np.eye(4) for _ in range(len(xyz))])
        poses[:, :3, :3] = Rs
        poses[:, :3, 3:4] = xyz
        poses[:, 2, 3] += self.dphys_cfg.robot_clearance + 0.1
        # poses inside the heightmap
        mask = (xyz[:, 0] > -self.dphys_cfg.d_max) & (xyz[:, 0] < self.dphys_cfg.d_max) & \
               (xyz[:, 1] > -self.dphys_cfg.d_max) & (xyz[:, 1] < self.dphys_cfg.d_max)
        mask = np.asarray(mask, dtype=bool).flatten()
        poses = poses[mask]
        return poses

    def predict_states(self, height, v, w):
        if isinstance(height, torch.Tensor):
            height = height.squeeze().cpu().numpy()
        with torch.no_grad():
            # constant linear and angular velocities as control inputs
            tt = torch.linspace(0., self.dphys_cfg.total_sim_time, self.dphys_cfg.n_samples)
            vs = v * torch.ones(self.dphys_cfg.n_samples)
            ws = w * torch.ones(self.dphys_cfg.n_samples)
            controls = {'stamps': tt, 'linear_v': vs, 'angular_w': ws}
            states, system = dphysics(height, controls, dphys_cfg=self.dphys_cfg, device=self.device)
        return states, system.robot_points.detach()

    def run(self):
        ds = RobinGasVis(self.data_seq, dphys_cfg=self.dphys_cfg, lss_cfg=self.lss_config, is_train=False)
        rospy.loginfo('Loaded dataset with %d samples from path: %s' % (len(ds), self.data_seq))
        sample_i = rospy.get_param('~sample_i', np.random.choice(range(len(ds))))
        rospy.loginfo('Using sample %d' % sample_i)

        self.camera_frames = ds.cameras
        self.img_pubs = [rospy.Publisher('%s/image' % cam, Image, queue_size=1) for cam in self.camera_frames]
        self.caminfo_pubs = [rospy.Publisher('%s/camera_info' % cam, CameraInfo, queue_size=1) for cam in self.camera_frames]

        imgs, rots, trans, intrins, post_rots, post_trans = ds.get_images_data(sample_i)
        points = position(ds.get_cloud(sample_i))

        traj = ds.get_traj(sample_i)
        poses_gt = traj['poses']

        map_pose = ds.get_pose(sample_i)

        imgs_raw = []
        Ks = []
        for cam in self.camera_frames:
            img_raw, K = ds.get_image(sample_i, cam, undistort=False)
            imgs_raw.append(img_raw)
            Ks.append(K)

        # get heightmap prediction
        with torch.no_grad():
            inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
            inputs = [torch.as_tensor(i[None]) for i in inputs]
            # voxel_feats = self.model.get_voxels(*inputs)
            # height_geom_pred, height_diff_pred = self.model.bevencode(voxel_feats)
            # height_terrain_pred = height_geom_pred - height_diff_pred
            height_terrain_pred = self.model(*inputs)

        rate = rospy.Rate(self.rate)
        pose_i = 0
        poses = None
        forces = None
        robot_points = None
        while not rospy.is_shutdown():
            stamp = rospy.Time.now()

            if pose_i == 0:
                # point cloud
                self.publish_cloud(points, stamp)
                # grid map
                # self.publish_gridmap(hm_geom[0], stamp, topic='grid_map_geom', mask=hm_geom[1])
                # self.publish_gridmap(hm_terrain[0], stamp, topic='grid_map_terrain', mask=hm_terrain[1])
                # self.publish_gridmap(height_geom_pred, stamp, topic='grid_map_geom_pred')
                # self.publish_gridmap(height_diff_pred, stamp, topic='grid_map_diff_pred')
                self.publish_gridmap(height_terrain_pred, stamp, topic='grid_map_terrain_pred')
                # images
                self.publish_images(imgs_raw, Ks, stamp)

                # predict path poses
                v = np.random.uniform(0.4, 0.8)
                if np.random.random() > 0.5:
                    v = -v
                w = np.random.uniform(-0.2, 0.2)
                # v = 0.4
                # w = -0.13
                rospy.loginfo('Predicting path with v=%.3f, w=%.3f' % (v, w))
                states, robot_points = self.predict_states(height_terrain_pred, v=v, w=w)
                # states, robot_points = self.predict_states(hm_terrain[0], v=v, w=w)
                poses = self.poses_from_states(states)
                rospy.loginfo('Predicted poses shape: %s' % str(poses.shape))
                forces = states[4].cpu().numpy()
                rospy.loginfo('Predicted forces shape: %s' % str(forces.shape))
                robot_points = robot_points.cpu().numpy()
                rospy.loginfo('Robot contact points shape: %s' % str(robot_points.shape))
                # publish paths
                path_msg = to_path(poses, frame_id=self.robot_initial_frame, stamp=stamp)
                path_gt_msg = to_path(poses_gt, frame_id=self.robot_initial_frame, stamp=stamp)
                self.path_pub.publish(path_msg)
                self.path_gt_pub.publish(path_gt_msg)

            # robot pose in map frame
            tf = to_tf(map_pose, self.map_frame, self.robot_initial_frame, stamp)
            self.tf_broadcast.sendTransform(tf)
            # camera poses
            for cam, tran, rot in zip(self.camera_frames, trans, rots):
                pose = np.eye(4)
                pose[:3, :3] = rot.numpy()
                pose[:3, 3] = tran.numpy()
                tf = to_tf(pose, self.robot_initial_frame, cam, stamp)
                self.tf_broadcast.sendTransform(tf)

            # robot's current pose
            robot_traj_pose = poses[pose_i]
            assert robot_traj_pose.shape == (4, 4)
            tf = to_tf(robot_traj_pose, self.robot_initial_frame, self.robot_frame, stamp)
            self.tf_broadcast.sendTransform(tf)

            # publish forces
            self.publish_forces(forces[pose_i], robot_points, stamp)

            pose_i = (pose_i + 1) % len(poses)
            rate.sleep()


def main():
    rospy.init_node('monoforce', anonymous=True, log_level=rospy.DEBUG)
    node = MonoForce()
    try:
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo('Shutting down monoforce node')


if __name__ == '__main__':
    main()
