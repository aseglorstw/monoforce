#!/usr/bin/env python

import os
from threading import RLock
import torch
import numpy as np
import rospy
from cv_bridge import CvBridge
from grid_map_msgs.msg import GridMap
from monoforce.cloudproc import estimate_heightmap
from monoforce.config import DPhysConfig
from monoforce.models.lss.model import compile_model
from monoforce.models.lss.utils import img_transform, normalize_img, sample_augmentation, ego_to_cam, \
    get_only_in_img_mask
from monoforce.ros import height_map_to_point_cloud_msg, height_map_to_gridmap_msg
from monoforce.utils import normalize, read_yaml, timing, position
from monoforce.datasets.utils import load_calib
from sensor_msgs.msg import CompressedImage, PointCloud2, CameraInfo
import rospkg
from time import time
from message_filters import ApproximateTimeSynchronizer, Subscriber
import tf2_ros
from PIL import Image as PILImage
from ros_numpy import numpify
import matplotlib.pyplot as plt
import matplotlib as mpl

torch.set_default_dtype(torch.float32)


class LSS:
    def __init__(self, dphys_cfg: DPhysConfig,
                 lss_cfg: dict,
                 weights=None,
                 hm_frame='base_link',
                 img_topics=[],
                 camera_info_topics=[],
                 calib_path='',
                 max_msgs_delay=0.1,
                 max_age=0.2,
                 n_cams=None):
        self.dphys_cfg = dphys_cfg
        self.lss_cfg = lss_cfg
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        self.model = self.load_model(weights)

        self.hm_frame = hm_frame

        self.img_topics = img_topics[:n_cams] if isinstance(n_cams, int) else img_topics
        self.camera_info_topics = camera_info_topics[:n_cams] if isinstance(n_cams, int) else camera_info_topics
        assert len(self.img_topics) == len(self.camera_info_topics)

        self.calib = load_calib(calib_path)
        if self.calib is not None:
            rospy.loginfo('Loaded calibration from %s' % calib_path)

        # cv bridge
        self.cv_bridge = CvBridge()
        # tf listener
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer)
        # grid map publisher
        self.gridmap_pub = rospy.Publisher('/grid_map/terrain', GridMap, queue_size=1)

        # subscribe to camera intrinsics (ones)
        self.proc_lock = RLock()

        self.max_msgs_delay = max_msgs_delay
        self.max_age = max_age

    def start(self):
        # subscribe to images with approximate time synchronization
        self.subs = []
        for topic in self.img_topics:
            rospy.loginfo('Subscribing to %s' % topic)
            self.subs.append(Subscriber(topic, CompressedImage))
        for topic in self.camera_info_topics:
            rospy.loginfo('Subscribing to %s' % topic)
            self.subs.append(Subscriber(topic, CameraInfo))
        self.sync = ApproximateTimeSynchronizer(self.subs, queue_size=1, slop=self.max_msgs_delay)
        self.sync.registerCallback(self.callback)

    def load_model(self, modelf):
        model = compile_model(self.lss_cfg['grid_conf'], self.lss_cfg['data_aug_conf'], outC=1)
        if not os.path.exists(modelf):
            rospy.logerr('Model weights file %s does not exist. Using random weights.' % modelf)
        else:
            rospy.loginfo('Loading LSS model from %s' % modelf)
            model.load_state_dict(torch.load(modelf, map_location=self.device))
        model.to(self.device)
        model.eval()
        return model

    def preprocess_img(self, img):
        post_rot = torch.eye(2)
        post_tran = torch.zeros(2)

        # preprocessing parameters (resize, crop)
        resize, resize_dims, crop, flip, rotate = sample_augmentation(self.lss_cfg, is_train=False)
        img, post_rot2, post_tran2 = img_transform(PILImage.fromarray(img), post_rot, post_tran,
                                                   resize=resize,
                                                   resize_dims=resize_dims,
                                                   crop=crop,
                                                   flip=False,
                                                   rotate=0)
        # normalize image (substraction of mean and division by std)
        img = normalize_img(img)

        # for convenience, make augmentation matrices 3x3
        post_tran = torch.zeros(3, dtype=torch.float32)
        post_rot = torch.eye(3, dtype=torch.float32)
        post_tran[:2] = post_tran2
        post_rot[:2, :2] = post_rot2

        return img, post_rot, post_tran

    def get_cam_calib_from_yaml(self, camera, robot_frame='base_link'):
        """
        Load camera calibration parameters from yaml file.
        :param calib_path: path to yaml file
        :return: E - extrinsics (4x4),
                 K - intrinsics (3x3),
                 D - distortion coefficients (5,)
        """
        assert self.calib is not None

        Tr_robot_cam = self.calib['transformations'][f'T_{robot_frame}__{camera}']['data']
        Tr_robot_cam = np.array(Tr_robot_cam, dtype=np.float32).reshape((4, 4))
        E = Tr_robot_cam
        K = np.array(self.calib[camera]['camera_matrix']['data'], dtype=np.float32).reshape((3, 3))
        D = np.array(self.calib[camera]['distortion_coefficients']['data'], dtype=np.float32)

        return E, K, D

    def get_cam_calib_from_info_msg(self, msg):
        """
        Get camera calibration parameters from CameraInfo message.
        :param msg: CameraInfo message
        :return: E - extrinsics (4x4),
                 K - intrinsics (3x3),
                 D - distortion coefficients (5,)
        """
        assert isinstance(msg, CameraInfo)

        time = rospy.Time(0)
        timeout = rospy.Duration.from_sec(1.0)
        try:
            tf = self.tf_buffer.lookup_transform(self.hm_frame, msg.header.frame_id, time, timeout)
        except Exception as ex:
            rospy.logerr('Could not transform from camera %s to robot %s: %s.',
                         msg.header.frame_id, self.hm_frame, ex)
            raise ex

        E = np.array(numpify(tf.transform), dtype=np.float32).reshape((4, 4))
        K = np.array(msg.K, dtype=np.float32).reshape((3, 3))
        D = np.array(msg.D, dtype=np.float32)

        return E, K, D

    def get_lss_inputs(self, img_msgs, info_msgs):
        """
        Get inputs for LSS model from image and camera info messages.
        """
        assert len(img_msgs) == len(info_msgs)

        imgs = []
        post_rots = []
        post_trans = []
        intriniscs = []
        cams_to_robot = []
        for cam_i, (img_msg, info_msg) in enumerate(zip(img_msgs, info_msgs)):
            assert isinstance(img_msg, CompressedImage)
            assert isinstance(info_msg, CameraInfo)

            img = self.cv_bridge.compressed_imgmsg_to_cv2(img_msg)
            # BGR to RGB
            img = img[..., ::-1]
            if self.calib is not None:
                rospy.logdebug('Using calibration from yaml file')
                cam_name = self.camera_info_topics[cam_i].split('/')[1]
                E, K, D = self.get_cam_calib_from_yaml(cam_name)
            else:
                rospy.logdebug('Using calibration from CameraInfo message')
                E, K, D = self.get_cam_calib_from_info_msg(info_msg)

            img, post_rot, post_tran = self.preprocess_img(img)
            imgs.append(img)
            post_rots.append(post_rot)
            post_trans.append(post_tran)
            intriniscs.append(K)
            cams_to_robot.append(E)

        # to arrays
        imgs = np.stack(imgs)
        post_rots = np.stack(post_rots)
        post_trans = np.stack(post_trans)
        intrins = np.stack(intriniscs)
        cams_to_robot = np.stack(cams_to_robot)
        rots, trans = cams_to_robot[:, :3, :3], cams_to_robot[:, :3, 3]
        rospy.loginfo('Preprocessed image shape: %s' % str(imgs.shape))

        inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
        inputs = [torch.as_tensor(i[np.newaxis], dtype=torch.float32) for i in inputs]

        return inputs

    def callback(self, *msgs):
        rospy.loginfo('Received %d messages' % len(msgs))
        # if message is stale do not process it
        dt = rospy.Time.now() - msgs[0].header.stamp
        if dt.to_sec() > self.max_age:
            rospy.logdebug(
                f'Stale image messages received ({dt.to_sec():.3f} > {self.max_age} [sec]), skipping')
            return

        with torch.no_grad():
            with self.proc_lock:
                self.proc(*msgs)

    def proc(self, *msgs):
        t0 = time()
        n = len(msgs)
        assert n % 2 == 0
        for i in range(n // 2):
            assert isinstance(msgs[i], CompressedImage), 'First %d messages must be CompressedImage' % (n // 2)
            assert isinstance(msgs[i + n // 2], CameraInfo), 'Last %d messages must be CameraInfo' % (n // 2)
            assert msgs[i].header.frame_id == msgs[i + n // 2].header.frame_id, \
                'Image and CameraInfo messages must have the same frame_id'
        img_msgs = msgs[:n // 2]
        info_msgs = msgs[n // 2:]

        inputs = self.get_lss_inputs(img_msgs, info_msgs)
        inputs = [i.to(self.device) for i in inputs]

        # model inference
        t1 = time()
        height_pred_rigid = self.model(*inputs)
        rospy.logdebug('LSS Processing time: %.3f [sec]' % (time() - t1))
        rospy.loginfo('Predicted height map shape: %s' % str(height_pred_rigid.shape))

        # publish height map as grid map
        stamp = msgs[0].header.stamp
        height = height_pred_rigid.squeeze().cpu().numpy()
        grid_msg = height_map_to_gridmap_msg(height, self.dphys_cfg.grid_res,
                                             xyz=np.array([0., 0., 0.]), q=np.array([0., 0., 0., 1.]))
        grid_msg.info.header.stamp = stamp
        grid_msg.info.header.frame_id = self.hm_frame
        self.gridmap_pub.publish(grid_msg)

    def spin(self):
        try:
            rospy.spin()
        except rospy.ROSInterruptException:
            pass


class LSSDebug(LSS):
    def __init__(self,
                 dphys_cfg: DPhysConfig,
                 lss_cfg: dict,
                 weights=None,
                 hm_frame='base_link',
                 img_topics=[],
                 camera_info_topics=[],
                 points_topic='/points',
                 calib_path='',
                 max_msgs_delay=0.1,
                 max_age=0.2,
                 n_cams=None,
                 ):
        super(LSSDebug, self).__init__(
            dphys_cfg=dphys_cfg,
            lss_cfg=lss_cfg,
            weights=weights,
            hm_frame=hm_frame,
            img_topics=img_topics,
            camera_info_topics=camera_info_topics,
            calib_path=calib_path,
            max_msgs_delay=max_msgs_delay,
            max_age=max_age,
            n_cams=n_cams,
        )
        self.points_topic = points_topic

    def start(self):
        # subscribe to images with approximate time synchronization
        self.subs = []
        for topic in self.img_topics:
            rospy.loginfo('Subscribing to %s' % topic)
            self.subs.append(Subscriber(topic, CompressedImage))
        for topic in self.camera_info_topics:
            rospy.loginfo('Subscribing to %s' % topic)
            self.subs.append(Subscriber(topic, CameraInfo))
        rospy.loginfo('Subscribing to %s' % self.points_topic)
        self.subs.append(Subscriber(self.points_topic, PointCloud2))
        self.sync = ApproximateTimeSynchronizer(self.subs, queue_size=1, slop=self.max_msgs_delay)
        self.sync.registerCallback(self.callback)

    def vis(self, imgs, rots, trans, intrins, post_rots, post_trans, bev_map, points, fname=None):
        assert isinstance(imgs, torch.Tensor)
        assert imgs.ndim == 5 and imgs.shape[2] == 3  # (B, N_cams, C=3, H, W)
        B, N_cams, C, H_i, W_i = imgs.shape
        assert isinstance(rots, torch.Tensor)
        assert rots.shape == (B, N_cams, 3, 3)
        assert isinstance(trans, torch.Tensor)
        assert trans.shape == (B, N_cams, 3)
        assert isinstance(intrins, torch.Tensor)
        assert intrins.shape == (B, N_cams, 3, 3)
        assert isinstance(post_rots, torch.Tensor)
        assert post_rots.shape == (B, N_cams, 3, 3)
        assert isinstance(post_trans, torch.Tensor)
        assert post_trans.shape == (B, N_cams, 3)
        assert isinstance(bev_map, torch.Tensor)
        assert bev_map.ndim == 3 and bev_map.shape[1] == bev_map.shape[2]  # (B, H, W)
        assert isinstance(points, torch.Tensor)
        assert points.ndim == 3 and points.shape[1] == 3  # (B, 3, N_points)

        H, W = self.lss_cfg['data_aug_conf']['H'], self.lss_cfg['data_aug_conf']['W']
        cams = [f'cam_{i}' for i in range(imgs.shape[1])]
        rat = H / W
        val = 10.1
        fig = plt.figure(figsize=(val + val / 2 * 2 * rat * 2, val / 2 * 2 * rat))
        gs = mpl.gridspec.GridSpec(2, 4, width_ratios=(1, 1, 2 * rat, 2 * rat))
        gs.update(wspace=0.0, hspace=0.0, left=0.0, right=1.0, top=1.0, bottom=0.0)
        img_pts = self.model.get_geometry(rots.to(self.device),
                                          trans.to(self.device),
                                          intrins.to(self.device),
                                          post_rots.to(self.device),
                                          post_trans.to(self.device),
                                          )
        img_pts = img_pts.cpu()

        for si in range(imgs.shape[0]):
            plt.clf()
            final_ax = plt.subplot(gs[:, 3:4])
            for imgi, img in enumerate(imgs[si]):
                cam_pts = ego_to_cam(points[si], rots[si, imgi], trans[si, imgi], intrins[si, imgi])
                mask = get_only_in_img_mask(cam_pts, H, W)
                plot_pts = post_rots[si, imgi].matmul(cam_pts) + post_trans[si, imgi].unsqueeze(1)

                ax = plt.subplot(gs[imgi // 2, imgi % 2])
                showimg = img.permute(1, 2, 0).numpy()
                showimg = normalize(showimg)

                plt.imshow(showimg)
                plt.scatter(plot_pts[0, mask], plot_pts[1, mask], c=points[si, 2, mask], s=2, cmap='jet', alpha=0.2)
                plt.axis('off')
                # camera name as text on image
                plt.text(0.5, 0.9, cams[imgi].replace('_', ' '), horizontalalignment='center', verticalalignment='top',
                         transform=ax.transAxes, fontsize=10)

                plt.sca(final_ax)
                plt.plot(img_pts[si, imgi, :, :, :, 0].view(-1), img_pts[si, imgi, :, :, :, 1].view(-1), '.',
                         label=cams[imgi].replace('_', ' '))

            plt.legend(loc='upper right')
            final_ax.set_aspect('equal')
            plt.xlim((-self.dphys_cfg.d_max, self.dphys_cfg.d_max))
            plt.ylim((-self.dphys_cfg.d_max, self.dphys_cfg.d_max))

            # ax = plt.subplot(gs[:, 2:3])
            # plt.scatter(pts[si, 0], pts[si, 1], c=pts[si, 2], s=5, cmap='Greys', vmin=-0.5, vmax=0.5)
            # plt.xlim((-self.cfg.d_max, self.cfg.d_max))
            # plt.ylim((-self.cfg.d_max, self.cfg.d_max))
            # ax.set_aspect('equal')

            ax = plt.subplot(gs[:, 2:3])
            plt.imshow(bev_map[si].squeeze(0).T, origin='lower', cmap='jet', vmin=-0.5, vmax=0.5)
            plt.colorbar()

            if fname is None:
                plt.show()
            fig.savefig(fname, dpi=300)

    def get_cloud_and_height(self, points_msg):
        assert isinstance(points_msg, PointCloud2)

        # process point cloud data
        cloud = numpify(points_msg)
        if cloud.ndim > 1:
            cloud = cloud.reshape(-1)
        points = position(cloud)
        # transform cloud to height map frame
        if self.calib is None:
            time = rospy.Time(0)
            timeout = rospy.Duration.from_sec(1.0)
            try:
                tf = self.tf_buffer.lookup_transform(self.hm_frame, points_msg.header.frame_id, time, timeout)
            except tf2_ros.TransformException as ex:
                rospy.logerr('Could not transform from cloud %s to robot %s: %s.',
                             points_msg.header.frame_id, self.hm_frame, ex)
                return None, None
            Tr = np.array(numpify(tf.transform), dtype=np.float32).reshape((4, 4))
        else:
            Tr = self.calib['transformations'][f'T_{self.hm_frame}__{points_msg.header.frame_id}']['data']
            Tr = np.array(Tr, dtype=np.float32).reshape((4, 4))
        points = Tr[:3, :3] @ points.T + Tr[:3, 3:4]
        hm = estimate_heightmap(points.T, d_min=self.dphys_cfg.d_min, d_max=self.dphys_cfg.d_max,
                                grid_res=self.dphys_cfg.grid_res, h_max_above_ground=self.dphys_cfg.h_max_above_ground,
                                hm_interp_method=self.dphys_cfg.hm_interp_method)
        if hm is None:
            rospy.logwarn('Could not estimate height map')
            return
        height = hm['z']

        points = torch.as_tensor(points[np.newaxis], dtype=torch.float32)
        height = torch.as_tensor(height[np.newaxis], dtype=torch.float32)

        return points, height

    def proc(self, *msgs):
        assert len(msgs) == 9
        for i in range(4):
            assert isinstance(msgs[i], CompressedImage)
            assert isinstance(msgs[i + 4], CameraInfo)
            assert msgs[i].header.frame_id == msgs[i + 4].header.frame_id
        assert isinstance(msgs[8], PointCloud2)

        img_msgs = msgs[:4]
        info_msgs = msgs[4:8]
        points_msg = msgs[8]

        lss_inputs = self.get_lss_inputs(img_msgs, info_msgs)

        # process point cloud data
        points, height = self.get_cloud_and_height(points_msg)
        rospy.logdebug('Point cloud shape: %s' % str(points.shape))
        rospy.logdebug('Estimated height map shape: %s' % str(height.shape))

        imgs, rots, trans, intrins, post_rots, post_trans = lss_inputs
        vis_inputs = [imgs, rots, trans, intrins, post_rots, post_trans, height, points]

        for v in vis_inputs:
            print(v.shape)

        self.vis(*vis_inputs, fname=f'lss_data_{time()}.png')


def main():
    rospy.init_node('lss', anonymous=True, log_level=rospy.DEBUG)
    pkg_path = rospkg.RosPack().get_path('monoforce')

    dphys_cfg = DPhysConfig()
    dphys_config_path = rospy.get_param('~dphys_config_path', os.path.join(pkg_path, 'config/dphys_cfg.yaml'))
    assert os.path.isfile(dphys_config_path), 'Config file %s does not exist' % dphys_config_path
    dphys_cfg.from_yaml(dphys_config_path)

    # load LSS config
    lss_config_path = rospy.get_param('~lss_config_path', os.path.join(pkg_path, 'config/lss_cfg_tradr.yaml'))
    assert os.path.isfile(lss_config_path), 'LSS config file %s does not exist' % lss_config_path
    lss_cfg = read_yaml(lss_config_path)

    img_topics = rospy.get_param('~img_topics', [])
    camera_info_topics = rospy.get_param('~camera_info_topics', [])
    hm_frame = rospy.get_param('~hm_frame', 'base_link')
    weights = rospy.get_param('~weights', os.path.join(pkg_path, 'config/weights/lss/lss.pt'))
    max_msgs_delay = rospy.get_param('~max_msgs_delay', 0.1)
    max_age = rospy.get_param('~max_age', 0.2)
    calib_path = rospy.get_param('~calib_path', '')
    n_cams = rospy.get_param('~n_cams', None)

    NodeClass = LSSDebug if rospy.get_param('~debug', False) else LSS
    node = NodeClass(dphys_cfg=dphys_cfg, lss_cfg=lss_cfg,
                     weights=weights,
                     img_topics=img_topics, camera_info_topics=camera_info_topics,
                     hm_frame=hm_frame,
                     max_msgs_delay=max_msgs_delay,
                     max_age=max_age,
                     calib_path=calib_path,
                     n_cams=n_cams)
    node.start()
    node.spin()


if __name__ == '__main__':
    main()
