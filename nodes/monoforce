#!/usr/bin/env python

import os
import numpy as np
import torch
import rospy
from numpy.lib.recfunctions import unstructured_to_structured
from monoforce.datasets import RobinGasVis, robingas_husky_seq_paths
from monoforce.config import DPhysConfig
from monoforce.models import State, RigidBodySoftTerrain
from monoforce.ros import height_map_to_gridmap_msg, to_path, to_tf, xyz_to_point
from monoforce.models.lss.model import compile_model
from monoforce.transformations import rot2rpy
from nav_msgs.msg import Path
from sensor_msgs.msg import PointCloud2, Image, CameraInfo
from grid_map_msgs.msg import GridMap
from ros_numpy import msgify
from monoforce.utils import read_yaml
import rospkg
import tf2_ros
from visualization_msgs.msg import Marker, MarkerArray


class DataVis:
    def __init__(self, name='monoforce'):
        self.dphys_cfg = DPhysConfig()
        self.pkg_path = rospkg.RosPack().get_path('monoforce')
        self.config_path = rospy.get_param('~config_path', os.path.join(self.pkg_path, 'config/dphys_cfg.yaml'))
        assert os.path.isfile(self.config_path), 'Config file %s does not exist' % self.config_path
        self.dphys_cfg.from_yaml(self.config_path)
        self.dphys_cfg.from_rosparams(node_name=name)

        # load LSS config
        self.lss_config_path = rospy.get_param('~lss_config_path', os.path.join(self.pkg_path, 'config/lss_cfg.yaml'))
        assert os.path.isfile(self.lss_config_path), 'LSS config file %s does not exist' % self.lss_config_path
        self.lss_config = read_yaml(self.lss_config_path)
        self.grid_conf = self.lss_config['grid_conf']
        self.data_aug_conf = self.lss_config['data_aug_conf']

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        if self.dphys_cfg.n_samples / self.dphys_cfg.total_sim_time != 100:
            rospy.logwarn('Simulated time and number of predicted trajectory samples'
                          'do not match the default rate of 100 Hz.')
        self.rate = rospy.get_param('~rate', self.dphys_cfg.n_samples / self.dphys_cfg.total_sim_time)
        self.map_frame = rospy.get_param('~map_frame', 'map')
        self.robot_initial_frame = rospy.get_param('~robot_initial_frame', 'base_link0')
        self.robot_frame = rospy.get_param('~robot_frame', 'base_link')
        # self.camera_frames = [cam.lower() for cam in self.data_aug_conf['cams']]
        self.camera_frames = ['camera_front', 'camera_left', 'camera_rear', 'camera_right']
        self.modelf = rospy.get_param('~lss_weights')
        self.model = self.load_model()

        # publishers
        self.gm_lidar_pub = rospy.Publisher('grid_map_lidar', GridMap, queue_size=1)
        self.gm_traj_pub = rospy.Publisher('grid_map_traj', GridMap, queue_size=1)
        self.gm_rigid_pub = rospy.Publisher('grid_map_rigid', GridMap, queue_size=1)
        self.gm_geom_pub = rospy.Publisher('grid_map_geom', GridMap, queue_size=1)
        self.gm_diff_pub = rospy.Publisher('grid_map_diff', GridMap, queue_size=1)
        self.cloud_pub = rospy.Publisher('cloud', PointCloud2, queue_size=1)
        self.path_pub = rospy.Publisher('path', Path, queue_size=1)
        self.path_gt_pub = rospy.Publisher('path_gt', Path, queue_size=1)
        self.img_pubs = [rospy.Publisher('%s/image' % cam, Image, queue_size=1) for cam in self.camera_frames]
        self.caminfo_pubs = [rospy.Publisher('%s/camera_info' % cam, CameraInfo, queue_size=1) for cam in self.camera_frames]
        self.tf_broadcast = tf2_ros.TransformBroadcaster()
        self.forces_pub = rospy.Publisher('forces', MarkerArray, queue_size=1)

    def load_model(self):
        model = compile_model(self.lss_config['grid_conf'], self.lss_config['data_aug_conf'], outC=1)
        rospy.loginfo('Loading model from: %s' % self.modelf)
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.load_state_dict(torch.load(self.modelf, map_location=device))
        model.eval()
        return model

    def publish_cloud(self, points, stamp):
        assert points.ndim == 2, 'Points must be of shape (N, 3)'
        assert points.shape[1] == 3, 'Points must be of shape (N, 3)'
        points = np.asarray(points, dtype='float32')
        cloud_struct = unstructured_to_structured(points, names=['x', 'y', 'z'])
        cloud_msg = msgify(PointCloud2, cloud_struct)
        cloud_msg.header.frame_id = self.robot_initial_frame
        cloud_msg.header.stamp = stamp
        self.cloud_pub.publish(cloud_msg)

    def publish_images(self, imgs, Ks, stamp):
        for cam, img, K, img_pub, K_pub in zip(self.camera_frames, imgs, Ks, self.img_pubs, self.caminfo_pubs):
            # images
            img = np.asarray(img, dtype='uint8')
            img_msg = msgify(Image, img, encoding='rgb8')
            img_msg.header.stamp = stamp
            img_msg.header.frame_id = cam.lower()
            img_pub.publish(img_msg)
            # cameras info
            K_msg = CameraInfo()
            P = np.zeros((3, 4))
            P[:3, :3] = K
            R = np.eye(3)
            K_msg.K = K.flatten().tolist()
            K_msg.P = P.flatten().tolist()
            K_msg.R = R.flatten().tolist()
            K_msg.header.stamp = stamp
            K_msg.header.frame_id = cam.lower()
            K_msg.height = img.shape[0]
            K_msg.width = img.shape[1]
            K_pub.publish(K_msg)

    def publish_gridmap(self, height, stamp, pub, mask=None):
        if isinstance(height, torch.Tensor):
            height = height.cpu().numpy()
        if isinstance(mask, torch.Tensor):
            mask = mask.cpu().numpy()
        grid_msg = height_map_to_gridmap_msg(height, grid_res=self.dphys_cfg.grid_res, mask=mask)
        grid_msg.info.header.frame_id = self.robot_initial_frame
        grid_msg.info.header.stamp = stamp
        pub.publish(grid_msg)

    def publish_forces(self, robot_forces, robot_points, stamp):
        assert robot_forces.shape == robot_points.shape
        assert robot_forces.shape[0] == 3
        # publish forces as arrows with MarkerArray
        markers = MarkerArray()
        for i in range(robot_forces.shape[1]):
            force = robot_forces[:, i]
            xyz = robot_points[:, i]
            marker = Marker()
            marker.header.frame_id = self.robot_frame
            marker.header.stamp = stamp
            marker.id = i
            marker.type = Marker.ARROW
            marker.action = Marker.ADD
            marker.pose.position.x = xyz[0]
            marker.pose.position.y = xyz[1]
            marker.pose.position.z = xyz[2]
            marker.points.append(xyz_to_point([0, 0, 0]))
            marker.points.append(xyz_to_point(force / self.dphys_cfg.robot_mass / 9.8))
            marker.scale.x = 0.05
            marker.scale.y = 0.1  # to make the arrow visible
            marker.scale.z = 0.05
            marker.color.a = 1.0
            marker.color.r = 1.0
            marker.color.g = 0.0
            marker.color.b = 0.0
            markers.markers.append(marker)
        self.forces_pub.publish(markers)

    def dphysics(self, height, controls, state=None):
        assert isinstance(height, np.ndarray)
        assert height.shape[0] == height.shape[1]
        assert isinstance(controls, dict)
        assert 'stamps' in controls.keys()
        assert 'linear_v' in controls.keys()
        assert 'angular_w' in controls.keys()
        assert isinstance(state, State) or state is None

        if state is None:
            state = State(xyz=torch.tensor([0., 0., 0.], device=self.device).view(3, 1),
                          rot=torch.eye(3, device=self.device),
                          vel=torch.tensor([0., 0., 0.], device=self.device).view(3, 1),
                          omega=torch.tensor([0., 0., 0.], device=self.device).view(3, 1),
                          device=self.device)

        """ Create robot-terrain interaction models """
        system = RigidBodySoftTerrain(height=height,
                                      grid_res=self.dphys_cfg.grid_res,
                                      friction=self.dphys_cfg.friction,
                                      mass=self.dphys_cfg.robot_mass,
                                      state=state,
                                      device=self.device, use_ode=False,
                                      interaction_model='diffdrive',
                                      robot_model='husky')

        # put models with their params to self.device
        system = system.to(self.device)
        tt = controls['stamps'].to(self.device)

        """ Navigation loop """
        dt = (tt[1:] - tt[:-1]).mean()

        xyz, Rs, linear_v, angular_w, forces = state
        xyz, Rs, linear_v, angular_w, forces = [xyz], [Rs], [linear_v], [angular_w], [forces]

        for t in range(len(tt[1:])):
            v, w = controls['linear_v'][t], controls['angular_w'][t]

            state[2][0] = v
            state[3][2] = w

            dstate = system.forward(t, state)
            state = state.update(dstate, dt)

            roll, pitch, yaw = rot2rpy(state[1].squeeze())
            if torch.abs(roll) > np.pi / 2. or torch.abs(pitch) > np.pi / 2.:
                rospy.logwarn('Robot is upside down')
                break

            xyz.append(state[0])
            Rs.append(state[1])
            linear_v.append(state[2])
            angular_w.append(state[3])
            forces.append(state[4])

        xyz = torch.stack(xyz)
        Rs = torch.stack(Rs)
        linear_v = torch.stack(linear_v)
        angular_w = torch.stack(angular_w)
        forces = torch.stack(forces)

        states = [xyz, Rs, linear_v, angular_w, forces]

        # robot points
        robot_points = system.robot_points

        return states, robot_points

    def poses_from_states(self, states):
        xyz = states[0].cpu().numpy()
        Rs = states[1].cpu().numpy()
        poses = np.stack([np.eye(4) for _ in range(len(xyz))])
        poses[:, :3, :3] = Rs
        poses[:, :3, 3:4] = xyz
        poses[:, 2, 3] += self.dphys_cfg.robot_clearance + 0.1
        # poses inside the heightmap
        mask = (xyz[:, 0] > -self.dphys_cfg.d_max) & (xyz[:, 0] < self.dphys_cfg.d_max) & \
               (xyz[:, 1] > -self.dphys_cfg.d_max) & (xyz[:, 1] < self.dphys_cfg.d_max)
        mask = np.asarray(mask, dtype=bool).flatten()
        poses = poses[mask]
        return poses

    def predict_states(self, height, v, w):
        with torch.no_grad():
            # controls
            tt = torch.linspace(0., self.dphys_cfg.total_sim_time, self.dphys_cfg.n_samples)
            controls = {
                'stamps': tt,
                'linear_v': v * torch.ones(self.dphys_cfg.n_samples),
                'angular_w': w * torch.ones(self.dphys_cfg.n_samples)
            }
            states, robot_points = self.dphysics(height, controls)
        return states, robot_points.detach()

    def run(self):
        # choose data sample
        seq_i = rospy.get_param('~seq_i', np.random.choice(range(len(robingas_husky_seq_paths))))
        data_seq = robingas_husky_seq_paths[seq_i]
        ds = RobinGasVis(data_seq, dphys_cfg=self.dphys_cfg, data_aug_conf=self.data_aug_conf, is_train=False)
        rospy.loginfo('Loaded dataset with %d samples from path: %s' % (len(ds), data_seq))
        sample_i = rospy.get_param('~sample_i', np.random.choice(range(len(ds))))
        rospy.loginfo('Using sample %d' % sample_i)

        imgs, rots, trans, intrins, post_rots, post_trans, hm_lidar, hm_traj, map_pose, lidar_pts = ds[sample_i]
        points = lidar_pts.numpy().T

        traj = ds.get_traj(sample_i)
        poses_gt = traj['poses']

        imgs_raw = []
        Ks = []
        for cam in self.camera_frames:
            img_raw, K = ds.get_image(sample_i, cam, undistort=False)
            imgs_raw.append(img_raw)
            Ks.append(K)

        # get heightmap prediction
        with torch.no_grad():
            inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
            inputs = [torch.as_tensor(i[None]) for i in inputs]
            # height_pred = self.model(*inputs)
            voxel_feats = self.model.get_voxels(*inputs)
            height_pred_geom, height_pred_diff = self.model.bevencode(voxel_feats)
            height_pred_rigid = height_pred_geom - height_pred_diff
            height_pred_rigid = height_pred_rigid.squeeze().cpu().numpy()
            height_pred_geom = height_pred_geom.squeeze().cpu().numpy()
            height_pred_diff = height_pred_diff.squeeze().cpu().numpy()

        rate = rospy.Rate(self.rate)
        pose_i = 0
        poses = None
        forces = None
        robot_points = None
        while not rospy.is_shutdown():
            stamp = rospy.Time.now()

            if pose_i == 0:
                # point cloud
                self.publish_cloud(points, stamp)
                # grid map
                self.publish_gridmap(hm_lidar[0], stamp, self.gm_lidar_pub, mask=hm_lidar[1])
                self.publish_gridmap(hm_traj[0], stamp, self.gm_traj_pub, mask=hm_traj[1])
                self.publish_gridmap(height_pred_rigid, stamp, self.gm_rigid_pub)
                self.publish_gridmap(height_pred_geom, stamp, self.gm_geom_pub)
                self.publish_gridmap(height_pred_diff, stamp, self.gm_diff_pub)
                # images
                self.publish_images(imgs_raw, Ks, stamp)

                # predict path poses
                v = np.random.uniform(0.4, 0.8)
                if np.random.random() > 0.5:
                    v = -v
                w = np.random.uniform(-0.2, 0.2)
                # v = 0.5
                # w = -0.13
                rospy.loginfo('Predicting path with v=%.3f, w=%.3f' % (v, w))
                states, robot_points = self.predict_states(height_pred_rigid, v=v, w=w)
                # states, robot_points = self.predict_poses(hm_lidar[0].cpu().numpy(), v=v, w=w)
                # states, robot_points = self.predict_poses(height_pred_geom, v=v, w=w)
                poses = self.poses_from_states(states)
                rospy.loginfo('Predicted poses shape: %s' % str(poses.shape))
                forces = states[4].cpu().numpy()
                rospy.loginfo('Predicted forces shape: %s' % str(forces.shape))
                robot_points = robot_points.cpu().numpy()
                rospy.loginfo('Robot contact points shape: %s' % str(robot_points.shape))
                # publish paths
                path_msg = to_path(poses, frame_id=self.robot_initial_frame, stamp=stamp)
                path_gt_msg = to_path(poses_gt, frame_id=self.robot_initial_frame, stamp=stamp)
                self.path_pub.publish(path_msg)
                self.path_gt_pub.publish(path_gt_msg)

            # robot pose in map frame
            tf = to_tf(map_pose, self.map_frame, self.robot_initial_frame, stamp)
            self.tf_broadcast.sendTransform(tf)
            # camera poses
            for cam, tran, rot in zip(self.camera_frames, trans, rots):
                pose = np.eye(4)
                pose[:3, :3] = rot.numpy()
                pose[:3, 3] = tran.numpy()
                tf = to_tf(pose, self.robot_initial_frame, cam, stamp)
                self.tf_broadcast.sendTransform(tf)

            # robot's current pose
            robot_traj_pose = poses[pose_i]
            assert robot_traj_pose.shape == (4, 4)
            tf = to_tf(robot_traj_pose, self.robot_initial_frame, self.robot_frame, stamp)
            self.tf_broadcast.sendTransform(tf)

            # publish forces
            self.publish_forces(forces[pose_i], robot_points, stamp)

            pose_i = (pose_i + 1) % len(poses)
            rate.sleep()

def main():
    rospy.init_node('monoforce', anonymous=True, log_level=rospy.DEBUG)
    node = DataVis()
    node.run()


if __name__ == '__main__':
    main()
