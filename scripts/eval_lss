#!/usr/bin/env python

import torch
import numpy as np
from torch.utils.data import ConcatDataset
from monoforce.models.lss.model import compile_model
from monoforce.datasets.data import OmniDemData, OmniDemDataVis
from monoforce.config import Config
from monoforce.datasets import seq_paths
from monoforce.models.lss.tools import MSELoss, ego_to_cam, get_only_in_img_mask, denormalize_img
from monoforce.utils import normalize
import matplotlib.pyplot as plt
import matplotlib as mpl
from mpl_toolkits.mplot3d import Axes3D
from tqdm import tqdm


def explore_data(ds, model=None, samples=1):
    plt.switch_backend('Qt5Agg')

    print('Cameras: ', ds.cameras)
    for counter in np.random.choice(range(len(ds)), samples):
        sample = ds[counter]
        imgs = sample[0].permute(0, 2, 3, 1)
        imgs = [ds.destandardize_img(img) for img in imgs]
        imgs = [normalize(img) for img in imgs]

        if model is None:
            local_map = sample[6][0]
        else:
            # predict heightmap
            preds = model(sample[0].unsqueeze(0).to(ds.cfg.device),
                          sample[1].unsqueeze(0).to(ds.cfg.device),
                          sample[2].unsqueeze(0).to(ds.cfg.device),
                          sample[3].unsqueeze(0).to(ds.cfg.device),
                          sample[4].unsqueeze(0).to(ds.cfg.device),
                          sample[5].unsqueeze(0).to(ds.cfg.device),
                          )
            local_map = preds.squeeze().cpu().numpy()

        fig, ax = plt.subplots(3, 3)
        # figsize
        fig.set_size_inches(18.5, 10.5)
        # switch off axis and grid
        for i in range(3):
            for j in range(3):
                if i == 1 and j == 1:
                    continue
                ax[i, j].axis('off')
                ax[i, j].grid(False)

        ax[0, 1].title.set_text('CAM_FRONT')
        ax[0, 1].imshow(imgs[0])
        ax[1, 0].title.set_text('CAM_LEFT')
        ax[1, 0].imshow(imgs[3])

        ax[1, 1].title.set_text('LOCAL_MAP')
        fig.colorbar(ax[1, 1].imshow(local_map, cmap='jet'), ax=ax[1, 1])
        ax[1, 1].plot(local_map.shape[0]//2, local_map.shape[1]//2, 'k+')
        # set x ticks from -d_max to d_max
        ax[1, 1].set_xticks(np.linspace(0, local_map.shape[0], 5))
        ax[1, 1].set_yticks(np.linspace(0, local_map.shape[1], 5))
        ax[1, 1].set_xticklabels(np.linspace(-ds.cfg.d_max, ds.cfg.d_max, 5))
        ax[1, 1].set_yticklabels(np.linspace(-ds.cfg.d_max, ds.cfg.d_max, 5))
        ax[1, 1].set_xlabel('x (m)')
        ax[1, 1].set_ylabel('y (m)')

        ax[1, 2].title.set_text('CAM_RIGHT')
        ax[1, 2].imshow(imgs[2])
        ax[2, 1].title.set_text('CAM_REAR')
        ax[2, 1].imshow(imgs[1])

        # plot height map as a surface at a new figure
        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        X = np.arange(-ds.cfg.d_max, ds.cfg.d_max, ds.cfg.grid_res)
        Y = np.arange(-ds.cfg.d_max, ds.cfg.d_max, ds.cfg.grid_res)
        X, Y = np.meshgrid(X, Y)
        surf = ax.plot_surface(X, Y, local_map, cmap='jet', linewidth=0, antialiased=False)
        ax.set_xlabel('x (m)')
        ax.set_ylabel('y (m)')
        ax.set_zlabel('z (m)')
        fig.colorbar(surf, shrink=0.5, aspect=5)
        ax.set_xlim(-ds.cfg.d_max, ds.cfg.d_max)
        ax.set_ylim(-ds.cfg.d_max, ds.cfg.d_max)
        ax.set_zlim(-1., 1.)

        plt.show()


def lidar_check():
    cfg = Config()
    cfg.d_min = 0.6
    cfg.d_max = 6.4
    cfg.grid_res = 0.1
    cfg.h_above_lidar = 0.3
    cfg.device = torch.device('cuda:0')

    grid_conf = {
        'xbound': [-cfg.d_max, cfg.d_max, cfg.grid_res],
        'ybound': [-cfg.d_max, cfg.d_max, cfg.grid_res],
        'zbound': [-2.0, 2.0, 4.0],
        'dbound': [cfg.d_min, cfg.d_max, cfg.grid_res],
    }

    data_aug_conf = {
        'resize_lim': (0.193, 0.225),
        'final_dim': (128, 352),
        'rot_lim': (-5.4, 5.4),
        'H': 1200, 'W': 1920,
        'rand_flip': False,
        'bot_pct_lim': (0.0, 0.22),
        'cams': ['CAM_FRONT', 'CAM_LEFT', 'CAM_REAR', 'CAM_RIGHT'],
        'Ncams': 4,
    }

    model = compile_model(grid_conf, data_aug_conf, outC=1)

    ds = OmniDemDataVis(seq_paths[-1], is_train=False, data_aug_conf=data_aug_conf, cfg=cfg)
    loader = torch.utils.data.DataLoader(ds, batch_size=1, shuffle=False, num_workers=0)

    H, W = data_aug_conf['H'], data_aug_conf['W']
    cams = data_aug_conf['cams']
    rat = H / W
    val = 10.1
    fig = plt.figure(figsize=(val + val / 2 * 2 * rat * 2, val / 2 * 2 * rat))
    gs = mpl.gridspec.GridSpec(2, 5, width_ratios=(1, 1, 2 * rat, 2 * rat, 2 * rat))
    gs.update(wspace=0.0, hspace=0.0, left=0.0, right=1.0, top=1.0, bottom=0.0)

    for batchi, (imgs, rots, trans, intrins, post_rots, post_trans, pts, bev_map) in enumerate(loader):

        img_pts = model.get_geometry(rots, trans, intrins, post_rots, post_trans)

        for si in range(imgs.shape[0]):
            plt.clf()
            final_ax = plt.subplot(gs[:, 4:5])
            for imgi, img in enumerate(imgs[si]):
                ego_pts = ego_to_cam(pts[si], rots[si, imgi], trans[si, imgi], intrins[si, imgi])
                mask = get_only_in_img_mask(ego_pts, H, W)
                plot_pts = post_rots[si, imgi].matmul(ego_pts) + post_trans[si, imgi].unsqueeze(1)

                ax = plt.subplot(gs[imgi // 2, imgi % 2])
                showimg = ds.destandardize_img(img.permute(1, 2, 0))

                plt.imshow(showimg)
                plt.scatter(plot_pts[0, mask], plot_pts[1, mask], c=ego_pts[2, mask],
                            s=5, alpha=0.1, cmap='jet')
                # plot_pts = post_rots[si, imgi].matmul(img_pts[si, imgi].view(-1, 3).t()) + post_trans[si, imgi].unsqueeze(1)
                # plt.scatter(img_pts[:, :, :, 0].view(-1), img_pts[:, :, :, 1].view(-1), s=1)
                plt.axis('off')

                plt.sca(final_ax)
                plt.plot(img_pts[si, imgi, :, :, :, 0].view(-1), img_pts[si, imgi, :, :, :, 1].view(-1), '.',
                         label=cams[imgi].replace('_', ' '))

            plt.legend(loc='upper right')
            final_ax.set_aspect('equal')
            plt.xlim((-cfg.d_max, cfg.d_max))
            plt.ylim((-cfg.d_max, cfg.d_max))

            ax = plt.subplot(gs[:, 2:3])
            plt.scatter(pts[si, 0], pts[si, 1], c=pts[si, 2], vmin=-5, vmax=5, s=5)
            plt.xlim((-cfg.d_max, cfg.d_max))
            plt.ylim((-cfg.d_max, cfg.d_max))
            ax.set_aspect('equal')

            ax = plt.subplot(gs[:, 3:4])
            plt.imshow(bev_map[si].squeeze(0).T, origin='lower', cmap='Greys', vmin=0, vmax=1)

            imname = f'lcheck_{batchi:05}_{si:02}.jpg'
            print('saving', imname)
            plt.savefig(imname)


def eval():
    cfg = Config()
    cfg.d_min = 0.6
    cfg.d_max = 6.4
    cfg.grid_res = 0.1
    cfg.h_above_lidar = 0.3
    cfg.device = torch.device('cuda:0')

    bsz = 2
    nworkers = 10

    modelf = '../config/weights/lss/lss11.pt'

    grid_conf = {
        'xbound': [-cfg.d_max, cfg.d_max, cfg.grid_res],
        'ybound': [-cfg.d_max, cfg.d_max, cfg.grid_res],
        'zbound': [-2.0, 2.0, 4.0],
        'dbound': [cfg.d_min, cfg.d_max, cfg.grid_res],
    }

    data_aug_conf = {
                    'resize_lim': (0.193, 0.225),
                    'final_dim': (128, 352),
                    'rot_lim': (-5.4, 5.4),
                    'H': 1200, 'W': 1920,
                    'rand_flip': False,
                    'bot_pct_lim': (0.0, 0.22),
                    'cams': ['CAM_FRONT', 'CAM_LEFT', 'CAM_REAR', 'CAM_RIGHT'],
                    'Ncams': 4,
                }

    all_seqs_mean_loss = 0.0
    for val_ds_path in seq_paths:
        val_ds = OmniDemData(val_ds_path, is_train=False, data_aug_conf=data_aug_conf, cfg=cfg)
        valloader = torch.utils.data.DataLoader(val_ds, batch_size=bsz, shuffle=False, num_workers=nworkers)

        model = compile_model(grid_conf, data_aug_conf, outC=1)
        print('loading', modelf)
        model.load_state_dict(torch.load(modelf))
        model.to(cfg.device)
        model.eval()

        loss_fn = MSELoss()

        # validation epoch
        with torch.no_grad():
            # explore_data(val_ds, model=model, samples=3)
            val_loss = 0.0
            for batchi, (imgs, rots, trans, intrins, post_rots, post_trans, heightmap)\
                    in tqdm(enumerate(valloader), total=len(valloader)):
                preds = model(imgs.to(cfg.device),
                              rots.to(cfg.device),
                              trans.to(cfg.device),
                              intrins.to(cfg.device),
                              post_rots.to(cfg.device),
                              post_trans.to(cfg.device),
                              )
                heightmap = heightmap.to(cfg.device)
                loss = loss_fn(preds, heightmap)
                val_loss += loss.item()
            val_loss /= len(valloader)

        print(f'For seq {val_ds_path.split("/")[-1]} Validation loss: {val_loss:.3f}')
        # explore_data(val_ds, model=model, samples=1)
        all_seqs_mean_loss += val_loss
    all_seqs_mean_loss /= len(seq_paths)
    print(f'Average validation loss: {all_seqs_mean_loss:.3f}')


if __name__ == '__main__':
    eval()
    # lidar_check()
