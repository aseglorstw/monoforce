#! /usr/bin/env python3
import os
import torch
from pytorch3d.loss import chamfer_distance
from pytorch3d.structures import Meshes, Pointclouds
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from tqdm import tqdm
from monoforce.cloudproc import hm_to_cloud, filter_grid
from monoforce.datasets.data import TravData, explore_data
from monoforce.datasets.data import robingas_husky_seq_paths, oru_seq_paths
from monoforce.config import Config
from monoforce.transformations import transform_cloud, so3_to_quaternion
from monoforce.utils import read_yaml, position
from monoforce.models.lss.model import compile_model
import open3d as o3d
import bisect
import numpy.matlib as ml
try:
    import matplotlib as mpl
    mpl.use('QtAgg')
except ImportError:
    pass


torch.set_default_dtype(torch.float32)

def feed_data():
    # path = '/media/ruslan/data/husky_sim/husky_back_forth_rigid_soft_cubes_2024-02-15-15-07-56/'
    # path = '/media/ruslan/data/husky_sim/husky_cubes_random_walk_2024-02-12-15-08-00/'
    path = robingas_husky_seq_paths[1]

    # lss model
    cfg = Config()
    cfg.from_yaml('../config/cfg.yaml')

    # load LSS config
    lss_config = read_yaml('../config/lss.yaml')
    grid_conf, data_aug_conf = lss_config['grid_conf'], lss_config['data_aug_conf']

    ds = TravData(path, data_aug_conf, is_train=False, cfg=cfg)
    model = compile_model(grid_conf, data_aug_conf, outC=1)
    model.train()
    model.to(cfg.device)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    max_grad_norm = 5.0

    def criterion(height_pred, height_gt, weights=None):
        if weights is None:
            weights = torch.ones_like(height_gt)
        return torch.mean(weights * (height_pred - height_gt) ** 2)

    # train on a single example
    sample_i = np.random.randint(len(ds))
    # sample_i = 64
    print('Sample index:', sample_i)
    explore_data(path, grid_conf, data_aug_conf, cfg, is_train=False, sample_range=[sample_i])
    imgs, rots, trans, intrins, post_rots, post_trans, hm_lidar, hm_traj, map_pose = ds[sample_i]
    inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
    inputs = [s[np.newaxis].to(cfg.device) for s in inputs]

    hm_lidar = torch.as_tensor(hm_lidar[np.newaxis], device=cfg.device)
    height_lidar, mask_lidar = hm_lidar[:, 0:1], hm_lidar[:, 1:2]

    hm_traj = torch.as_tensor(hm_traj[np.newaxis], device=cfg.device)
    height_traj, mask_traj = hm_traj[:, 0:1], hm_traj[:, 1:2]

    losses = {'lidar': [], 'traj': [], 'total': [], 'hdiff': []}
    n_iters = 1001
    vis_step = 50
    for i in tqdm(range(n_iters)):
        voxel_feats = model.get_voxels(*inputs)
        height_pred_geom, height_pred_diff = model.bevencode(voxel_feats)
        height_pred_rigid = height_pred_geom - height_pred_diff

        weights_obstacles = 1.0 + torch.abs(height_lidar[mask_lidar.bool()] - height_lidar[mask_lidar.bool()].mean())
        loss_lidar = criterion(height_pred_geom[mask_lidar.bool()], height_lidar[mask_lidar.bool()], weights_obstacles)
        loss_traj = 10.*criterion(height_pred_rigid[mask_traj.bool()], height_traj[mask_traj.bool()])
        loss_hdif = 1e-4*height_pred_diff.std()

        loss = loss_lidar + loss_traj + loss_hdif

        print('loss lidar: %f, loss traj: %f, loss reg: %f, total loss: %f' %
              (loss_lidar.item(), loss_traj.item(), loss_hdif.item(), loss.item()))
        losses['lidar'].append(loss_lidar.item())
        losses['traj'].append(loss_traj.item())
        losses['hdiff'].append(loss_hdif.item())
        losses['total'].append(loss.item())

        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        optimizer.step()

        if i % vis_step == 0:
            # plot the result
            plt.figure(figsize=(20, 10))
            plt.subplot(2, 3, 1)
            plt.title('Lidar HM')
            plt.imshow(height_lidar[0, 0].cpu().numpy().T, cmap='jet', vmin=-1, vmax=1, origin='lower')
            plt.colorbar()

            plt.subplot(2, 3, 2)
            plt.title('Traj HM')
            plt.imshow(height_traj[0, 0].cpu().numpy().T, cmap='jet', vmin=-1, vmax=1, origin='lower')
            plt.colorbar()

            plt.subplot(2, 3, 3)
            plt.title('Loss')
            for k, v in losses.items():
                plt.plot(v[-vis_step:], label=k)
            plt.legend()

            plt.subplot(2, 3, 4)
            plt.title('Prediction Geom')
            plt.imshow(height_pred_geom[0, 0].detach().cpu().numpy().T, cmap='jet', vmin=-1, vmax=1, origin='lower')
            plt.colorbar()

            plt.subplot(2, 3, 5)
            plt.title('Prediction Diff')
            plt.imshow(height_pred_diff[0, 0].detach().cpu().numpy().T, cmap='jet', vmin=-1, vmax=1, origin='lower')
            plt.colorbar()

            plt.subplot(2, 3, 6)
            plt.title('Prediction Rigid')
            plt.imshow(height_pred_rigid[0, 0].detach().cpu().numpy().T, cmap='jet', vmin=-1, vmax=1, origin='lower')
            plt.colorbar()

            plt.show()
            plt.close()


def map_consistency():
    cfg_path = '../config/tb_runs/lss_2024_01_26_15_07_31/cfg.yaml'
    lss_cfg_path = '../config/tb_runs/lss_2024_01_26_15_07_31/lss.yaml'
    model_path = '../config/tb_runs/lss_2024_01_26_15_07_31/train_lss.pt'

    cfg = Config()
    cfg.from_yaml(cfg_path)
    cfg.hm_interp_method = None
    cfg.device = 'cuda'

    predicted_map = True
    vis = True

    lss_cfg = read_yaml(lss_cfg_path)
    data_aug_conf = lss_cfg['data_aug_conf']
    grid_conf = lss_cfg['grid_conf']

    ds = TravData(robingas_husky_seq_paths[0], is_train=True, data_aug_conf=data_aug_conf, cfg=cfg)
    loader = DataLoader(ds, batch_size=16, shuffle=False)
    # ds.global_cloud(vis=True)
    ds.global_hm_cloud(vis=True)

    model = compile_model(grid_conf, data_aug_conf, outC=1)
    model.load_state_dict(torch.load(model_path))
    model.eval()
    model.to(cfg.device)

    # create global heightmap
    for batch in tqdm(loader):
        with torch.no_grad():
            batch = [torch.as_tensor(b, dtype=torch.float32, device=cfg.device) for b in batch]
            imgs, rots, trans, intrins, post_rots, post_trans, hm_lidar, hm_traj, map_pose = batch

            if predicted_map:
                inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
                height_pred = model(*inputs)
                height = height_pred
                # mask = torch.ones_like(height)
                mask = hm_lidar[:, 1:2]
            else:
                height = hm_lidar[:, 0:1]
                mask = hm_lidar[:, 1:2]

            global_hm_clouds = []
            for p, h, m in zip(map_pose, height, mask):
                hm_cloud = hm_to_cloud(h.squeeze(), cfg, mask=m.squeeze())
                hm_cloud = transform_cloud(hm_cloud, p)
                global_hm_clouds.append(hm_cloud)

            # pytorch3d pointcloud
            src_cloud = Pointclouds(points=[torch.cat(global_hm_clouds[::2])])
            tgt_cloud = Pointclouds(points=[torch.cat(global_hm_clouds[1::2])])
            # chamfer distance
            chamfer_dist, _ = chamfer_distance(src_cloud, tgt_cloud)
            print('Chamfer distance:', chamfer_dist)

            if vis:
                global_hm_cloud = torch.cat(global_hm_clouds, dim=0)
                # plot global cloud with open3d
                hm_pcd = o3d.geometry.PointCloud()
                hm_pcd.points = o3d.utility.Vector3dVector(global_hm_cloud.cpu().numpy())
                o3d.visualization.draw_geometries([hm_pcd])


def data_slicing():
    cfg = Config()
    cfg.from_yaml('../config/cfg.yaml')

    lss_cfg = read_yaml('../config/lss.yaml')
    data_aug_conf = lss_cfg['data_aug_conf']
    grid_conf = lss_cfg['grid_conf']

    ds = TravData(robingas_husky_seq_paths[0], is_train=True, data_aug_conf=data_aug_conf, cfg=cfg)
    ds_slice = ds[150:200]
    print("Full dataset contains samples", ds.ids)
    print("Sliced dataset contains samples", ds_slice.ids)
    # check if sliced dataset indixes is a subset of full dataset indixes
    assert set(ds_slice.ids).issubset(set(ds.ids))
    ds_slice.global_hm_cloud(vis=True)


def create_global_gloud_map():
    """
    Create global heightmap cloud from the sequence of point clouds
    """
    cfg = Config()
    cfg.from_yaml('../config/cfg.yaml')

    lss_cfg = read_yaml('../config/lss.yaml')
    data_aug_conf = lss_cfg['data_aug_conf']

    ds = TravData(robingas_husky_seq_paths[2], is_train=True, data_aug_conf=data_aug_conf, cfg=cfg)

    # create global cloud
    poses = ds.get_poses()
    for i in tqdm(range(len(ds))):
        cloud = ds.get_cloud(i)
        T = poses[i]
        cloud = transform_cloud(cloud, T)
        points = position(cloud)
        if i == 0:
            mask = filter_grid(points, ds.cfg.grid_res, keep='first', log=False, only_mask=True)
            global_cloud = points[mask]
        else:
            global_cloud = np.vstack((global_cloud, points[mask]))

    # visualize global cloud
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(global_cloud)

    pcd_poses = o3d.geometry.PointCloud()
    pcd_poses.points = o3d.utility.Vector3dVector(poses[:, :3, 3])
    pcd_poses.paint_uniform_color([1, 0, 0])

    o3d.visualization.draw_geometries([pcd, pcd_poses])

def visualize_point_cloud_map():
    """
    Visualize point cloud map and trajectory point cloud
    """
    path = robingas_husky_seq_paths[0]
    # path = oru_seq_paths[0]

    map_path = os.path.join(path, 'map.pcd')
    traj_path = os.path.join(path, 'trajectory.pcd')

    pcd = o3d.io.read_point_cloud(map_path)
    pcd_traj = o3d.io.read_point_cloud(traj_path)
    pcd_traj.paint_uniform_color([1, 0, 0])
    o3d.visualization.draw_geometries([pcd, pcd_traj])


def interpolate_poses(pose_timestamps, abs_poses, requested_timestamps, origin_timestamp):
    """Interpolate between absolute poses.

    Args:
        pose_timestamps (list[int]): Timestamps of supplied poses. Must be in ascending order.
        abs_poses (list[numpy.matrixlib.defmatrix.matrix]): SE3 matrices representing poses at the timestamps specified.
        requested_timestamps (list[int]): Timestamps for which interpolated timestamps are required.
        origin_timestamp (int): UNIX timestamp of origin frame. Poses will be reported relative to this frame.

    Returns:
        list[numpy.matrixlib.defmatrix.matrix]: SE3 matrix representing interpolated pose for each requested timestamp.

    Raises:
        ValueError: if pose_timestamps and abs_poses are not the same length
        ValueError: if pose_timestamps is not in ascending order

    """
    requested_timestamps.insert(0, origin_timestamp)
    requested_timestamps = np.array(requested_timestamps)
    pose_timestamps = np.array(pose_timestamps)

    if len(pose_timestamps) != len(abs_poses):
        raise ValueError('Must supply same number of timestamps as poses')

    abs_quaternions = np.zeros((4, len(abs_poses)))
    abs_positions = np.zeros((3, len(abs_poses)))
    for i, pose in enumerate(abs_poses):
        if i > 0 and pose_timestamps[i-1] >= pose_timestamps[i]:
            raise ValueError('Pose timestamps must be in ascending order')

        abs_quaternions[:, i] = so3_to_quaternion(pose[0:3, 0:3])
        abs_positions[:, i] = np.ravel(pose[0:3, 3])

    upper_indices = [bisect.bisect(pose_timestamps, pt) for pt in requested_timestamps]
    lower_indices = [u - 1 for u in upper_indices]

    if max(upper_indices) >= len(pose_timestamps):
        upper_indices = [min(i, len(pose_timestamps) - 1) for i in upper_indices]

    fractions = (requested_timestamps - pose_timestamps[lower_indices]) // \
                (pose_timestamps[upper_indices] - pose_timestamps[lower_indices])

    quaternions_lower = abs_quaternions[:, lower_indices]
    quaternions_upper = abs_quaternions[:, upper_indices]

    d_array = (quaternions_lower * quaternions_upper).sum(0)

    linear_interp_indices = np.nonzero(d_array >= 1)
    sin_interp_indices = np.nonzero(d_array < 1)

    scale0_array = np.zeros(d_array.shape)
    scale1_array = np.zeros(d_array.shape)

    scale0_array[linear_interp_indices] = 1 - fractions[linear_interp_indices]
    scale1_array[linear_interp_indices] = fractions[linear_interp_indices]

    theta_array = np.arccos(np.abs(d_array[sin_interp_indices]))

    scale0_array[sin_interp_indices] = \
        np.sin((1 - fractions[sin_interp_indices]) * theta_array) / np.sin(theta_array)
    scale1_array[sin_interp_indices] = \
        np.sin(fractions[sin_interp_indices] * theta_array) / np.sin(theta_array)

    negative_d_indices = np.nonzero(d_array < 0)
    scale1_array[negative_d_indices] = -scale1_array[negative_d_indices]

    quaternions_interp = np.tile(scale0_array, (4, 1)) * quaternions_lower \
                         + np.tile(scale1_array, (4, 1)) * quaternions_upper

    positions_lower = abs_positions[:, lower_indices]
    positions_upper = abs_positions[:, upper_indices]

    positions_interp = np.multiply(np.tile((1 - fractions), (3, 1)), positions_lower) \
                       + np.multiply(np.tile(fractions, (3, 1)), positions_upper)

    poses_mat = ml.zeros((4, 4 * len(requested_timestamps)))

    poses_mat[0, 0::4] = 1 - 2 * np.square(quaternions_interp[2, :]) - \
                         2 * np.square(quaternions_interp[3, :])
    poses_mat[0, 1::4] = 2 * np.multiply(quaternions_interp[1, :], quaternions_interp[2, :]) - \
                         2 * np.multiply(quaternions_interp[3, :], quaternions_interp[0, :])
    poses_mat[0, 2::4] = 2 * np.multiply(quaternions_interp[1, :], quaternions_interp[3, :]) + \
                         2 * np.multiply(quaternions_interp[2, :], quaternions_interp[0, :])

    poses_mat[1, 0::4] = 2 * np.multiply(quaternions_interp[1, :], quaternions_interp[2, :]) \
                         + 2 * np.multiply(quaternions_interp[3, :], quaternions_interp[0, :])
    poses_mat[1, 1::4] = 1 - 2 * np.square(quaternions_interp[1, :]) \
                         - 2 * np.square(quaternions_interp[3, :])
    poses_mat[1, 2::4] = 2 * np.multiply(quaternions_interp[2, :], quaternions_interp[3, :]) - \
                         2 * np.multiply(quaternions_interp[1, :], quaternions_interp[0, :])

    poses_mat[2, 0::4] = 2 * np.multiply(quaternions_interp[1, :], quaternions_interp[3, :]) - \
                         2 * np.multiply(quaternions_interp[2, :], quaternions_interp[0, :])
    poses_mat[2, 1::4] = 2 * np.multiply(quaternions_interp[2, :], quaternions_interp[3, :]) + \
                         2 * np.multiply(quaternions_interp[1, :], quaternions_interp[0, :])
    poses_mat[2, 2::4] = 1 - 2 * np.square(quaternions_interp[1, :]) - \
                         2 * np.square(quaternions_interp[2, :])

    poses_mat[0:3, 3::4] = positions_interp
    poses_mat[3, 3::4] = 1

    poses_mat = np.linalg.solve(poses_mat[0:4, 0:4], poses_mat)

    poses_out = [0] * (len(requested_timestamps) - 1)
    for i in range(1, len(requested_timestamps)):
        poses_out[i - 1] = poses_mat[0:4, i * 4:(i + 1) * 4]

    return poses_out


def check_interpolate_poses():
    from monoforce.vis import draw_coord_frame, draw_coord_frames
    from mayavi import mlab

    pose_timestamps = [0, 1, 2, 3, 4]
    pose0 = np.eye(4)
    abs_poses = []
    for i in range(len(pose_timestamps)):
        pose = pose0.copy()
        pose[0, 3] += i+1
        abs_poses.append(pose)

    requested_timestamps = [p + 0.5 for p in pose_timestamps[:-1]]
    origin_timestamp = 0

    interp_poses = interpolate_poses(pose_timestamps, abs_poses, requested_timestamps.copy(), origin_timestamp)
    print(interp_poses)

    abs_poses = np.asarray(abs_poses)
    interp_poses = np.asarray(interp_poses)

    poses = np.vstack((abs_poses, interp_poses))

    # visualize
    draw_coord_frames(poses)
    mlab.show()

    # plt.figure()
    # plt.plot(pose_timestamps, abs_poses[:, 0, 3], 'o', label='Pose timestamps')
    # plt.plot(requested_timestamps, poses[:, 0, 3], 'x', label='Interpolated poses')
    # plt.legend()
    # plt.show()


def main():
    # feed_data()
    # map_consistency()
    # data_slicing()
    # visualize_point_cloud_map()
    # create_global_gloud_map()
    check_interpolate_poses()


if __name__ == '__main__':
    main()
