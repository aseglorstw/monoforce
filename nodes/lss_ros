#!/usr/bin/env python

import os
from threading import RLock
import torch
import numpy as np
import rospy
from cv_bridge import CvBridge
from grid_map_msgs.msg import GridMap
from monoforce.config import Config
from monoforce.imgproc import standardize_img, undistort_image
from monoforce.models.lss.model import compile_model
from monoforce.models.lss.tools import img_transform
from monoforce.ros import height_map_to_point_cloud_msg, height_map_to_gridmap_msg
from monoforce.utils import normalize
from sensor_msgs.msg import Image, CompressedImage, PointCloud2, CameraInfo
import rospkg
from time import time
from message_filters import ApproximateTimeSynchronizer, Subscriber
import tf2_ros
from PIL import Image as PILImage
from ros_numpy import numpify


pkg_path = rospkg.RosPack().get_path('monoforce')
torch.set_default_dtype(torch.float32)


class LSS:
    def __init__(self, cfg: Config,
                 data_aug_conf: dict,
                 grid_conf: dict,
                 model_weights,
                 hm_frame='base_link',
                 img_topics=['/camera_front/color/image_raw/compressed',
                             '/camera_left/color/image_raw/compressed',
                             '/camera_right/color/image_raw/compressed',
                             '/camera_rear/color/image_raw/compressed'],
                 camera_info_topics=['/camera_front/color/camera_info',
                                     '/camera_left/color/camera_info',
                                     '/camera_right/color/camera_info',
                                     '/camera_rear/color/camera_info'],
                 img_mean=None,
                 img_std=None,
                 max_imgs_delay=0.1):
        self.cfg = cfg
        self.data_aug_conf = data_aug_conf
        self.grid_conf = grid_conf

        self.model = self.load_model(model_weights)

        self.hm_frame = hm_frame

        self.img_topics = img_topics
        self.camera_info_topics = camera_info_topics
        self.img_mean = img_mean
        self.img_std = img_std

        # cv bridge
        self.cv_bridge = CvBridge()
        # tf listener
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer)
        # height map publisher
        self.hm_img_pub = rospy.Publisher('/height_map/image', Image, queue_size=1)
        # point cloud publisher
        self.hm_cloud_pub = rospy.Publisher('/height_map/points', PointCloud2, queue_size=1)
        # grid map publisher
        self.hm_grid_pub = rospy.Publisher('/grid_map', GridMap, queue_size=1)

        # subscribe to camera intrinsics (ones)
        self.proc_lock = RLock()

        # subscribe to images with approximate time synchronization
        self.subs = []
        for topic in img_topics:
            rospy.loginfo('Subscribing to %s' % topic)
            self.subs.append(Subscriber(topic, CompressedImage))
        for topic in camera_info_topics:
            rospy.loginfo('Subscribing to %s' % topic)
            self.subs.append(Subscriber(topic, CameraInfo))
        self.sync = ApproximateTimeSynchronizer(self.subs, queue_size=1, slop=max_imgs_delay)
        self.sync.registerCallback(self.callback)

    def load_model(self, modelf):
        rospy.loginfo('Loading LSS model from %s' % modelf)
        model = compile_model(self.grid_conf, self.data_aug_conf, outC=1)
        model.load_state_dict(torch.load(modelf))
        model.to(self.cfg.device)
        model.eval()
        return model

    def preprocess_params(self):
        H, W = self.data_aug_conf['H'], self.data_aug_conf['W']
        fH, fW = self.data_aug_conf['final_dim']
        resize = max(fH/H, fW/W)
        resize_dims = (int(W*resize), int(H*resize))
        newW, newH = resize_dims
        crop_h = int((1 - np.mean(self.data_aug_conf['bot_pct_lim']))*newH) - fH
        crop_w = int(max(0, newW - fW) / 2)
        crop = (crop_w, crop_h, crop_w + fW, crop_h + fH)
        return resize, resize_dims, crop

    def preprocess_img(self, img):
        post_rot = torch.eye(2)
        post_tran = torch.zeros(2)

        # preprocessing parameters (resize, crop)
        resize, resize_dims, crop = self.preprocess_params()
        img, post_rot2, post_tran2 = img_transform(PILImage.fromarray(img), post_rot, post_tran,
                                                   resize=resize,
                                                   resize_dims=resize_dims,
                                                   crop=crop,
                                                   flip=False,
                                                   rotate=0)

        # for convenience, make augmentation matrices 3x3
        post_tran = torch.zeros(3, dtype=torch.float32)
        post_rot = torch.eye(3, dtype=torch.float32)
        post_tran[:2] = post_tran2
        post_rot[:2, :2] = post_rot2

        img = standardize_img(np.asarray(img), self.img_mean, self.img_std)
        img = torch.as_tensor(img, dtype=torch.float32).permute((2, 0, 1))

        return img, post_rot, post_tran

    def get_cam_calib(self, msg):
        """
        Get camera calibration parameters from CameraInfo message.
        :param msg: CameraInfo message
        :return: E - extrinsics (4x4),
                 K - intrinsics (3x3),
                 D - distortion coefficients (5,)
        """
        assert isinstance(msg, CameraInfo)

        time = rospy.Time(0)
        timeout = rospy.Duration.from_sec(1.0)
        try:
            tf = self.tf_buffer.lookup_transform(self.hm_frame, msg.header.frame_id, time, timeout)
        except tf2_ros.TransformException as ex:
            rospy.logerr('Could not transform from camera %s to robot %s: %s.',
                         msg.header.frame_id, self.hm_frame, ex)
            return

        E = np.array(numpify(tf.transform), dtype=np.float32).reshape((4, 4))
        # T_cor = np.array([[0, 0, 1, 0],
        #                   [-1, 0, 0, 0],
        #                   [0, -1, 0, 0],
        #                   [0, 0, 0, 1]], dtype=np.float32)
        # E = E @ T_cor
        K = np.array(msg.K, dtype=np.float32).reshape((3, 3))
        D = np.array(msg.D, dtype=np.float32)

        return E, K, D

    def callback(self, img_msg1, img_msg2, img_msg3, img_msg4, info_msg1, info_msg2, info_msg3, info_msg4):
        # if message is stale do not process it
        dt = rospy.Time.now() - img_msg1.header.stamp
        if dt > rospy.Duration(0.2):
            rospy.logdebug(f'Stale image messages received ({dt.to_sec():.1f} [sec]), skipping')
            return

        with torch.no_grad():
            with self.proc_lock:
                self.proc(img_msg1, img_msg2, img_msg3, img_msg4, info_msg1, info_msg2, info_msg3, info_msg4)

    def proc(self, img_msg1, img_msg2, img_msg3, img_msg4, info_msg1, info_msg2, info_msg3, info_msg4):
        # msgs = [img_msg1, img_msg2, img_msg3, img_msg4, info_msg1, info_msg2, info_msg3, info_msg4]
        # for msg in msgs:
        #     print(msg.header.frame_id)
        # print('---')
        assert isinstance(img_msg1, CompressedImage)
        assert isinstance(img_msg2, CompressedImage)
        assert isinstance(img_msg3, CompressedImage)
        assert isinstance(img_msg4, CompressedImage)
        assert isinstance(info_msg1, CameraInfo)
        assert isinstance(info_msg2, CameraInfo)
        assert isinstance(info_msg3, CameraInfo)
        assert isinstance(info_msg4, CameraInfo)
        assert img_msg1.header.frame_id == info_msg1.header.frame_id
        assert img_msg2.header.frame_id == info_msg2.header.frame_id
        assert img_msg3.header.frame_id == info_msg3.header.frame_id
        assert img_msg4.header.frame_id == info_msg4.header.frame_id

        img_msgs = [img_msg1, img_msg2, img_msg3, img_msg4]
        info_msgs = [info_msg1, info_msg2, info_msg3, info_msg4]

        imgs = []
        post_rots = []
        post_trans = []
        intriniscs = []
        cams_to_robot = []
        for img_msg, info_msg in zip(img_msgs, info_msgs):
            img = self.cv_bridge.compressed_imgmsg_to_cv2(img_msg)
            E, K, D = self.get_cam_calib(info_msg)
            img, K = undistort_image(img, K, D)
            img = img[..., (2, 1, 0)]  # BGR -> RGB

            img, post_rot, post_tran = self.preprocess_img(img)
            imgs.append(img)
            post_rots.append(post_rot)
            post_trans.append(post_tran)
            intriniscs.append(K)
            cams_to_robot.append(E)

        # to arrays
        imgs = np.stack(imgs)
        post_rots = np.stack(post_rots)
        post_trans = np.stack(post_trans)
        intrins = np.stack(intriniscs)
        cams_to_robot = np.stack(cams_to_robot)
        rots, trans = cams_to_robot[:, :3, :3], cams_to_robot[:, :3, 3]
        rospy.logdebug('Preprocessed image shape: %s' % str(imgs.shape))

        inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
        inputs = [torch.as_tensor(i[np.newaxis], device=self.cfg.device) for i in inputs]

        # model inference
        pred = self.model(*inputs)

        height = pred.squeeze().cpu().numpy()
        rospy.logdebug('Predicted height map shape: %s' % str(height.shape))
        rospy.logdebug('Height min: %.3f, max: %.3f' % (height.min(), height.max()))

        # publish height map as image
        stamp = rospy.Time.now()
        height_uint8 = np.asarray(255 * normalize(height), dtype='uint8')
        img_msg = self.cv_bridge.cv2_to_imgmsg(height_uint8, encoding='mono8')
        img_msg.header.stamp = stamp
        img_msg.header.frame_id = self.hm_frame
        self.hm_img_pub.publish(img_msg)

        # publish height map as point cloud
        t1 = time()
        cloud_msg = height_map_to_point_cloud_msg(height, self.cfg.grid_res,
                                                  xyz=np.array([0., 0., 0.]), q=np.array([0., 0., 0., 1.]))
        cloud_msg.header.stamp = stamp
        cloud_msg.header.frame_id = self.hm_frame
        self.hm_cloud_pub.publish(cloud_msg)

        # publish height map as grid map
        grid_msg = height_map_to_gridmap_msg(height, self.cfg.grid_res,
                                             xyz=np.array([0., 0., 0.]), q=np.array([0., 0., 0., 1.]))
        grid_msg.info.header.stamp = stamp
        grid_msg.info.header.frame_id = self.hm_frame
        self.hm_grid_pub.publish(grid_msg)
        rospy.logdebug('Height map publishing took %.3f' % (time() - t1))


def main():
    rospy.init_node('lss', anonymous=True, log_level=rospy.DEBUG)

    cfg = Config()
    cfg.d_min = 0.6
    cfg.d_max = 6.4
    cfg.grid_res = 0.1
    cfg.h_max = 0.3
    cfg.device = torch.device('cuda:0')

    grid_conf = {
        'xbound': [-cfg.d_max, cfg.d_max, cfg.grid_res],
        'ybound': [-cfg.d_max, cfg.d_max, cfg.grid_res],
        'zbound': [-10.0, 10.0, 20.0],
        'dbound': [cfg.d_min, cfg.d_max, cfg.grid_res],
    }

    data_aug_conf = {
        # 'resize_lim': (0.0, 0.0),
        'final_dim': (128, 352),
        'rot_lim': (0.0, 0.0),
        'H': 1200, 'W': 1920,
        # 'H': 1536, 'W': 2048,
        'rand_flip': False,
        'bot_pct_lim': (0.0, 0.0),
        'cams': ['CAM_FRONT', 'CAM_LEFT', 'CAM_RIGHT', 'CAM_REAR'],
        'Ncams': 4,
    }

    img_topics = rospy.get_param('~img_topics')
    camera_info_topics = rospy.get_param('~camera_info_topics')
    hm_frame = rospy.get_param('~hm_frame')
    # model weights
    model_weights = rospy.get_param('~model_weights', os.path.join(pkg_path, 'config/weights/lss/lss.pt'))

    try:
        node = LSS(cfg=cfg, data_aug_conf=data_aug_conf, grid_conf=grid_conf,
                   img_mean=np.array([0.44175903, 0.44948574, 0.45226233]),
                   img_std=np.array([0.25382164, 0.26486757, 0.2440394]),
                   model_weights=model_weights,
                   img_topics=img_topics, camera_info_topics=camera_info_topics,
                   hm_frame=hm_frame,
                   max_imgs_delay=rospy.get_param('~max_imgs_delay', 0.1)
                   )
        rospy.spin()
    except rospy.ROSInterruptException:
        pass


if __name__ == '__main__':
    main()
