#!/usr/bin/env python

import torch
import torch.optim as optim
import numpy as np
from monoforce.models import RigidBodySoftTerrain, State
from monoforce.datasets import DEMPathData, robingas_husky_seq_paths
from monoforce.config import Config
from monoforce.vis import setup_visualization, animate_trajectory, mlab_imshow, draw_coord_frames
from monoforce.losses import translation_difference, rotation_difference, total_variation, traj_dist
from monoforce.control import pose_control, cmd_vel_from_goal
from monoforce.transformations import rot2rpy
from mayavi import mlab
from scipy.spatial.transform import Rotation

torch.set_default_dtype(torch.float64)

cfg = Config()
cfg.grid_res = 0.2
cfg.d_max = 12.8
# cfg.device = 'cuda:0'
cfg.device = 'cpu'
cfg.lr = 0.03
cfg.total_sim_time = 10.0
cfg.n_samples = 100 * int(cfg.total_sim_time)
cfg.n_train_iters = 21
cfg.friction = 0.8
cfg.robot_mass = 10.
cfg.vel_tracks = 2. * np.array([1., 1.])
cfg.trans_cost_weight = 1.
cfg.rot_cost_weight = 1.


device = torch.device(cfg.device)


def get_data(i: int = None, vis=True, path=robingas_husky_seq_paths[0]):
    """
    Get ground truth data smple from the RobinGas dataset
    :param i: index of the sample
    :param vis: visualize the sample
    :param path: path to the dataset
    :return: states_true, tt_true, height
    """
    ds = DEMPathData(path, cfg=cfg)
    if i is None:
        i = np.random.choice(range(len(ds)))
    points, traj, heightmap = ds[i]
    poses = traj['poses']
    tstamps = traj['stamps']
    tstamps = tstamps - tstamps[0]
    height = heightmap['z']

    if vis:
        img = ds.get_raw_image(i)
        # mayavi show image, img is a numpy array
        mlab.figure(size=(img.shape[1], img.shape[0]), bgcolor=(1, 1, 1))
        mlab_imshow(np.rot90(img[..., (2, 1, 0)], axes=(1, 0)))
        # setup top-down view point
        mlab.view(azimuth=0, elevation=0)
        mlab.show()

    xyz_true = torch.as_tensor(poses[:, :3, 3])
    rot_true = torch.as_tensor(poses[:, :3, :3])

    n_true_states = len(xyz_true)
    tt_true = torch.tensor(tstamps)[None].T

    dps = torch.diff(xyz_true, dim=0)
    dt = torch.diff(tt_true, dim=0)
    theta_true = torch.atan2(dps[:, 1], dps[:, 0]).view(-1, 1)
    theta_true = torch.cat([theta_true[:1], theta_true], dim=0)

    vel_true = torch.zeros_like(xyz_true)
    vel_true[:-1] = dps / dt
    omega_true = torch.zeros_like(xyz_true)
    omega_true[:-1, 2:3] = torch.diff(theta_true, dim=0) / dt  # + torch.diff(angles_true, dim=0)[:, 2:3] / dt

    forces_true = torch.zeros((n_true_states, 3, 10))  # TODO: 10 is a hack, 10 is the number of contact points
    states_true = (xyz_true.view(-1, 3, 1),
                   rot_true.view(-1, 3, 3),
                   vel_true.view(-1, 3, 1),
                   omega_true.view(-1, 3, 1),
                   forces_true.view(-1, 3, 10))
    states_true = tuple([s.to(device) for s in states_true])

    return states_true, tt_true, height

def get_test_data(cfg: Config):
    """
    Generate simple ground truth data.
    returns: states_true, tt_true, height
    """
    xyz_true = torch.tensor([
        [-4., 0., 0.2],
        [-2., -0.5, 0.3],
        [0., -1, 0.5],
        [1., -0.2, 0.2],
        [2., -0.5, -0.1],
        [3., 0.5, -0.2],
        [4., 2., -0.3],
        [3.5, 3., -0.1],
        [3., 4., 0.2]
    ])
    angles_true = torch.as_tensor([
        [0., 0., 0.],
        [0., 0., -np.pi / 8.],
        [0., 0., np.pi / 4.],
        [0., 0., np.pi / 8.],
        [0., 0., 0.],
        [0., 0., np.pi / 4.],
        [0., 0., np.pi / 2.],
        [0., 0., 0.],
        [0., 0., -np.pi / 6.]
    ])
    headings = torch.atan2(xyz_true[1:, 1] - xyz_true[:-1, 1], xyz_true[1:, 0] - xyz_true[:-1, 0])
    angles_true[:-1, 2] = headings
    rot_true = torch.tensor(np.asarray([Rotation.from_euler('xyz', a).as_matrix() for a in angles_true]))
    h, w = int(2 * cfg.d_max // cfg.grid_res), int(2 * cfg.d_max // cfg.grid_res)
    height = np.zeros((h, w))

    n_true_states = len(xyz_true)
    tt_true = torch.linspace(0., cfg.total_sim_time, n_true_states)[None].T

    dps = torch.diff(xyz_true, dim=0)
    dt = torch.diff(tt_true, dim=0)
    theta_true = torch.atan2(dps[:, 1], dps[:, 0]).view(-1, 1)
    theta_true = torch.cat([theta_true[:1], theta_true], dim=0)

    vel_true = torch.zeros_like(xyz_true)
    vel_true[:-1] = dps / dt
    omega_true = torch.zeros_like(xyz_true)
    omega_true[:-1, 2:3] = torch.diff(theta_true, dim=0) / dt  # + torch.diff(angles_true, dim=0)[:, 2:3] / dt

    forces_true = torch.zeros((n_true_states, 3, 10))  # TODO: 10 is a hack, 10 is the number of contact points
    states_true = (xyz_true.view(-1, 3, 1),
                   rot_true.view(-1, 3, 3),
                   vel_true.view(-1, 3, 1),
                   omega_true.view(-1, 3, 1),
                   forces_true.view(-1, 3, 10))
    states_true = tuple([s.to(device) for s in states_true])

    return states_true, tt_true, height


def train_omni():
    """
    Learn terrain with omni-directional robot motion model.
    """

    """ Get ground truth data """
    # states_true, tt_true, height = get_data()
    states_true, tt_true, height = get_test_data(cfg)
    xyz_true, rot_true, vel_true, omega_true, forces_true = states_true
    n_true_states = len(xyz_true)

    """ Create robot-terrain interaction models """
    system = RigidBodySoftTerrain(height=height,
                                  grid_res=cfg.grid_res,
                                  friction=cfg.friction, mass=cfg.robot_mass,
                                  state=State(xyz=xyz_true[0] + torch.tensor([0., 0., 0.2]).view(xyz_true[0].shape),
                                              rot=rot_true[0],
                                              vel=vel_true[0],
                                              omega=omega_true[0],
                                              forces=forces_true[0]),
                                  device=cfg.device, use_ode=False,
                                  interaction_model='omni')

    # put models with their params to cfg.device
    system = system.to(device)
    tt = torch.linspace(0, cfg.total_sim_time, cfg.n_samples).to(device)
    s0 = system.state
    states = system.sim(s0, tt)

    """ Set-up visualization """
    vis_cfg = setup_visualization(system=system,
                                  states=states,
                                  states_true=states_true,
                                  cfg=cfg)
    # mlab.show()

    """ Navigation loop """
    optimizer = optim.Adam([{'params': system.height, 'lr': cfg.lr}])
    states_true = tuple([x.detach() for x in states_true])

    frame_n = 0
    for k in range(cfg.n_train_iters):
        optimizer.zero_grad()
        state = system.state.as_tuple()

        loss_sum = torch.tensor(0., device=cfg.device)
        loss_trans_sum = torch.tensor(0., device=cfg.device)
        loss_rot_sum = torch.tensor(0., device=cfg.device)
        states = []
        for i in range(n_true_states-1):
            # print('Going from pose %s -> to waypoint %s' % (state[0].squeeze(), xyz_true[i + 1].squeeze()))
            time_interval = tt[i * cfg.n_samples // (n_true_states - 1):(i+1) * cfg.n_samples // (n_true_states - 1)]
            states_interval = system.sim(state, time_interval)

            pos_x, pos_R, vel_x, vel_omega, forces = states_interval
            # update state
            state = (pos_x[-1].view(3, 1),
                     pos_R[-1].view(3, 3),
                     vel_true[i + 1].view(3, 1),
                     omega_true[i + 1].view(3, 1),
                     forces[-1])

            # compute loss
            loss_trans = translation_difference(pos_x[-1].view(1, 3, 1), states_true[0][i + 1].view(1, 3, 1))
            loss_rot = rotation_difference(pos_R[-1].view(1, 3, 3), states_true[1][i + 1].view(1, 3, 3))
            regularization = total_variation(system.height[None])

            loss_trans_sum += loss_trans
            loss_rot_sum += loss_rot
            loss_sum = loss_trans_sum + loss_rot_sum + 0.1*regularization

            states.append(states_interval)

        # visualize
        if True and k % 20 == 0:
            mlab.title("loss = {:.3f}".format(loss_sum.item()), size=0.5)
            pos_x = torch.cat([x[0] for x in states], dim=0)
            pos_R = torch.cat([x[1] for x in states], dim=0)
            vel_x = torch.cat([x[2] for x in states], dim=0)
            vel_omega = torch.cat([x[3] for x in states], dim=0)
            forces = torch.cat([x[4] for x in states], dim=0)

            system.update_trajectory(states=(pos_x, pos_R, vel_x, vel_omega, forces))
            frame_n = animate_trajectory(system, vis_cfg, frame_n=frame_n)

        loss_sum.backward()
        optimizer.step()
        print('Loss: %.3f (trans: %.3f, rot: %.3f)' % (loss_sum.item(), loss_trans_sum.item(), loss_rot_sum.item()))

    mlab.show()


def train_p_diffdrive(regularization=True, max_vel=np.inf, max_omega=np.inf, vis=True):
    """
    Learn terrain with diffdrive (X-linear, Z-angular velocity Proportional control) robot motion model.
    """

    """ Get ground truth data """
    # states_true, tt_true, height = get_data(i=0, vis=vis)
    states_true, tt_true, height = get_test_data(cfg)
    xyz_true, rot_true, vel_true, omega_true, forces_true = states_true
    n_true_states = len(xyz_true)
    height = np.zeros_like(height)

    """ Create robot-terrain interaction models """
    system = RigidBodySoftTerrain(height=height,
                                  grid_res=cfg.grid_res,
                                  friction=cfg.friction, mass=cfg.robot_mass,
                                  state=State(xyz=xyz_true[0] + torch.tensor([0., 0., 0.3]).view(xyz_true[0].shape),
                                              rot=rot_true[0],
                                              # vel=vel_true[0],
                                              # omega=omega_true[0],
                                              forces=forces_true[0]),
                                  device=cfg.device, use_ode=False,
                                  interaction_model='diffdrive')

    # put models with their params to cfg.device
    system = system.to(device)
    tt = torch.linspace(0, cfg.total_sim_time, cfg.n_samples).to(device)
    s0 = system.state
    states = system.sim(s0, tt)

    """ Set-up visualization """
    if vis:
        vis_cfg = setup_visualization(system=system,
                                      states=states,
                                      states_true=states_true,
                                      cfg=cfg)
    # mlab.show()

    """ Navigation loop """
    optimizer = optim.Adam([{'params': system.height, 'lr': cfg.lr}])
    states_true = tuple([x.detach() for x in states_true])

    frame_n = 0
    dt = (tt[1:] - tt[:-1]).mean()
    for k in range(cfg.n_train_iters):
        optimizer.zero_grad()
        state = system.state

        loss_trans_sum = torch.tensor(0., device=cfg.device)
        loss_rot_sum = torch.tensor(0., device=cfg.device)
        states = []
        poses_eval = []
        for i in range(n_true_states - 1):
            # print('Going from pose %s -> to waypoint %s' % (state[0].squeeze(), xyz_true[i + 1].squeeze()))
            time_interval = tt[i * cfg.n_samples // (n_true_states - 1):(i + 1) * cfg.n_samples // (n_true_states - 1)]

            pos_x, pos_R, vel_x, vel_omega, forces = state
            pos_x, pos_R, vel_x, vel_omega, forces = [pos_x], [pos_R], [vel_x], [vel_omega], [forces]
            for t in time_interval[1:]:
                goal_pose = torch.eye(4)
                goal_pose[:3, 3:4] = xyz_true[i + 1]
                goal_pose[:3, :3] = rot_true[i + 1]

                v, w = pose_control(state, goal_pose, allow_backwards=False,
                                    Kp_rho=1, Kp_theta=4., Kp_yaw=0.)

                v = torch.clip(v, -max_vel, max_vel)
                w = torch.clip(w, -max_omega, max_omega)
                state[2][0] = v
                state[3][2] = w

                dstate = system.forward(t, state)
                state = state.update(dstate, dt)

                pos_x.append(state[0])
                pos_R.append(state[1])
                vel_x.append(state[2])
                vel_omega.append(state[3])
                forces.append(state[4])

            states_interval = [torch.stack(pos_x), torch.stack(pos_R), torch.stack(vel_x), torch.stack(vel_omega), torch.stack(forces)]

            # poses at the end of the interval used for loss evaluation
            pose_eval = np.eye(4)
            pose_eval[:3, 3] = pos_x[-1].detach().squeeze().cpu().numpy()
            pose_eval[:3, :3] = pos_R[-1].detach().squeeze().cpu().numpy()
            poses_eval.append(pose_eval)

            # compute loss
            loss_trans = translation_difference(pos_x[-1].view(1, 3, 1), states_true[0][i + 1].view(1, 3, 1))
            loss_rot = rotation_difference(pos_R[-1].view(1, 3, 3), states_true[1][i + 1].view(1, 3, 3))

            loss_trans_sum += loss_trans
            loss_rot_sum += loss_rot

            states.append(states_interval)

        # concatenate states from all time intervals
        pos_x = torch.cat([x[0] for x in states], dim=0)
        pos_R = torch.cat([x[1] for x in states], dim=0)
        vel_x = torch.cat([x[2] for x in states], dim=0)
        vel_omega = torch.cat([x[3] for x in states], dim=0)
        forces = torch.cat([x[4] for x in states], dim=0)

        states = (pos_x, pos_R, vel_x, vel_omega, forces)
        # loss_sum = traj_dist(states, states_true)

        loss_rot_sum /= n_true_states
        loss_trans_sum /= n_true_states
        loss_sum = cfg.trans_cost_weight * loss_trans_sum + cfg.rot_cost_weight * loss_rot_sum
        if regularization:
            loss_sum += total_variation(system.height[None])

        # visualize
        if vis and k % 10 == 0:
            with torch.no_grad():
                system.update_trajectory(states=states)
                metric = traj_dist(states, states_true)

                # mlab.title("loss={:.3f} (traj dist={:.3f})".format(loss_sum.item(), metric.item()), size=0.5)
                # mlab.title("loss (trajectory difference)={:.3f}".format(loss_sum.item()), size=0.5)
                mlab.title("N iters: %d" % k, size=0.5)
                # draw_coord_frames(np.asarray(poses_eval), scale=0.2)
                frame_n = animate_trajectory(system, vis_cfg, frame_n=frame_n)

        loss_sum.backward()
        optimizer.step()

        print('Loss: %.3f (trans: %.3f, rot: %.3f)' % (loss_sum.item(), loss_trans_sum.item(), loss_rot_sum.item()))

    if vis:
        mlab.show()


def train_cmd_vel(regularization=True):
    """
    Learn terrain with diffdrive (X-linear, Z-angular velocity Proportional control) robot motion model.
    """

    """ Get ground truth data """
    states_true, tt_true, height = get_data(i=0)
    # sample_step = len(tt_true) // 4
    # states_true = [s[::sample_step] for s in states_true]
    # tt_true = tt_true[::sample_step]
    # states_true, tt_true, height = get_test_data()
    xyz_true, rot_true, vel_true, omega_true, forces_true = states_true
    n_true_states = len(xyz_true)

    """ Create robot-terrain interaction models """
    system = RigidBodySoftTerrain(height=height,
                                  grid_res=cfg.grid_res,
                                  friction=cfg.friction, mass=cfg.robot_mass,
                                  state=State(xyz=xyz_true[0] + torch.tensor([0., 0., 1.]).view(xyz_true[0].shape),
                                              rot=rot_true[0],
                                              vel=vel_true[0],
                                              omega=omega_true[0],
                                              forces=forces_true[0]),
                                  device=cfg.device, use_ode=False,
                                  interaction_model='diffdrive')

    # put models with their params to cfg.device
    system = system.to(device)
    tt = torch.linspace(0, cfg.total_sim_time, cfg.n_samples).to(device)
    s0 = system.state
    states = system.sim(s0, tt)

    """ Set-up visualization """
    vis_cfg = setup_visualization(system=system,
                                  states=states,
                                  states_true=states_true,
                                  cfg=cfg)
    # mlab.show()

    """ Navigation loop """
    optimizer = optim.Adam([{'params': system.height, 'lr': cfg.lr}])
    states_true = tuple([x.detach() for x in states_true])

    frame_n = 0
    dt = (tt[1:] - tt[:-1]).mean()
    for k in range(cfg.n_train_iters):
        optimizer.zero_grad()
        state = system.state

        loss_trans_sum = torch.tensor(0., device=cfg.device)
        loss_rot_sum = torch.tensor(0., device=cfg.device)

        states = []
        for i in range(n_true_states - 1):
            n_interval_samples = cfg.n_samples // (n_true_states - 1)
            time_interval = tt[i * n_interval_samples:(i + 1) * n_interval_samples]

            goal_state = State(xyz=xyz_true[i + 1],
                               rot=rot_true[i + 1],
                               vel=vel_true[i + 1],
                               omega=omega_true[i + 1])

            x, y, yaw = state[0][0], state[0][1], rot2rpy(state[1])[2]
            x_g, y_g = goal_state[0][:2]
            v, w = cmd_vel_from_goal(x, y, yaw, x_g, y_g, T=dt * n_interval_samples)
            v = torch.clamp(v, -cfg.max_vel, cfg.max_vel)
            w = torch.clamp(w, -cfg.max_omega, cfg.max_omega)

            state[2][0] = v
            state[3][2] = w

            states_interval = system.sim(state, time_interval)
            pos_x, pos_R, vel_x, vel_omega, forces = states_interval
            state = State(xyz=pos_x[-1],
                          rot=pos_R[-1],
                          vel=vel_x[-1],
                          omega=vel_omega[-1],
                          forces=forces[-1])
            # state[0][:2] = goal_state[0][:2]
            # state[1][:] = goal_state[1][:]
            # print('Reached waypoint with accuracy: %.2f [m]' % dist.item())

            states.append(states_interval)

            # compute loss
            loss_trans = translation_difference(pos_x[-1].view(1, 3, 1), states_true[0][i + 1].view(1, 3, 1))
            loss_rot = rotation_difference(pos_R[-1].view(1, 3, 3), states_true[1][i + 1].view(1, 3, 3))

            loss_trans_sum += loss_trans
            loss_rot_sum += loss_rot

        # concatenate states from all intervals
        pos_x = torch.cat([x[0] for x in states], dim=0)
        pos_R = torch.cat([x[1] for x in states], dim=0)
        vel_x = torch.cat([x[2] for x in states], dim=0)
        vel_omega = torch.cat([x[3] for x in states], dim=0)
        forces = torch.cat([x[4] for x in states], dim=0)
        states = (pos_x, pos_R, vel_x, vel_omega, forces)

        # compute loss
        # loss_rot_sum /= n_true_states
        # loss_trans_sum /= n_true_states
        # loss_sum = cfg.trans_cost_weight * loss_trans_sum +  cfg.rot_cost_weight * loss_rot_sum
        loss_sum = traj_dist(states, states_true, cfg=cfg)
        if regularization:
            loss_sum += total_variation(system.height[None])

        # visualize
        if True and k % 20 == 0:
            mlab.title("loss = {:.3f}".format(loss_sum.item()), size=0.5)

            system.update_trajectory(states=states)
            frame_n = animate_trajectory(system, vis_cfg, frame_n=frame_n)

        loss_sum.backward()
        optimizer.step()

        print('Loss: %.3f (trans: %.3f, rot: %.3f)' % (loss_sum.item(), loss_trans_sum.item(), loss_rot_sum.item()))

    mlab.show()


def train_p_track_vels(regularization=True, max_vel=np.inf, vis=True):
    """
    Learn terrain with Proportional control of robot position.
    Robot visits a set of waypoints.
    Robot is controlled via velocity commands transformed to it's tracks velocities.
    Robot-terrain interaction model is used, respecting height map properties like:
        - friction,
        - elasticity,
        - damping.
    """

    """ Get ground truth data """
    # states_true, tt_true, height = get_data(i=0)
    states_true, tt_true, height = get_test_data(cfg)
    xyz_true, rot_true, vel_true, omega_true, forces_true = states_true
    n_true_states = len(xyz_true)
    height = np.zeros_like(height)

    """ Create robot-terrain interaction models """
    system = RigidBodySoftTerrain(height=height,
                                  grid_res=cfg.grid_res,
                                  friction=cfg.friction, mass=cfg.robot_mass,
                                  state=State(xyz=xyz_true[0] + torch.tensor([0., 0., 1.]).view(xyz_true[0].shape),
                                              rot=rot_true[0],
                                              # vel=vel_true[0],
                                              # omega=omega_true[0],
                                              forces=forces_true[0]),
                                  device=cfg.device, use_ode=False,
                                  interaction_model='rigid_soft_layers')

    # put models with their params to cfg.device
    system = system.to(device)
    tt = torch.linspace(0, cfg.total_sim_time, cfg.n_samples).to(device)

    """ Set-up visualization """
    if vis:
        s0 = system.state
        states = system.sim(s0, tt)
        vis_cfg = setup_visualization(system=system,
                                      states=states,
                                      states_true=states_true,
                                      cfg=cfg)
    # mlab.show()

    """ Navigation loop """
    optimizer = optim.Adam([{'params': system.height, 'lr': cfg.lr},
                            {'params': system.friction, 'lr': cfg.lr},])
    states_true = tuple([x.detach() for x in states_true])

    frame_n = 0
    dt = (tt[1:] - tt[:-1]).mean()
    for k in range(cfg.n_train_iters):
        optimizer.zero_grad()
        state = system.state

        loss_trans_sum = torch.tensor(0., device=cfg.device)
        loss_rot_sum = torch.tensor(0., device=cfg.device)
        states = []
        tracks_distance = system.robot_points[1].max() - system.robot_points[1].min()

        for i in range(n_true_states - 1):
            # print('Going from pose %s -> to waypoint %s' % (state[0].squeeze(), xyz_true[i + 1].squeeze()))
            time_interval = tt[i * cfg.n_samples // (n_true_states - 1):(i + 1) * cfg.n_samples // (n_true_states - 1)]

            pos_x, pos_R, vel_x, vel_omega, forces = state
            pos_x, pos_R, vel_x, vel_omega, forces = [pos_x], [pos_R], [vel_x], [vel_omega], [forces]
            for t in time_interval[1:]:
                goal_pose = torch.eye(4)
                goal_pose[:3, 3:4] = xyz_true[i + 1]
                goal_pose[:3, :3] = rot_true[i + 1]

                v, w = pose_control(state, goal_pose, allow_backwards=True,
                                    Kp_rho=1.5, Kp_theta=20., Kp_yaw=0.2)

                # two tracks (flippers) robot model
                u1 = v - w * tracks_distance / 4.
                u2 = v + w * tracks_distance / 4.
                system.vel_tracks = torch.tensor([u1, u2])
                system.vel_tracks = torch.clip(system.vel_tracks, min=-max_vel, max=max_vel)

                dstate = system.forward(t, state)
                state = state.update(dstate, dt)

                pos_x.append(state[0])
                pos_R.append(state[1])
                vel_x.append(state[2])
                vel_omega.append(state[3])
                forces.append(state[4])

            states_interval = [torch.stack(pos_x), torch.stack(pos_R), torch.stack(vel_x), torch.stack(vel_omega), torch.stack(forces)]

            # compute loss
            loss_trans = translation_difference(pos_x[-1].view(1, 3, 1), states_true[0][i + 1].view(1, 3, 1))
            loss_rot = rotation_difference(pos_R[-1].view(1, 3, 3), states_true[1][i + 1].view(1, 3, 3))

            loss_trans_sum += loss_trans
            loss_rot_sum += loss_rot

            states.append(states_interval)

        loss_rot_sum /= n_true_states
        loss_trans_sum /= n_true_states
        loss_sum = loss_trans_sum + loss_rot_sum
        if regularization:
            loss_sum += 0.2 * total_variation(system.height[None])

        # visualize
        if vis and k % 10 == 0:
            mlab.title("loss = {:.3f}".format(loss_sum.item()), size=0.5)
            pos_x = torch.cat([x[0] for x in states], dim=0)
            pos_R = torch.cat([x[1] for x in states], dim=0)
            vel_x = torch.cat([x[2] for x in states], dim=0)
            vel_omega = torch.cat([x[3] for x in states], dim=0)
            forces = torch.cat([x[4] for x in states], dim=0)

            system.update_trajectory(states=(pos_x, pos_R, vel_x, vel_omega, forces))
            frame_n = animate_trajectory(system, vis_cfg, frame_n=frame_n)

        loss_sum.backward()
        optimizer.step()

        print('Loss: %.3f (trans: %.3f, rot: %.3f)' % (loss_sum.item(), loss_trans_sum.item(), loss_rot_sum.item()))

    if vis:
        mlab.show()


def main():
    # train_omni()
    train_p_diffdrive()
    # train_cmd_vel()
    # train_p_track_vels()


if __name__ == '__main__':
    main()
