#!/usr/bin/env python

import os
import numpy as np
from datetime import datetime
import torch
from torch.utils.data import DataLoader, ConcatDataset
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import matplotlib.pyplot as plt
from monoforce.datasets import MonoDemDataset
from monoforce.config import Config
from monoforce.models import monolayout
from monoforce.utils import normalize
from argparse import ArgumentParser


def str2bool(v):
    return v.lower() in ('1', 'yes', 'true', 't', 'y')

def parse_args():
    parser = ArgumentParser(description='Train Monolayout')
    parser.add_argument('--visualize', type=str2bool, default=False)
    parser.add_argument('--save', type=str2bool, default=True)
    parser.add_argument('--batch_size', type=int, default=16)
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--n_epochs', type=int, default=500)
    parser.add_argument('--img_size', type=int, default=512)
    parser.add_argument('--regularization', type=float, default=0.2)
    parser.add_argument('--weighted_loss', type=str2bool, default=False)
    return parser.parse_args()


class Trainer(object):
    def __init__(self, train_dataset, val_dataset, img_size=(512, 512),
                 batch_size=1, lr=1e-3,
                 regularization=None, weighted_loss=False,
                 pretrained_paths=None,
                 vis=False, save=True):
        self.train_ds = train_dataset
        self.val_ds = val_dataset
        self.train_dataloader = DataLoader(self.train_ds, batch_size=batch_size, shuffle=True)
        self.val_dataloader = DataLoader(self.val_ds, batch_size=batch_size, shuffle=False)
        self.regularization = regularization
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.img_size = img_size

        # models
        self.models = self.init_models(pretrained_paths=pretrained_paths)

        # optimizer
        self.parameters_to_train = []
        for key in self.models.keys():
            self.models[key].to(self.device)
            self.parameters_to_train += list(self.models[key].parameters())
        self.optimizer = torch.optim.Adam(params=self.parameters_to_train, lr=lr)

        self.weighted_loss = weighted_loss
        if self.weighted_loss:
            # no loss reduction to apply weights first: https://discuss.pytorch.org/t/how-to-weight-the-loss/66372/2
            self.loss_fn = torch.nn.MSELoss(reduction='none')
        else:
            self.loss_fn = torch.nn.MSELoss(reduction='mean')
        self.min_val_loss = np.inf
        self.min_train_loss = np.inf

        self.vis = vis
        self.save = save

        # logging: tensorboard and weights
        path = os.path.dirname(os.path.realpath(__file__))
        time_label = datetime.now().strftime("%Y_%m_%d-%H:%M:%S")
        self.writer = SummaryWriter(log_dir=os.path.join(path, '../config/tb_runs/monolayout/%s/' % time_label))
        self.weights_dir_path = os.path.join(path, '../config/weights/monolayout/%s/' % time_label)

    def init_models(self, pretrained_paths=None):
        assert isinstance(pretrained_paths, dict) or pretrained_paths is None
        models = {}
        models["encoder"] = monolayout.Encoder(num_layers=18, img_ht=self.img_size[0], img_wt=self.img_size[1], pretrained=True)
        models["decoder"] = monolayout.Decoder(models["encoder"].resnet_encoder.num_ch_enc)

        if pretrained_paths is not None:
            assert "encoder" in pretrained_paths.keys() and "decoder" in pretrained_paths.keys()
            print('Loading pretrained weights for encoder and decoder from:\n%s...' % pretrained_paths)

            encoder_dict = torch.load(pretrained_paths["encoder"], map_location=self.device)
            filtered_dict_enc = {k: v for k, v in encoder_dict.items() if k in models["encoder"].state_dict()}
            models["encoder"].load_state_dict(filtered_dict_enc)
            models["decoder"].load_state_dict(torch.load(pretrained_paths["decoder"], map_location=self.device))

        for key in models.keys():
            models[key].train()
            models[key].to(self.device)

        return models

    def visualize(self, img, height_label, height_pred, height_reg, weights_trav, weights_reg):
        plt.figure(figsize=(20, 5))
        plt.subplot(1, 5, 1)
        plt.title('Input Image')
        img_vis = img[0].cpu().numpy().transpose((1, 2, 0))
        # img_vis = self.val_ds.destandardize_img(img_vis)
        plt.imshow(img_vis)

        plt.subplot(1, 5, 2)
        plt.title('Height Label')
        plt.imshow(height_label[0].squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()
        plt.imshow(weights_trav[0].squeeze().cpu().numpy(), alpha=0.5, cmap='jet')

        plt.subplot(1, 5, 3)
        plt.title('Height Prediction')
        plt.imshow(height_pred[0].squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()

        plt.subplot(1, 5, 4)
        plt.title('Height Regularization')
        plt.imshow(height_reg[0].squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()

        plt.subplot(1, 5, 5)
        plt.title('Weights Regularization')
        plt.imshow(weights_reg[0].squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()

        plt.show()

    def epoch(self, dataloader, epoch_n, mode='train'):
        assert mode in ['train', 'val']

        loss_sum = torch.as_tensor(0.0, device=self.device)
        for i, batch in tqdm(enumerate(dataloader)):
            # get sample from data loader (front image, height map label and height map regularization)
            img, height_label, height_reg, weights_traversed, weights_reg = batch
            img = img.to(self.device)
            height_label = height_label.to(self.device)
            height_reg = height_reg.to(self.device)
            weights_traversed = weights_traversed.to(self.device)
            weights_reg = weights_reg.to(self.device)

            if torch.any(torch.isnan(height_label)):
                print('Warning: NaN values in height label (corrupted label)!')
                print('Skipping this batch...')
                continue

            if torch.any(torch.isnan(height_reg)) and self.regularization is not None:
                print('Warning: NaN values in height regularization (corrupted label)!')
                print('Skipping this batch...')
                continue

            # model inference
            features = self.models['encoder'](img)
            height_pred = self.models['decoder'](features, is_training=True)

            # loss is computed for the part of the predicted height map covered by robot's trajectory
            # assert torch.any(~torch.isnan(height_label))
            # assert torch.any(~torch.isnan(height_pred))
            if self.weighted_loss:
                loss = self.loss_fn(height_pred, height_label)
                loss = loss * weights_traversed
                loss = loss.sum() / (weights_traversed.sum() + 1e-6)
            else:
                loss = self.loss_fn(height_pred[weights_traversed], height_label[weights_traversed])
            # print('Loss: %f' % loss.item())
            self.writer.add_scalar('Loss(iter)/%s' % mode, loss.item(), i + epoch_n * len(dataloader))

            # add regularization loss
            if self.regularization is not None:
                # assert torch.any(~torch.isnan(height_reg))
                # assert torch.any(~torch.isnan(height_pred))
                if self.weighted_loss:
                    loss_reg = self.loss_fn(height_pred, height_reg)
                    loss_reg = loss_reg * weights_reg
                    loss_reg = loss_reg.sum() / (weights_reg.sum() + 1e-6)
                else:
                    loss_reg = self.loss_fn(height_pred, height_reg)

                # print('Loss reg: %f' % loss_reg.item())
                self.writer.add_scalar('Loss_reg(iter)/%s' % mode, loss_reg.item(), i + epoch_n * len(dataloader))
                loss += self.regularization * loss_reg

            if mode == 'train':
                # backpropagate gradients and update model params
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            loss_sum += loss

        loss_sum /= len(self.train_ds)
        
        # add input image to tensorboard logger
        self.writer.add_images(f'Input Image ({mode})', img, 0)
        # add predictions to tensorboard logger
        self.writer.add_images(f'Height Label ({mode})', normalize(height_label), 0)
        self.writer.add_images(f'Height Prediction ({mode})', normalize(height_pred), 0)
        self.writer.add_images(f'Height Regularization ({mode})', normalize(height_reg), 0)
        self.writer.add_images(f'Mask Traversed ({mode})', weights_traversed, 0)
        self.writer.add_images(f'Mask Regularization ({mode})', weights_reg, 0)

        # visualize
        if self.vis:
            self.visualize(img, height_label, height_pred, height_reg, weights_traversed, weights_reg)

        return loss_sum

    def train(self, n_epochs=1):
        for e in range(n_epochs):
            print('Training epoch %i...' % e)
            train_loss = self.epoch(dataloader=self.train_dataloader, epoch_n=e, mode='train')
            print('Validation epoch %i...' % e)
            with torch.no_grad():
                val_loss = self.epoch(dataloader=self.val_dataloader, epoch_n=e, mode='val')
            print('Train loss: %f' % train_loss.item())
            print('Val loss: %f' % val_loss.item())

            # log losses on the same plot
            self.writer.add_scalars('Loss(epoch)', {'train': train_loss.item(), 'val': val_loss.item()}, e)

            if self.save:
                # save better model
                if self.min_val_loss > val_loss:
                    self.min_val_loss = val_loss
                    print('Saving better val model...')
                    for key in self.models.keys():
                        os.makedirs(self.weights_dir_path, exist_ok=True)
                        torch.save(self.models[key].state_dict(), os.path.join(self.weights_dir_path, '%s_val.pth' % key))

                if self.min_train_loss > train_loss:
                    self.min_train_loss = train_loss
                    print('Saving better train model...')
                    for key in self.models.keys():
                        os.makedirs(self.weights_dir_path, exist_ok=True)
                        torch.save(self.models[key].state_dict(), os.path.join(self.weights_dir_path, '%s_train.pth' % key))
        else:
            print('Training finished!')
            # log training results: (write to file)
            with open(os.path.join(self.weights_dir_path, 'train_log.txt'), 'w') as f:
                # val loss
                f.write('Val loss: %f\n' % self.min_val_loss.item())
                # train loss
                f.write('Train loss: %f\n' % self.min_train_loss.item())

            # close tensorboard logger
            self.writer.close()

def main():
    args = parse_args()

    data_paths = [
        '../data/robingas/data/22-08-12-cimicky_haj/marv/ugv_2022-08-12-16-37-03_trav/',
        '../data/robingas/data/22-09-27-unhost/husky/husky_2022-09-27-15-01-44_trav/',
        '../data/robingas/data/22-09-27-unhost/husky/husky_2022-09-27-10-33-15_trav/',
        '../data/robingas/data/22-10-27-unhost-final-demo/husky_2022-10-27-15-33-57_trav/',
        '../data/robingas/data/22-08-12-cimicky_haj/marv/ugv_2022-08-12-15-18-34_trav/',
    ]

    # create dataset for MonoLayout training
    datasets = []
    img_size = (args.img_size, args.img_size)
    train_paths = data_paths[:-1]
    val_path = data_paths[-1]
    print('Train paths:', train_paths)
    print('Val path:', val_path)
    for path in train_paths:
        assert os.path.exists(path)

        cfg = Config()
        cfg.from_yaml(os.path.join(path, 'terrain', 'train_log', 'cfg.yaml'))
        cfg.hm_interp_method = 'nearest'

        # create dataset for MonoDEM training
        train_ds = MonoDemDataset(path, img_size=img_size, is_train=True, cfg=cfg)
        # print('Dataset size:', len(train_ds))

        if args.visualize:
            # visualize a data sample from the dataset
            for _ in range(1):
                i = np.random.choice(len(train_ds))
                train_ds.__getitem__(i, visualize=True)

        datasets.append(train_ds)
    train_ds = ConcatDataset(datasets)

    # create validation dataset
    cfg_val = Config()
    cfg_val.from_yaml(os.path.join(val_path, 'terrain', 'train_log', 'cfg.yaml'))
    cfg_val.hm_interp_method = 'nearest'
    val_ds = MonoDemDataset(val_path, img_size=img_size, is_train=False, cfg=cfg_val)

    # pretrained weights paths for MonoDEM (encoder and decoder)
    # pretrained_paths = {
    #     "encoder": "../config/weights/monolayout/encoder.pth",
    #     "decoder": "../config/weights/monolayout/decoder.pth",
    # }
    pretrained_paths = None

    # train_ds = torch.utils.data.Subset(train_ds, np.random.choice(len(train_ds), 32))
    # val_ds = torch.utils.data.Subset(val_ds, np.random.choice(len(val_ds), 16))
    print('Training dataset size:', len(train_ds))
    print('Validation dataset size:', len(val_ds))

    # MonoDEM Training
    trainer = Trainer(train_ds, val_ds,
                      img_size=img_size,
                      batch_size=args.batch_size, lr=args.lr,
                      regularization=args.regularization, weighted_loss=args.weighted_loss,
                      pretrained_paths=pretrained_paths,
                      vis=args.visualize, save=args.save)
    trainer.train(n_epochs=args.n_epochs)


if __name__ == '__main__':
    main()
