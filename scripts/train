#!/usr/bin/env python

import os
import torch
import numpy as np
from torch.utils.data import ConcatDataset, DataLoader, Subset
from monoforce.models.lss.utils import denormalize_img, ego_to_cam, get_only_in_img_mask
from monoforce.models.lss.model import compile_model
from monoforce.datasets import RobinGas, RobinGasVis
from monoforce.datasets.utils import explore_data
from monoforce.datasets import Rellis3D, Rellis3DVis
from monoforce.datasets import robingas_seq_paths, rellis3d_seq_paths
from monoforce.config import DPhysConfig
from monoforce.utils import read_yaml, write_to_yaml, str2bool
from tqdm import tqdm
from torch.utils.tensorboard import SummaryWriter
from datetime import datetime
import matplotlib.pyplot as plt
import argparse


np.random.seed(0)
torch.manual_seed(0)

def arg_parser():
    parser = argparse.ArgumentParser(description='Train LSS model')
    parser.add_argument('--bsz', type=int, default=1, help='Batch size')
    parser.add_argument('--nworkers', type=int, default=10, help='Number of workers for dataloaders')
    parser.add_argument('--nepochs', type=int, default=1000, help='Number of epochs')
    parser.add_argument('--lr', type=float, default=1e-3, help='Learning rate')
    parser.add_argument('--weight_decay', type=float, default=1e-7, help='Weight decay')
    # parser.add_argument('--dataset', type=str, default='rellis3d', help='Dataset name')
    parser.add_argument('--dataset', type=str, default='robingas', help='Dataset name')
    parser.add_argument('--robot', type=str, default='tradr', help='Dataset name')
    parser.add_argument('--dphys_cfg_path', type=str, default='../config/dphys_cfg.yaml', help='Path to DPhys config')
    parser.add_argument('--lss_cfg_path', type=str, default='../config/lss_cfg_tradr.yaml', help='Path to LSS config')
    parser.add_argument('--pretrained_model_path', type=str, default=None, help='Path to pretrained model')
    parser.add_argument('--debug', type=str2bool, default=False, help='Debug mode: use small datasets')
    parser.add_argument('--vis', type=str2bool, default=False, help='Visualize training samples')
    parser.add_argument('--only_front_hm', type=str2bool, default=False, help='Use only front heightmap')
    parser.add_argument('--geom_hm_weight', type=float, default=1.0, help='Weight for geometry heightmap loss')
    parser.add_argument('--terrain_hm_weight', type=float, default=100.0, help='Weight for terrain heightmap loss')
    parser.add_argument('--hdiff_weight', type=float, default=0.001, help='Weight for height difference loss')

    return parser.parse_args()


class Trainer:
    """
    Trainer for LSS terrain encoder model

    Args:
    dataset: str, dataset name
    robot: str, robot name
    dphys_cfg: DPhysConfig, physical robot-terrain interaction configuration
    lss_cfg: dict, LSS model configuration
    bsz: int, batch size
    nworkers: int, number of workers for dataloaders
    lr: float, learning rate
    weight_decay: float, weight decay
    nepochs: int, number of epochs
    pretrained_model_path: str, path to pretrained model
    log_dir: str, path to log directory
    debug: bool, debug mode: use small datasets
    vis: bool, visualize training samples
    geom_hm_weight: float, weight for geometry heightmap loss
    terrain_hm_weight: float, weight for terrain heightmap loss
    hdiff_weight: float, weight for height difference loss
    only_front_hm: bool, use only front heightmap part for training
    """

    def __init__(self,
                 dataset,
                 robot,
                 dphys_cfg,
                 lss_cfg,
                 bsz=1,
                 nworkers=10,
                 lr=1e-3,
                 weight_decay=1e-7,
                 nepochs=1000,
                 pretrained_model_path=None,
                 debug=False,
                 vis=False,
                 geom_hm_weight=1.0,
                 terrain_hm_weight=10.0,
                 hdiff_weight=0.001,
                 only_front_hm=False):

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.dataset = dataset
        assert dataset in ['rellis3d', 'robingas'], 'Unknown dataset: %s' % dataset
        self.robot = robot
        assert robot in ['husky', 'tradr', 'husky_oru'], 'Unknown robot: %s' % robot
        self.dphys_cfg = dphys_cfg
        self.lss_cfg = lss_cfg
        self.nepochs = nepochs

        self.min_loss = np.inf
        self.min_train_loss = np.inf
        self.train_counter = 0
        self.val_counter = 0

        self.geom_hm_weight = geom_hm_weight
        self.terrain_hm_weight = terrain_hm_weight
        self.hdiff_weight = hdiff_weight

        self.only_front_hm = only_front_hm

        self.train_loader, self.val_loader = self.create_dataloaders(bsz=bsz, nworkers=nworkers, debug=debug, vis=vis)
        self.model = self.load_model(modelf=pretrained_model_path)
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)
        self.loss_fn = torch.nn.MSELoss(reduction='none')

        self.log_dir = os.path.join('../config/tb_runs',
                                    f'lss_{dataset}_{robot}_{datetime.now().strftime("%Y_%m_%d_%H_%M_%S")}')

        self.writer = SummaryWriter(log_dir=self.log_dir)
        # save configs to log dir
        write_to_yaml(dphys_cfg.__dict__, os.path.join(self.log_dir, 'dphys_cfg.yaml'))
        write_to_yaml(lss_cfg, os.path.join(self.log_dir, 'lss_cfg.yaml'))

    def load_model(self, modelf=None):
        model = compile_model(self.lss_cfg['grid_conf'], self.lss_cfg['data_aug_conf'], outC=1)
        if modelf is not None:
            print('Loading pretrained LSS model from', modelf)
            model.load_state_dict(torch.load(modelf))
        model.to(self.device)
        model.train()
        return model

    def create_dataloaders(self, val_fraction=0.1, bsz=1, nworkers=1, debug=False, vis=False):
        # create dataset for LSS model training
        train_datasets = []
        val_datasets = []
        if self.dataset == 'rellis3d':
            Data = Rellis3D
            DataVis = Rellis3DVis
            data_paths = rellis3d_seq_paths
        elif self.dataset == 'robingas':
            Data = RobinGas
            DataVis = RobinGasVis
            data_paths = robingas_seq_paths[self.robot]
        else:
            raise ValueError(f'Unknown dataset: {self.dataset}. Supported datasets are rellis3d and robingas.')
        print('Data paths:', data_paths)
        for path in data_paths:
            assert os.path.exists(path)
            train_ds = Data(path, is_train=True, lss_cfg=self.lss_cfg, dphys_cfg=self.dphys_cfg, only_front_hm=self.only_front_hm)
            val_ds = Data(path, is_train=False, lss_cfg=self.lss_cfg, dphys_cfg=self.dphys_cfg, only_front_hm=self.only_front_hm)

            if vis:
                train_ds_vis = DataVis(path, is_train=True, lss_cfg=self.lss_cfg, dphys_cfg=self.dphys_cfg, only_front_hm=self.only_front_hm)
                explore_data(train_ds_vis)

            # randomly select a subset of the dataset
            val_ds_size = int(val_fraction * len(train_ds))
            val_ids = np.random.choice(len(train_ds), val_ds_size, replace=False)
            train_ids = np.setdiff1d(np.arange(len(train_ds)), val_ids)
            assert len(train_ids) + len(val_ids) == len(train_ds)
            # check that there is no overlap between train and val ids
            assert len(np.intersect1d(train_ids, val_ids)) == 0

            train_ds = train_ds[train_ids]
            val_ds = val_ds[val_ids]
            print(f'Train dataset from path {path} size is {len(train_ds)}')
            print(f'Validation dataset from path {path} size is {len(val_ds)}')

            train_datasets.append(train_ds)
            val_datasets.append(val_ds)

        # concatenate datasets
        train_dataset = ConcatDataset(train_datasets)
        val_dataset = ConcatDataset(val_datasets)
        if debug:
            print('Debug mode: using small datasets')
            train_dataset = Subset(train_dataset, np.random.choice(len(train_dataset), 32, replace=False))
            val_dataset = Subset(val_dataset, np.random.choice(len(val_dataset), 8, replace=False))
        print('Concatenated datasets length: train %i, valid: %i' % (len(train_dataset), len(val_dataset)))

        # create dataloaders
        train_loader = DataLoader(train_dataset, batch_size=bsz, shuffle=True, num_workers=nworkers)
        val_loader = DataLoader(val_dataset, batch_size=bsz, shuffle=False, num_workers=nworkers)

        return train_loader, val_loader

    def geom_hm_loss(self, height_pred, height_gt, weights=None):
        assert height_pred.shape == height_gt.shape, 'Height prediction and ground truth must have the same shape'
        if weights is None:
            weights = torch.ones_like(height_gt)
        assert weights.shape == height_gt.shape, 'Weights and height ground truth must have the same shape'

        # handle imbalanced height distribution (increase weights for higher heights / obstacles)
        h_mean = height_gt[weights.bool()].mean()
        # the higher the difference from mean the higher the weight
        weights_h = 1.0 + torch.abs(height_gt - h_mean)
        # apply height difference weights
        weights = weights * weights_h

        # compute weighted loss
        loss = (self.loss_fn(height_pred * weights, height_gt * weights)).mean()
        return loss

    def terrain_hm_loss(self, height_pred, height_gt, weights=None):
        assert height_pred.shape == height_gt.shape, 'Height prediction and ground truth must have the same shape'
        if weights is None:
            weights = torch.ones_like(height_gt)
        assert weights.shape == height_gt.shape, 'Weights and height ground truth must have the same shape'

        # mask of valid labels
        mask_valid = ~torch.isnan(height_gt)
        # apply mask
        height_gt = height_gt[mask_valid]
        height_pred = height_pred[mask_valid]
        weights = weights[mask_valid]

        # compute weighted loss
        loss = (self.loss_fn(height_pred * weights, height_gt * weights)).mean()
        return loss

    def epoch(self, train=True):
        loader = self.train_loader if train else self.val_loader
        counter = self.train_counter if train else self.val_counter

        if train:
            self.model.train()
        else:
            self.model.eval()

        max_grad_norm = 5.0
        epoch_loss = 0.0
        for batch in tqdm(loader, total=len(loader)):
            batch = [torch.as_tensor(b, dtype=torch.float32, device=self.device) for b in batch]
            imgs, rots, trans, intrins, post_rots, post_trans, hm_geom, hm_terrain = batch
            height_geom, weights_geom = hm_geom[:, 0:1], hm_geom[:, 1:2]
            height_terrain, weights_terrain = hm_terrain[:, 0:1], hm_terrain[:, 1:2]

            if train:
                self.optimizer.zero_grad()

            inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
            voxel_feats = self.model.get_voxels(*inputs)
            height_pred_geom, height_pred_diff = self.model.bevencode(voxel_feats)
            height_pred_terrain = height_pred_geom - height_pred_diff

            loss_geom = self.geom_hm_loss(height_pred_geom, height_geom, weights_geom)
            loss_terrain = self.terrain_hm_loss(height_pred_terrain, height_terrain, weights_terrain)

            # add height difference loss
            loss_hdiff = height_pred_diff.std()

            loss = self.geom_hm_weight * loss_geom + self.terrain_hm_weight * loss_terrain + self.hdiff_weight * loss_hdiff

            if train:
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_grad_norm)
                self.optimizer.step()
            epoch_loss += loss.item()

            counter += 1
            self.writer.add_scalar(f"{'train' if train else 'val'}/iter_loss_geom", loss_geom, counter)
            self.writer.add_scalar(f"{'train' if train else 'val'}/iter_loss_terrain", loss_terrain, counter)
            self.writer.add_scalar(f"{'train' if train else 'val'}/iter_loss_hdiff", loss_hdiff, counter)
            self.writer.add_scalar(f"{'train' if train else 'val'}/iter_loss", loss, counter)

        if len(loader) > 0:
            epoch_loss /= len(loader)

        return epoch_loss, counter

    def train(self):
        for e in range(self.nepochs):
            # training epoch
            train_loss, self.train_counter = self.epoch(train=True)
            print('Epoch:', e, 'Train loss:', train_loss)
            self.writer.add_scalar('train/epoch_loss', train_loss, e)

            if train_loss < self.min_train_loss:
                with torch.no_grad():
                    self.min_train_loss = train_loss
                    print('Saving train model...')
                    self.model.eval()
                    torch.save(self.model.state_dict(), os.path.join(self.log_dir, 'train_lss.pt'))

                    # visualize training predictions
                    fig = self.vis_pred(self.train_loader)
                    self.writer.add_figure('train/prediction', fig, e)

            # validation epoch
            with torch.no_grad():
                val_loss, self.val_counter = self.epoch(train=False)
                print('Epoch:', e, 'Validation loss:', val_loss)
                self.writer.add_scalar('val/epoch_loss', val_loss, e)
                if val_loss < self.min_loss:
                    self.min_loss = val_loss
                    print('Saving model...')
                    self.model.eval()
                    torch.save(self.model.state_dict(), os.path.join(self.log_dir, 'lss.pt'))

                    # visualize validation predictions
                    fig = self.vis_pred(self.val_loader)
                    self.writer.add_figure('val/prediction', fig, e)

    def vis_pred(self, loader):
        fig = plt.figure(figsize=(20, 12))
        ax1 = fig.add_subplot(341)
        ax2 = fig.add_subplot(342)
        ax3 = fig.add_subplot(343)
        ax4 = fig.add_subplot(344)
        ax5 = fig.add_subplot(345)
        ax6 = fig.add_subplot(346)
        ax7 = fig.add_subplot(347)
        ax8 = fig.add_subplot(348)
        ax9 = fig.add_subplot(349)

        axes = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9]
        for ax in axes:
            ax.clear()

        # visualize training predictions
        with torch.no_grad():
            imgs, rots, trans, intrins, post_rots, post_trans, hm_geom, hm_terrain = next(iter(loader))
            inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
            inputs = [torch.as_tensor(i, dtype=torch.float32, device=self.device) for i in inputs]
            voxel_feats = self.model.get_voxels(*inputs)
            height_pred_geom, height_pred_diff = self.model.bevencode(voxel_feats)
            height_pred_terrain = height_pred_geom - height_pred_diff

            batchi = 0
            height_pred_geom = height_pred_geom[batchi, 0].cpu()
            height_pred_terrain = height_pred_terrain[batchi, 0].cpu()
            height_pred_diff = height_pred_diff[batchi, 0].cpu()
            height_geom = hm_geom[batchi, 0].cpu()
            height_terrain = hm_terrain[batchi, 0].cpu()

            # get height map points
            z_grid = height_pred_terrain
            x_grid = torch.arange(-self.dphys_cfg.d_max, self.dphys_cfg.d_max, self.dphys_cfg.grid_res)
            y_grid = torch.arange(-self.dphys_cfg.d_max, self.dphys_cfg.d_max, self.dphys_cfg.grid_res)
            x_grid, y_grid = torch.meshgrid(x_grid, y_grid)
            hm_points = torch.stack([x_grid, y_grid, z_grid], dim=-1)
            hm_points = hm_points.view(-1, 3).T

            # plot images with projected height map points
            for imgi in range(imgs.shape[1])[:4]:
                ax = axes[imgi]
                img = imgs[batchi, imgi]
                img = denormalize_img(img)
                cam_pts = ego_to_cam(hm_points, rots[batchi, imgi], trans[batchi, imgi], intrins[batchi, imgi])
                img_H, img_W = self.lss_cfg['data_aug_conf']['H'], self.lss_cfg['data_aug_conf']['W']
                mask_img = get_only_in_img_mask(cam_pts, img_H, img_W)
                plot_pts = post_rots[batchi, imgi].matmul(cam_pts) + post_trans[batchi, imgi].unsqueeze(1)
                ax.imshow(img)
                ax.scatter(plot_pts[0, mask_img], plot_pts[1, mask_img], s=1, c=hm_points[2, mask_img],
                           cmap='jet', vmin=-1.0, vmax=1.0)
                ax.axis('off')

            ax5.set_title('Prediction: Geom')
            ax5.imshow(height_pred_geom.T, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            ax6.set_title('Label: Geom')
            ax6.imshow(height_geom.T, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            ax7.set_title('Prediction: Terrain')
            ax7.imshow(height_pred_terrain.T, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            ax8.set_title('Label: Terrain')
            ax8.imshow(height_terrain.T, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            ax9.set_title('Prediction: HM Diff')
            ax9.imshow(height_pred_diff.T, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            return fig


def main():
    args = arg_parser()
    print(args)

    # load configs: DPhys
    dphys_cfg = DPhysConfig()
    dphys_config_path = args.dphys_cfg_path
    assert os.path.isfile(dphys_config_path), 'Config file %s does not exist' % dphys_config_path
    dphys_cfg.from_yaml(dphys_config_path)
    # load configs: LSS
    lss_config_path = args.lss_cfg_path
    assert os.path.isfile(lss_config_path), 'LSS config file %s does not exist' % lss_config_path
    lss_cfg = read_yaml(lss_config_path)

    # create trainer
    trainer = Trainer(dataset=args.dataset, robot=args.robot,
                      dphys_cfg=dphys_cfg, lss_cfg=lss_cfg,
                      bsz=args.bsz, nworkers=args.nworkers, nepochs=args.nepochs,
                      lr=args.lr, weight_decay=args.weight_decay,
                      pretrained_model_path=args.pretrained_model_path,
                      geom_hm_weight=args.geom_hm_weight,
                      terrain_hm_weight=args.terrain_hm_weight,
                      hdiff_weight=args.hdiff_weight,
                      debug=args.debug, vis=args.vis,
                      only_front_hm=args.only_front_hm)
    trainer.train()


if __name__ == '__main__':
    main()
