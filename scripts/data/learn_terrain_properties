#!/usr/bin/env python

import torch
from torch import optim
import numpy as np
from monoforce.models import RigidBodySoftTerrain, State
from monoforce.losses import rotation_difference, translation_difference, total_variation, traj_dist
from monoforce.utils import read_yaml, str2bool
from monoforce.vis import setup_visualization, animate_trajectory, set_axes_equal
from monoforce.datasets.utils import visualize_data
from monoforce.datasets import RobinGas, robingas_husky_seq_paths
from monoforce.config import Config
from monoforce.control import pose_control
from mayavi import mlab
from matplotlib import pyplot as plt
import os
from copy import deepcopy
from tqdm import tqdm
from argparse import ArgumentParser
from torch.utils.tensorboard import SummaryWriter


def arg_parser():
    parser = ArgumentParser(epilog="""Path format uses following placeholders:
    """)
    parser.add_argument('--control-model', type=str, default='diffdrive')
    parser.add_argument('--visualize', type=str2bool, default=False)
    parser.add_argument('--save-data', type=str2bool, default=True)
    parser.add_argument('--data-path', type=str, default=robingas_husky_seq_paths[0])
    parser.add_argument('--vel-tracks', type=float, default=2.)
    parser.add_argument('--lr', type=float, default=0.02)
    parser.add_argument('--n-train-iters', type=int, default=100)
    parser.add_argument('--convergence-std', type=float, default=0.001)
    parser.add_argument('--convergence-n-samples', type=int, default=20)
    parser.add_argument('--hm-var-weight', type=float, default=1.)
    parser.add_argument('--device', type=str, default='cpu')
    return parser


class Learner:
    def __init__(self, data_path, cfg, data_aug_config,
                 vis=False, save_data=False,
                 convergence_std=0.001, convergence_n_samples=30,
                 lr=0.01, n_train_iters=100,
                 hm_var_weight=1.):
        self.data_path = data_path
        self.cfg = cfg
        self.data_aug_config = data_aug_config
        self.vis = vis
        self.save_data = save_data
        self.convergence_std = convergence_std
        self.convergence_n_samples = convergence_n_samples
        self.lr = lr
        self.n_train_iters = n_train_iters
        self.hm_var_weight = hm_var_weight
        self.output_path = os.path.join(self.data_path, 'terrain', 'traj', 'dphysics')
        self.tb_writer = SummaryWriter(log_dir=os.path.join(self.output_path, 'train_log'))

    def create_robot_terrain_interaction_system(self, height, states):
        system = RigidBodySoftTerrain(height=torch.zeros_like(height) + states[0][:, 2].min(),
                                      grid_res=self.cfg.grid_res,
                                      friction=self.cfg.friction, mass=self.cfg.robot_mass,
                                      state=State(
                                          xyz=states[0][0] + torch.tensor([0., 0., 1.], device=self.cfg.device).view(
                                              states[0][0].shape),
                                          rot=states[1][0],
                                          vel=states[2][0],
                                          omega=states[3][0],
                                          forces=states[4][0], device=self.cfg.device),
                                      device=self.cfg.device, use_ode=False,
                                      interaction_model=self.cfg.robot_terrain_interaction_model)
        return system

    def learn(self):
        ds = RobinGas(path=self.data_path, cfg=self.cfg, data_aug_conf=self.data_aug_config, is_train=False)
        for data_i in tqdm(range(len(ds)), desc='Learning terrain properties'):
            print('Processing %s data sample' % ds.ids[data_i])
            if os.path.exists(os.path.join(ds.path, 'terrain/', ds.ids[data_i] + '.npy')):
                print('Terrain properties already exist for this sample, skipping')
                continue

            states_true = ds.get_states_traj(data_i, start_from_zero=True)
            states_true = tuple([x.to(self.cfg.device) for x in states_true])

            hm_lidar = ds.get_lidar_height_map(data_i)
            height = hm_lidar[0]

            traj = ds.get_traj(data_i)
            img, _ = ds.get_image(data_i)

            if self.vis:
                visualize_data(height, traj, img=img, cfg=self.cfg)

            # create robot-terrain interaction model
            system = self.create_robot_terrain_interaction_system(height, states_true)
            system = system.to(self.cfg.device)

            t0, s0 = 0., system.state
            tt = torch.linspace(float(t0), float(t0) + self.cfg.total_sim_time, self.cfg.n_samples)
            states = system.sim(s0, tt)
            vis_cfg = setup_visualization(system=system, states=states, states_true=states_true,
                                          cfg=self.cfg) if self.vis else None

            # optimize terrain properties to fit the trajectory
            id = ds.ids[data_i]
            system_opt = self.optimize_terrain(system, states_true=states_true, tt=tt, vis_cfg=vis_cfg, id=id)
            if self.save_data:
                self.save_result(system_opt, id=id, cfg=self.cfg)

    def follow_trajectory(self, system, tt, states_true):
        state = system.state
        n_true_states = len(states_true[0])
        xyz_true, rot_true = states_true[0], states_true[1]
        dt = (tt[1:] - tt[:-1]).mean()

        loss_trans_sum = torch.tensor(0., device=self.cfg.device)
        loss_rot_sum = torch.tensor(0., device=self.cfg.device)
        states = []
        tracks_distance = system.robot_points[1].max() - system.robot_points[1].min()

        for i_s in range(n_true_states - 1):
            # print('Going from pose %s -> to waypoint %s' % (state[0].squeeze(), xyz_true[i_s + 1].squeeze()))
            time_interval = tt[i_s * self.cfg.n_samples // (n_true_states - 1):(i_s + 1) * self.cfg.n_samples // (
                    n_true_states - 1)]

            pos_x, pos_R, vel_x, vel_omega, forces = state
            pos_x, pos_R, vel_x, vel_omega, forces = [pos_x], [pos_R], [vel_x], [vel_omega], [forces]
            for t in time_interval[1:]:
                goal_pose = torch.eye(4)
                goal_pose[:3, 3:4] = xyz_true[i_s + 1]
                goal_pose[:3, :3] = rot_true[i_s + 1]

                v, w = pose_control(state, goal_pose, allow_backwards=True,
                                    Kp_rho=1.5, Kp_theta=20., Kp_yaw=0.5)

                if self.cfg.robot_terrain_interaction_model in ['rigid_layer', 'rigid_soft_layers']:
                    # two tracks (flippers) robot model
                    u1 = v - w * tracks_distance / 4.
                    u2 = v + w * tracks_distance / 4.
                    system.vel_tracks = torch.clip(torch.tensor([u1, u2]), min=-self.cfg.max_vel, max=self.cfg.max_vel)
                else:
                    v = torch.clip(torch.as_tensor(v), -self.cfg.max_vel, self.cfg.max_vel)
                    w = torch.clip(torch.as_tensor(w), -self.cfg.max_omega, self.cfg.max_omega)
                    state[2][0] = v
                    state[3][2] = w

                dstate = system.forward(t, state)
                state = state.update(dstate, dt)

                pos_x.append(state[0])
                pos_R.append(state[1])
                vel_x.append(state[2])
                vel_omega.append(state[3])
                forces.append(state[4])

            states_interval = [torch.stack(pos_x), torch.stack(pos_R), torch.stack(vel_x), torch.stack(vel_omega),
                               torch.stack(forces)]

            # compute loss
            loss_trans = translation_difference(pos_x[-1].view(1, 3, 1), states_true[0][i_s + 1].view(1, 3, 1))
            loss_rot = rotation_difference(pos_R[-1].view(1, 3, 3), states_true[1][i_s + 1].view(1, 3, 3))

            loss_trans_sum += loss_trans
            loss_rot_sum += loss_rot

            states.append(states_interval)

        # concatenate states from all time intervals
        pos_x = torch.cat([x[0] for x in states], dim=0)
        pos_R = torch.cat([x[1] for x in states], dim=0)
        vel_x = torch.cat([x[2] for x in states], dim=0)
        vel_omega = torch.cat([x[3] for x in states], dim=0)
        forces = torch.cat([x[4] for x in states], dim=0)
        states = (pos_x, pos_R, vel_x, vel_omega, forces)

        return states

    def optimize_terrain(self, system, states_true, tt, vis_cfg=None, id=None):
        if id is None:
            id = 0

        optimizer = optim.Adam([
            {'params': system.height, 'lr': self.cfg.lr},
            {'params': system.friction, 'lr': self.cfg.lr},
            {'params': system.elasticity, 'lr': self.cfg.lr},
            {'params': system.damping, 'lr': self.cfg.lr},
            # {'params': system.vel_tracks, 'lr': self.cfg.lr},
        ])

        system_best = None
        loss_min = np.inf
        frame_n = 0
        losses = []
        for i_n in tqdm(range(self.n_train_iters), desc='Optimizing terrain properties'):
            optimizer.zero_grad()
            states = self.follow_trajectory(system, tt, states_true)
            loss_tran, loss_rot = traj_dist(states, states_true, cfg=self.cfg, return_trans_and_rot=True)
            loss = loss_tran + loss_rot
            losses.append(loss.item())
            if self.hm_var_weight is not None:
                loss_reg = self.hm_var_weight * total_variation(system.height[None])
                loss += loss_reg
            else:
                loss_reg = torch.tensor(np.nan)
            loss.backward()
            optimizer.step()

            # tensorboard logging
            self.tb_writer.add_scalar(f'sample_{id}/loss/trans', loss_tran.item(), i_n)
            self.tb_writer.add_scalar(f'sample_{id}/loss/rot', loss_rot.item(), i_n)
            self.tb_writer.add_scalar(f'sample_{id}/loss/total', loss.item(), i_n)
            self.tb_writer.add_scalar(f'sample_{id}/loss/reg', loss_reg.item(), i_n)

            if system_best is None or loss.item() < loss_min:
                loss_min = loss.item()
                system.update_trajectory(states=states)
                system_best = deepcopy(system)

            # if converged: loss history does not change much, break
            if i_n > self.convergence_n_samples and np.std(losses[-self.convergence_n_samples:]) < self.convergence_std:
                print('Converged')
                break

            if self.vis and i_n % 10 == 0:
                system.update_trajectory(states=states)
                mlab.title("loss = {:.3f}".format(loss.item()), size=0.5)
                frame_n = animate_trajectory(system, vis_cfg, frame_n=frame_n)

        return system_best

    def save_result(self, system, id, cfg):
        # save resultant height map, friction, elasticity, damping as structured np array with corresponding field names
        height_init = system.height0.detach().cpu().numpy()
        height = system.height.detach().cpu().numpy()
        friction = system.friction.detach().cpu().numpy()
        elasticity = system.elasticity.detach().cpu().numpy()
        damping = system.damping.detach().cpu().numpy()
        result = np.zeros((height.shape[0], height.shape[1]), dtype=[('height_init', np.float32),
                                                                     ('height', np.float32),
                                                                     ('friction', np.float32),
                                                                     ('elasticity', np.float32),
                                                                     ('damping', np.float32)])
        result['height_init'] = height_init
        result['height'] = height
        result['friction'] = friction
        result['elasticity'] = elasticity
        result['damping'] = damping
        # save terrain properties array to file
        os.makedirs(self.output_path, exist_ok=True)
        output_name = '%s.npy' % id
        print('Saving result to %s' % os.path.join(self.output_path, output_name))
        np.save(os.path.join(self.output_path, output_name), result)

        # create a figure showing terrain properties
        fig, ax = plt.subplots(1, 5, figsize=(15, 3))
        ax[0].imshow(height, cmap='terrain')
        ax[0].set_title('Height map')
        ax[1].imshow(friction, cmap='terrain')
        ax[1].set_title('Friction')
        ax[2].imshow(elasticity, cmap='terrain')
        ax[2].set_title('Elasticity')
        ax[3].imshow(damping, cmap='terrain')
        ax[3].set_title('Damping')
        ax[4].imshow(height_init, cmap='terrain')
        ax[4].set_title('Initial height map')
        for a in ax:
            a.axis('off')
        plt.tight_layout()
        # tensorboard logging of the terrain properties figure
        self.tb_writer.add_figure('terrain_properties/%s' % id, fig)
        plt.close(fig)

        # save config in yaml file
        cfg.to_yaml(os.path.join(self.output_path, 'train_log', 'dphys_cfg.yaml'))
        return result


def main():
    args = arg_parser().parse_args()
    print(args)

    cfg = Config()
    cfg.from_yaml('../../config/dphys_cfg.yaml')
    cfg.vel_tracks = args.vel_tracks * np.asarray([1., 1.])
    cfg.robot_terrain_interaction_model = args.control_model
    cfg.device = args.device

    data_aug_conf = read_yaml('../../config/lss_cfg.yaml')['data_aug_conf']

    learner = Learner(data_path=args.data_path, cfg=cfg, data_aug_config=data_aug_conf,
                      vis=args.visualize, save_data=args.save_data,
                      convergence_std=args.convergence_std, convergence_n_samples=args.convergence_n_samples,
                      lr=args.lr, n_train_iters=args.n_train_iters)
    learner.learn()


if __name__ == '__main__':
    main()
