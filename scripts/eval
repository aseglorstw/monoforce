#!/usr/bin/env python

import os
from datetime import datetime
from typing import Union
import matplotlib.pyplot as plt
import matplotlib as mpl
from mayavi import mlab
from tqdm import tqdm
import numpy as np
import torch
from torch.utils.data import ConcatDataset
from torch.utils.tensorboard import SummaryWriter
from monoforce.models import RigidBodySoftTerrain, State
from monoforce.models.lss.utils import denormalize_img, ego_to_cam, get_only_in_img_mask
from monoforce.models.lss.model import compile_model
from monoforce.datasets.robingas import RobinGasVis
from monoforce.datasets.rellis3d import Rellis3DVis
from monoforce.config import DPhysConfig
from monoforce.cloudproc import estimate_heightmap
from monoforce.datasets import rellis3d_seq_paths, robingas_seq_paths
from monoforce.utils import read_yaml, position
from monoforce.control import pose_control
from monoforce.losses import translation_difference, rotation_difference
from monoforce.transformations import rot2rpy
from monoforce.vis import animate_trajectory, setup_visualization, show_cloud


date = datetime.now().strftime("%Y_%m_%d_%H_%M_%S")

class EvaluatorGeom:
    def __init__(self, dphys_config_path, lss_config_path, dataset, robot='tradr', model_path=None):
        self.model_path = model_path
        assert model_path is None or os.path.isfile(model_path), 'Model file %s does not exist' % model_path
        self.config_path = dphys_config_path
        assert os.path.isfile(dphys_config_path), 'Config file %s does not exist' % dphys_config_path
        self.lss_config_path = lss_config_path
        assert os.path.isfile(lss_config_path), 'LSS config file %s does not exist' % lss_config_path
        self.dataset = dataset
        if dataset == 'robingas':
            self.data_paths = robingas_seq_paths[robot]
            self.DataClass = RobinGasVis
        elif dataset == 'rellis3d':
            self.data_paths = rellis3d_seq_paths
            self.DataClass = Rellis3DVis
        else:
            raise ValueError('Invalid dataset %s. Supported: rellis3d and robingas' % dataset)
        self.dphys_cfg = DPhysConfig()
        self.dphys_cfg.from_yaml(dphys_config_path)
        self.lss_cfg = read_yaml(lss_config_path)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = self.load_model()
        self.loss_fn = torch.nn.MSELoss()
        self.metrics = {'trans_diff': [],
                        'rot_diff': []}
        self.log_dir = os.path.join('../config/tb_runs',
                                    f'eval_{dataset}_{date}',
                                    self.__class__.__name__)
        self.writer = SummaryWriter(log_dir=self.log_dir)

    def load_model(self):
        return None

    def quantitative_evaluation(self, paths=None, sample_ranges=None, save=False):
        if paths is None:
            paths = [self.data_paths[0]]
        if sample_ranges is None:
            sample_ranges = [[0]] * len(paths)
        assert len(paths) == len(sample_ranges)

        for path, sample_range in zip(paths, sample_ranges):
            self.hm_to_imgs_projection(path, sample_range, save=save, dt=5)

    def hm_to_imgs_projection(self, seq_path=None, sample_range=None, save=False, dt=1):
        if seq_path is None:
            seq_path = self.data_paths[0]

        ds = self.DataClass(seq_path, is_train=False, data_aug_conf=self.lss_cfg['data_aug_conf'], dphys_cfg=self.dphys_cfg)
        if sample_range is None:
            sample_range = range(len(ds))

        fig = plt.figure(figsize=(20, 10))
        gs = mpl.gridspec.GridSpec(3, 6)
        gs.update(wspace=0.0, hspace=0.0, left=0.0, right=1.0, top=1.0, bottom=0.0)
        for i in tqdm(sample_range, total=len(sample_range)):
            # clear grid axes
            plt.clf()

            imgs, rots, trans, intrins, post_rots, post_trans, hm_geom, hm_terrain, lidar_pts = ds[i]
            height = self.get_height(i, ds)

            # create height map grid
            z_grid = height
            x_grid = torch.arange(-self.dphys_cfg.d_max, self.dphys_cfg.d_max, self.dphys_cfg.grid_res)
            y_grid = torch.arange(-self.dphys_cfg.d_max, self.dphys_cfg.d_max, self.dphys_cfg.grid_res)
            x_grid, y_grid = torch.meshgrid(x_grid, y_grid)
            hm_points = torch.stack([x_grid, y_grid, z_grid], dim=-1)
            hm_points = hm_points.view(-1, 3).T

            # plot images and height map points
            for img_gs_ids, imgi in zip([(1, 2), (0, 1), (1, 0), (2, 1)], range(len(imgs))):
                grid_i, grid_j = img_gs_ids
                ax = plt.subplot(gs[grid_i, grid_j])
                img = imgs[imgi]
                img = denormalize_img(img)
                # project height map points to image
                ego_pts = ego_to_cam(hm_points, rots[imgi], trans[imgi], intrins[imgi])
                img_H, img_W = self.lss_cfg['data_aug_conf']['H'], self.lss_cfg['data_aug_conf']['W']
                mask = get_only_in_img_mask(ego_pts, img_H, img_W)
                plot_pts = post_rots[imgi].matmul(ego_pts) + post_trans[imgi].unsqueeze(1)
                ax.imshow(img)
                ax.scatter(plot_pts[0, mask], plot_pts[1, mask], s=0.5, c=hm_points[2, mask],
                           cmap='jet', vmin=-1.0, vmax=1.0)
                ax.axis('off')

            # plot prediction as image
            ax = plt.subplot(gs[1, 1])
            ax.imshow(z_grid.T, cmap='jet', vmin=-1.0, vmax=1.0, origin='lower')

            # plot prediction as surface
            ax = plt.subplot(gs[:, 3:6], projection='3d')
            ax.plot_surface(x_grid, y_grid, z_grid, cmap='jet', vmin=-1.0, vmax=1.0)
            ax.set_zlim(-2.0, 2.0)
            # set up view
            ax.view_init(elev=60., azim=-80.)
            ax.set_xlabel('x [m]')
            ax.set_ylabel('y [m]')
            ax.set_zlabel('z [m]')

            if save:
                plt.savefig(f'{self}_hm_projection_{i}.png')
            else:
                plt.pause(dt)
                plt.draw()

    def compute_losses(self, batch):
        imgs, rots, trans, intrins, post_rots, post_trans, hm_geom, hm_terrain, lidar_pts = batch
        height_geom, weights_geom = hm_geom[:, 0:1], hm_geom[:, 1:2]
        height_terrain, weights_terrain = hm_terrain[:, 0:1], hm_terrain[:, 1:2]

        loss_geom = self.loss_fn(height_geom[weights_geom.bool()], height_geom[weights_geom.bool()])
        loss_rigid = self.loss_fn(height_geom[weights_terrain.bool()], height_terrain[weights_terrain.bool()])

        return loss_geom, loss_rigid

    def eval_terrain_encoder(self, bsz=1, nworkers=10):
        all_seqs_mean_geom_loss, all_seqs_mean_rigid_loss = 0.0, 0.0
        for path in self.data_paths:
            print(f'Evaluation on {os.path.basename(path)}...')

            val_ds = self.DataClass(path, is_train=False, lss_cfg=self.lss_cfg, dphys_cfg=self.dphys_cfg)
            valloader = torch.utils.data.DataLoader(val_ds, batch_size=bsz, shuffle=False, num_workers=nworkers)

            # validation epoch
            eval_geom_loss, eval_rigid_loss = 0.0, 0.0
            for batch in tqdm(valloader, total=len(valloader)):
                loss_geom, loss_rigid = self.compute_losses(batch)
                eval_geom_loss += loss_geom
                eval_rigid_loss += loss_rigid
            eval_geom_loss /= len(valloader)
            eval_rigid_loss /= len(valloader)

            print(f'For seq {os.path.basename(path)} mean geom loss: {eval_geom_loss:.3f}, '
                  f'mean rigid loss: {eval_rigid_loss:.3f}')
            all_seqs_mean_geom_loss += eval_geom_loss
            all_seqs_mean_rigid_loss += eval_rigid_loss
        all_seqs_mean_geom_loss /= len(self.data_paths)
        all_seqs_mean_rigid_loss /= len(self.data_paths)
        print(f'Average evaluation geom loss: {all_seqs_mean_geom_loss:.3f}, '
              f'average evaluation rigid loss: {all_seqs_mean_rigid_loss:.3f}')

        return all_seqs_mean_geom_loss, all_seqs_mean_rigid_loss

    def get_states(self, i: int, ds: Union[RobinGasVis, Rellis3DVis]):
        id = ds.ids[i] if self.dataset == 'rellis3d' else i
        states = ds.get_states_traj(id, start_from_zero=True)
        return states

    def get_height(self, i: int, ds: Union[RobinGasVis, Rellis3DVis]):
        id = ds.ids[i] if self.dataset == 'rellis3d' else i
        hm_geom = ds.get_geom_height_map(id)
        height = hm_geom[0]
        return height

    def get_data(self, i: int, ds: Union[RobinGasVis, Rellis3DVis]):
        """
        Get ground truth data sample from the dataset

        :param i: index of the sample
        :param ds: dataset of type TravDataVis

        :return: states, height
        """
        assert i < len(ds), 'Index out of range'
        assert isinstance(ds, self.DataClass), 'Invalid dataset type'

        # get states
        states = self.get_states(i, ds)

        # get height map
        height = self.get_height(i, ds)

        # evaluate the states that are inside the height map
        xyz = states[0]
        mask = (xyz[:, 0] > -self.dphys_cfg.d_max) & (xyz[:, 0] < self.dphys_cfg.d_max) & \
               (xyz[:, 1] > -self.dphys_cfg.d_max) & (xyz[:, 1] < self.dphys_cfg.d_max)
        mask = mask.view(-1)
        states = tuple([s[mask] for s in states])

        return states, height

    def eval_diff_physics(self, height, states_true, vis=False):
        """
        Simulate the system with P control.
        Robot visits a set of waypoints.
        Diff-drive (controlled with X-linear and Z-angular velocities) robot motion model is used.
        """
        height = torch.as_tensor(height, device=self.device)
        states_true = tuple([s.to(self.device) for s in states_true])
        xyz_true, rot_true, vel_true, omega_true, forces_true = states_true
        n_true_states = len(xyz_true)

        if n_true_states < 2:
            print('Not enough waypoints to evaluate')
            return None, None

        """ Create robot-terrain interaction models """
        system = RigidBodySoftTerrain(height=height,
                                      grid_res=self.dphys_cfg.grid_res,
                                      friction=self.dphys_cfg.friction, mass=self.dphys_cfg.robot_mass,
                                      state=State(
                                          xyz=xyz_true[0] + torch.tensor([0., 0., 1.],
                                                                         device=self.device).view(xyz_true[0].shape),
                                          rot=rot_true[0],
                                          vel=vel_true[0],
                                          omega=omega_true[0],
                                          device=self.device),
                                      device=self.device, use_ode=False,
                                      interaction_model='diffdrive')

        # put models with their params to self.cfg.device
        system = system.to(self.device)
        s0 = system.state
        tt = torch.linspace(0, self.dphys_cfg.total_sim_time, self.dphys_cfg.n_samples).to(self.device)

        if vis:
            states = system.sim(s0, tt)
            """ Set-up visualization """
            vis_cfg = setup_visualization(system=system,
                                          states=states,
                                          states_true=states_true,
                                          cfg=self.dphys_cfg)

        """ Navigation loop """
        state = system.state
        states = []
        dt = (tt[1:] - tt[:-1]).mean()
        loss_trans_sum = torch.tensor(0., device=self.device)
        loss_rot_sum = torch.tensor(0., device=self.device)
        poses_eval = []
        for i in range(n_true_states - 1):
            # print('Going from pose %s -> to waypoint %s' % (state[0].squeeze(), xyz_true[i + 1].squeeze()))
            time_interval = tt[i * self.dphys_cfg.n_samples // (n_true_states - 1):(i + 1) * self.dphys_cfg.n_samples // (
                        n_true_states - 1)]

            pos_x, pos_R, vel_x, vel_omega, forces = state
            pos_x, pos_R, vel_x, vel_omega, forces = [pos_x], [pos_R], [vel_x], [vel_omega], [forces]

            roll, pitch, yaw = rot2rpy(pos_R[-1].squeeze())

            if torch.abs(roll) > np.pi / 2. or torch.abs(pitch) > np.pi / 2.:
                # print('Robot is upside down')
                return None, None

            goal_pose = torch.eye(4, device=self.device)
            goal_pose[:3, 3:4] = xyz_true[i + 1]
            goal_pose[:3, :3] = rot_true[i + 1]

            for t in time_interval[1:]:
                v, w = pose_control(state, goal_pose, allow_backwards=True,
                                    Kp_rho=2., Kp_theta=4., Kp_yaw=4., dist_reached=0.01)
                state[2][0] = v
                state[3][2] = w

                dstate = system.forward(t, state)
                state = state.update(dstate, dt)

                pos_x.append(state[0])
                pos_R.append(state[1])
                vel_x.append(state[2])
                vel_omega.append(state[3])
                forces.append(state[4])
            # print('Reached waypoint with accuracy: %.2f [m]' % dist.item())

            states_interval = [torch.stack(pos_x), torch.stack(pos_R), torch.stack(vel_x), torch.stack(vel_omega),
                               torch.stack(forces)]
            states.append(states_interval)

            # compute loss
            loss_trans = translation_difference(pos_x[-1].view(1, 3, 1), states_true[0][i + 1].view(1, 3, 1))
            loss_rot = rotation_difference(pos_R[-1].view(1, 3, 3), states_true[1][i + 1].view(1, 3, 3))

            loss_trans_sum += loss_trans
            loss_rot_sum += loss_rot

            # log poses at the end of each interval for which we compute loss
            pose_eval = torch.eye(4)
            pose_eval[:3, 3:4] = pos_x[-1].view(3, 1)
            pose_eval[:3, :3] = pos_R[-1].view(3, 3)
            poses_eval.append(pose_eval)

        pos_x = torch.cat([x[0] for x in states], dim=0)
        pos_R = torch.cat([x[1] for x in states], dim=0)
        vel_x = torch.cat([x[2] for x in states], dim=0)
        vel_omega = torch.cat([x[3] for x in states], dim=0)
        forces = torch.cat([x[4] for x in states], dim=0)

        states = (pos_x, pos_R, vel_x, vel_omega, forces)

        loss_trans_sum /= (n_true_states - 1)
        loss_rot_sum /= (n_true_states - 1)

        # visualize trajectory
        if vis:
            system.update_trajectory(states=states)
            # draw_coord_frames(torch.stack(poses_eval).cpu().numpy(), scale=0.1)
            animate_trajectory(system, vis_cfg)
            mlab.show()

        return loss_trans_sum, loss_rot_sum

    def evaluate(self, vis=False, debug=False):
        for path in self.data_paths:
            print(f'Evaluation on {os.path.basename(path)}...')
            ds = self.DataClass(path, is_train=False, lss_cfg=self.lss_cfg, dphys_cfg=self.dphys_cfg)
            if debug:
                np.random.seed(0)
                ds = ds[np.random.choice(len(ds), 5)]
            for i in tqdm(range(len(ds))):
                states_true, height = self.get_data(i, ds)
                trans_diff, rot_diff = self.eval_diff_physics(height, states_true, vis=vis)
                if rot_diff is not None:
                    self.metrics['trans_diff'].append(trans_diff.item())
                    self.metrics['rot_diff'].append(rot_diff.item())
                    # log to tensorboard
                    self.writer.add_scalar(f'{os.path.basename(path)}/trans_diff', trans_diff, i)
                    self.writer.add_scalar(f'{os.path.basename(path)}/rot_diff', rot_diff, i)

        trans_diff_final = np.mean(self.metrics['trans_diff'])
        rot_diff_final = np.mean(self.metrics['rot_diff'])
        print(f'Average loss translation: %.2f [m]' % trans_diff_final)
        print(f'Average loss rotation: %.2f [deg]' % (rot_diff_final * 180 / np.pi))

        # write to file
        fname = f'eval_metrics_{self.__class__.__name__}.csv'
        data = [['ATE [m]', 'ARE [deg]'],
                [trans_diff_final, rot_diff_final * 180 / np.pi]]
        with open(fname, 'w') as f:
            for line in data:
                f.write(','.join([str(x) for x in line]) + '\n')

    def __str__(self):
        return f'Evaluator: {self.__class__.__name__} with the Model: {self.model.__class__.__name__}'

class EvaluatorLSS(EvaluatorGeom):
    def __init__(self, dphys_config_path, lss_config_path, dataset, robot, model_path):
        super().__init__(dphys_config_path, lss_config_path, dataset, robot, model_path)

    def load_model(self):
        print('Loading LSS model')
        model = compile_model(self.lss_cfg['grid_conf'], self.lss_cfg['data_aug_conf'], outC=1)
        print('Loading', self.model_path)
        model.load_state_dict(torch.load(self.model_path))
        model.eval()
        model.to(self.device)
        return model

    def get_height(self, i: int, ds: Union[RobinGasVis, Rellis3DVis]):
        sample = ds[i]
        imgs, rots, trans, intrins, post_rots, post_trans, hm_geom, hm_terrain, lidar_pts = sample
        inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
        inputs = [torch.as_tensor(i[None], device=self.device) for i in inputs]
        height_pred = self.model(*inputs)
        height = height_pred.squeeze().cpu()
        return height

    def compute_losses(self, batch):
        batch = [torch.as_tensor(b, device=self.device) for b in batch]
        imgs, rots, trans, intrins, post_rots, post_trans, hm_geom, hm_terrain, lidar_pts = batch
        height_geom, weights_geom = hm_geom[:, 0:1], hm_geom[:, 1:2]
        height_terrain, weights_terrain = hm_terrain[:, 0:1], hm_terrain[:, 1:2]
        inputs = [imgs, rots, trans, intrins, post_rots, post_trans]

        # compute loss
        voxel_feats = self.model.get_voxels(*inputs)
        height_pred_geom, height_pred_diff = self.model.bevencode(voxel_feats)
        height_pred_rigid = height_pred_geom - height_pred_diff

        loss_geom = self.loss_fn(height_pred_geom[weights_geom.bool()], height_geom[weights_geom.bool()])
        loss_rigid = self.loss_fn(height_pred_rigid[weights_terrain.bool()], height_terrain[weights_terrain.bool()])
        return loss_geom, loss_rigid


class EvaluatorLSSGeom(EvaluatorLSS):
    def __init__(self, dphys_config_path, lss_config_path, dataset, robot, model_path):
        super().__init__(dphys_config_path, lss_config_path, dataset, robot, model_path)

    def get_height(self, i: int, ds: Union[RobinGasVis, Rellis3DVis]):
        sample = ds[i]
        imgs, rots, trans, intrins, post_rots, post_trans, hm_geom, hm_terrain, lidar_pts = sample
        inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
        inputs = [torch.as_tensor(i[None], device=self.device) for i in inputs]
        voxel_feats = self.model.get_voxels(*inputs)
        height_pred_geom, _ = self.model.bevencode(voxel_feats)
        height = height_pred_geom.squeeze().cpu()
        return height


class EvaluatorKKT(EvaluatorGeom):
    def __init__(self, dphys_config_path, lss_config_path, dataset, robot, model_path):
        super().__init__(dphys_config_path, lss_config_path, dataset, robot, model_path)

    def load_model(self):
        print('Loading KKT model')
        import sys
        sys.path.append('../../pose-consistency-KKT-loss/scripts/')
        import network_s2d
        model = network_s2d.Net()
        model.load_state_dict(torch.load('../../pose-consistency-KKT-loss/weights/network_weights_s2d'))
        model.eval()
        model.to(self.device)
        return model

    def get_height(self, i: int, ds: Union[RobinGasVis, Rellis3DVis]):
        sample = ds[i]
        imgs, rots, trans, intrins, post_rots, post_trans, hm_geom, hm_terrain, lidar_pts = sample
        input = torch.as_tensor(hm_geom[None], device=self.device)
        hm_pred = self.model(input)
        height = hm_pred.squeeze().cpu()[0]
        return height

    def compute_losses(self, batch):
        imgs, rots, trans, intrins, post_rots, post_trans, hm_geom, hm_terrain, lidar_pts = batch
        hm_geom = torch.as_tensor(hm_geom, device=self.device)
        hm_terrain = torch.as_tensor(hm_terrain, device=self.device)

        height_geom, weights_geom = hm_geom[:, 0:1], hm_geom[:, 1:2]
        height_terrain, weights_terrain = hm_terrain[:, 0:1], hm_terrain[:, 1:2]

        hm_pred = self.model(hm_geom)
        height_pred = hm_pred[:, 0:1]

        loss_geom = self.loss_fn(height_pred[weights_geom.bool()], height_geom[weights_geom.bool()])
        loss_rigid = self.loss_fn(height_pred[weights_terrain.bool()], height_terrain[weights_terrain.bool()])
        return loss_geom, loss_rigid


def evaluate(dataset):
    dphys_config_path = '../config/dphys_cfg.yaml'
    robot = 'husky'
    lss_config_path = f'../config/lss_cfg_{robot}.yaml'
    if dataset == 'robingas':
        model_path = f'../config/weights/lss/lss_robingas_{robot}.pt'
    elif dataset == 'rellis3d':
        model_path = '../config/tb_runs/lss_rellis3d.pt'
    else:
        raise ValueError('Invalid dataset %s. Supported: rellis3d and robingas' % dataset)

    evals = [EvaluatorGeom, EvaluatorLSS, EvaluatorKKT, EvaluatorLSSGeom]
    # evals = [EvaluatorLSS]
    # evals = [EvaluatorLSSGeom]
    # evals = [EvaluatorGeom]
    # evals = [EvaluatorKKT]

    with torch.no_grad():
        for Eval in evals:
            evaluator = Eval(dphys_config_path=dphys_config_path,
                             lss_config_path=lss_config_path,
                             dataset=dataset, robot=robot,
                             model_path=model_path)
            print(evaluator)
            evaluator.evaluate(vis=False, debug=False)


def main():
    dataset = 'robingas'
    # dataset = 'rellis3d'
    evaluate(dataset)


if __name__ == '__main__':
    main()
