#!/usr/bin/env python

import os
import numpy as np
import torch
import matplotlib.pyplot as plt
from monoforce.datasets import MonoDemDataset, seq_paths
from monoforce.config import Config
from monoforce.models import monolayout, Geom2Trav
from monoforce.vis import set_axes_equal
from monoforce.segmentation import filter_grid, position
from monoforce.transformations import transform_cloud
from tqdm import tqdm
from argparse import ArgumentParser


def parse_args():
    parser = ArgumentParser(description='Monolayout demo')
    parser.add_argument('--data_path', type=str, default=seq_paths[0],
                        help='Path to the data directory')
    parser.add_argument('--encoder_path', type=str, default='../config/weights/monolayout/encoder.pth',
                        help='Path to the encoder weights')
    parser.add_argument('--decoder_path', type=str, default='../config/weights/monolayout/decoder.pth',
                        help='Path to the decoder weights')
    parser.add_argument('--img_size', type=int, nargs='+', default=[512, 512],
                        help='Image size')
    parser.add_argument('--pause_time', type=float, default=0.1,
                        help='Pause time between visualized frames')
    return parser.parse_args()


def demo():
    args = parse_args()
    path = args.data_path
    img_size = args.img_size
    assert os.path.exists(path)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    encoder_path='../config/weights/monolayout/encoder.pth'
    decoder_path='../config/weights/monolayout/decoder.pth'
    geom2trav_path='../config/weights/monolayout/geom2trav.pth'
    H, W = img_size
    models = {}
    # load encoder weights
    models["encoder"] = monolayout.Encoder(num_layers=18, img_ht=H, img_wt=W, pretrained=False)
    encoder_dict = torch.load(encoder_path, map_location=device)
    filtered_dict_enc = {k: v for k, v in encoder_dict.items() if k in models["encoder"].state_dict()}
    models["encoder"].load_state_dict(filtered_dict_enc)

    # load decoder weights
    models["decoder"] = monolayout.Decoder(models["encoder"].resnet_encoder.num_ch_enc)
    models["decoder"].load_state_dict(torch.load(decoder_path, map_location=device))

    # load geom2trav weights
    if os.path.exists(geom2trav_path):
        print('Loading geom2trav weights from %s' % geom2trav_path)
        models["geom2trav"] = Geom2Trav()
        models["geom2trav"].load_state_dict(torch.load(geom2trav_path, map_location=device))

    # models in eval mode
    for model in models.values():
        if model is not None:
            model.eval()

    cfg = Config()
    cfg.from_yaml(os.path.join(path, 'terrain', 'train_log', 'cfg.yaml'))

    camera = 'camera_fisheye_front' if 'marv' in path else 'camera_front'

    # create dataset for MonoDEM training
    ds = MonoDemDataset(path, cameras=[camera], img_size=img_size, cfg=cfg)
    fig = plt.figure(figsize=(20, 10))

    for i in tqdm(range(len(ds))):
        # print('Sample index: {}'.format(i))
        img, height_opt, height_est, mask_traversed, mask_reg = ds[i]
        cloud = ds.get_cloud(i)
        poses = ds.get_traj(i)['poses']

        # transform point cloud to robot frame
        Tr = np.linalg.inv(poses[0])
        cloud = transform_cloud(cloud, Tr)
        poses = np.asarray([np.matmul(Tr, pose) for pose in poses])

        # grid filter
        cloud = filter_grid(cloud, cfg.grid_res)
        # filter point cloud in height map box range
        mask_x = np.logical_and(cloud['x'] > 0., cloud['x'] < cfg.d_max)
        mask_y = np.logical_and(cloud['y'] > -cfg.d_max / 2., cloud['y'] < cfg.d_max / 2.)
        mask_z = np.logical_and(cloud['z'] > 0., cloud['z'] < cfg.h_max)
        mask = np.logical_and(mask_x, mask_y)
        mask = np.logical_and(mask, mask_z)
        cloud_hm = cloud[mask]

        with torch.no_grad():
            # model inference
            img_tensor = torch.from_numpy(img).unsqueeze(0)
            features = models['encoder'](img_tensor)
            height_pred = models['decoder'](features, is_training=True)

        # visualize results
        plt.clf()
        img_vis = img.transpose((1, 2, 0))
        # img_vis = ds.destandardize_img(img_vis)
        plt.subplot(231)
        plt.imshow(img_vis)  # RGB
        plt.title('Input image')

        plt.subplot(232)
        plt.imshow(height_est.squeeze(), cmap='jet')
        plt.title('Height from lidar')
        plt.colorbar()

        plt.subplot(233)
        plt.imshow(height_pred.squeeze().cpu().numpy(), cmap='jet')
        plt.title('Height prediction')
        plt.colorbar()

        # visualize results in 3D
        x_grid = np.arange(0, cfg.d_max, cfg.grid_res)
        y_grid = np.arange(-cfg.d_max / 2., cfg.d_max / 2., cfg.grid_res)
        x_grid, y_grid = np.meshgrid(x_grid, y_grid)

        ax = fig.add_subplot(235, projection='3d')
        ax.set_title('Height from lidar')
        # plot estimated heightmap surface
        height_vis = height_est.squeeze()
        height_vis = np.fliplr(height_vis)
        height_vis = np.rot90(height_vis, k=1, axes=(1, 0))
        ax.plot_surface(x_grid, y_grid, height_vis, cmap='jet', alpha=0.7)
        # plot height map cloud
        ax.scatter(cloud_hm['x'], cloud_hm['y'], cloud_hm['z'], s=0.2, alpha=0.5)
        # plot poses
        ax.plot(poses[:, 0, 3], poses[:, 1, 3], poses[:, 2, 3], color='k', linewidth=2)
        ax.set_xlabel('x')
        ax.set_ylabel('y')
        ax.set_zlabel('z')
        set_axes_equal(ax)
        # set up view point
        ax.view_init(elev=60, azim=180)

        ax = fig.add_subplot(236, projection='3d')
        ax.set_title('Height prediction')
        # plot predicted heightmap surface
        height_vis = height_pred.squeeze().cpu().numpy()
        height_vis = np.fliplr(height_vis)
        height_vis = np.rot90(height_vis, k=1, axes=(1, 0))
        ax.plot_surface(x_grid, y_grid, height_vis, cmap='jet', alpha=0.7)
        # plot height map cloud
        ax.scatter(cloud_hm['x'], cloud_hm['y'], cloud_hm['z'], s=0.2, alpha=0.5)
        # plot poses
        ax.plot(poses[:, 0, 3], poses[:, 1, 3], poses[:, 2, 3], color='k', linewidth=2)
        ax.set_xlabel('x')
        ax.set_ylabel('y')
        ax.set_zlabel('z')
        set_axes_equal(ax)
        # set up view point
        ax.view_init(elev=60, azim=180)

        plt.pause(args.pause_time)

    plt.show()


def main():
    with torch.no_grad():
        demo()


if __name__ == '__main__':
    main()
