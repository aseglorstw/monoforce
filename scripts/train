#!/usr/bin/env python

import os
import torch
import numpy as np
from torch.utils.data import ConcatDataset, DataLoader, Subset
from pytorch3d.loss import chamfer_distance
from pytorch3d.structures import Pointclouds
from monoforce.cloudproc import hm_to_cloud
from monoforce.transformations import transform_cloud
from monoforce.models.lss.tools import denormalize_img
from monoforce.models.lss.model import compile_model
from monoforce.datasets.data import TravData, explore_data
from monoforce.config import Config
from monoforce.utils import read_yaml, write_to_yaml, normalize
from monoforce.datasets import seq_paths, sim_seq_paths
from monoforce.losses import RMSE, total_variation
from tqdm import tqdm
from torch.utils.tensorboard import SummaryWriter
from datetime import datetime
import matplotlib.pyplot as plt

torch.set_default_dtype(torch.float32)


torch.random.manual_seed(0)
np.random.seed(0)

class Trainer:
    def __init__(self,
                 data_paths,
                 cfg,
                 data_aug_conf,
                 grid_conf,
                 bsz=1,
                 nworkers=10,
                 lr=1e-3,
                 weight_decay=1e-7,
                 nepochs=500,
                 map_consistency=True,
                 pretrained_model_path=None,
                 log_dir='./runs',
                 debug=False,
                 vis=False):

            self.cfg = cfg
            self.data_aug_conf = data_aug_conf
            self.grid_conf = grid_conf
            self.data_paths = data_paths
            self.nepochs = nepochs
            self.map_consistency = map_consistency
            self.log_dir = log_dir

            self.train_loaders, self.val_loaders = self.create_dataloaders(bsz=bsz, nworkers=nworkers, debug=debug, vis=vis)

            self.model = self.load_model(modelf=pretrained_model_path)

            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)
            self.loss_fn = torch.nn.MSELoss(reduction='none')
            # self.loss_fn = RMSE(reduction='none')

            self.writer = SummaryWriter(log_dir=log_dir)
            # save configs to log dir
            write_to_yaml(cfg.__dict__, os.path.join(log_dir, 'cfg.yaml'))
            lss_cfg = {'data_aug_conf': data_aug_conf, 'grid_conf': grid_conf}  # combine data_aug_conf and grid_conf
            write_to_yaml(lss_cfg, os.path.join(log_dir, 'lss.yaml'))

            self.min_loss = np.inf
            self.min_train_loss = np.inf
            self.train_counter = 0
            self.val_counter = 0

    def load_model(self, modelf=None):
        model = compile_model(self.grid_conf, self.data_aug_conf, outC=1)
        if modelf is not None:
            print('Loading pretrained LSS model from', modelf)
            model.load_state_dict(torch.load(modelf))
        model.to(self.cfg.device)
        model.train()
        return model

    def create_dataloaders(self, val_fraction=0.1, bsz=1, nworkers=1, debug=False, vis=False):
        # random seed to have consistent train/val split
        # np.random.seed(0)

        # create dataset for LSS model training
        train_datasets = []
        val_datasets = []
        print('Data paths:', self.data_paths)
        for path in self.data_paths:
            assert os.path.exists(path)
            # print(f'Train dataset from path {path} size is {len(ds)}')
            if vis:
                explore_data(path, self.grid_conf, self.data_aug_conf, self.cfg, save=False, is_train=True)

            train_ds = TravData(path, is_train=True, data_aug_conf=self.data_aug_conf, cfg=self.cfg)
            val_ds = TravData(path, is_train=False, data_aug_conf=self.data_aug_conf, cfg=self.cfg)

            if debug:
                print('Debug mode: using small datasets')
                # randomly sample from the dataset
                train_ids = np.random.choice(len(train_ds), int(0.1 * len(train_ds)), replace=False)
                val_ids = np.random.choice(len(val_ds), int(0.05 * len(val_ds)), replace=False)
            else:
                # randomly select a subset of the dataset
                val_ds_size = int(val_fraction * len(train_ds))
                # if map consistency is enabled, use a sequential part of the dataset
                val_ids = np.random.choice(len(train_ds), val_ds_size, replace=False) if not self.map_consistency\
                    else range(len(train_ds) // 2, len(train_ds) // 2 + val_ds_size)
                train_ids = np.setdiff1d(np.arange(len(train_ds)), val_ids)
                assert len(train_ids) + len(val_ids) == len(train_ds)
                # check that there is no overlap between train and val ids
                assert len(np.intersect1d(train_ids, val_ids)) == 0

            train_ds = train_ds[train_ids]
            val_ds = val_ds[val_ids]
            print(f'Train dataset from path {path} size is {len(train_ds)}')
            print(f'Validation dataset from path {path} size is {len(val_ds)}')

            train_datasets.append(train_ds)
            val_datasets.append(val_ds)

        # concatenate datasets if map consistency is disabled
        if not self.map_consistency:
            train_datasets = [ConcatDataset(train_datasets)]
            val_datasets = [ConcatDataset(val_datasets)]

        # create dataloaders
        train_loaders = []
        for ds in train_datasets:
            train_loader = DataLoader(ds, batch_size=bsz,
                                      shuffle=False if self.map_consistency else True,
                                      num_workers=nworkers)
            train_loaders.append(train_loader)
        val_loaders = []
        for ds in val_datasets:
            val_loader = DataLoader(ds, batch_size=bsz, shuffle=False, num_workers=nworkers)
            val_loaders.append(val_loader)

        return train_loaders, val_loaders

    def lidar_hm_loss(self, height_pred, height_gt, weights=None):
        assert height_pred.shape == height_gt.shape, 'Height prediction and ground truth must have the same shape'
        if weights is None:
            weights = torch.ones_like(height_gt)
        assert weights.shape == height_gt.shape, 'Weights and height ground truth must have the same shape'

        # handle imbalanced height distribution (increase weights for higher heights / obstacles)
        h_mean = height_gt[weights.bool()].mean()
        # the higher the difference from mean the higher the weight
        weights_h = 1.0 + torch.abs(height_gt - h_mean)
        # apply height difference weights
        weights = weights * weights_h

        # compute weighted loss
        loss = (self.loss_fn(height_pred, height_gt) * weights).mean()
        return loss

    def traj_hm_loss(self, height_pred, height_gt, weights=None):
        assert height_pred.shape == height_gt.shape, 'Height prediction and ground truth must have the same shape'
        if weights is None:
            weights = torch.ones_like(height_gt)
        assert weights.shape == height_gt.shape, 'Weights and height ground truth must have the same shape'

        # mask of valid labels
        mask_valid = ~torch.isnan(height_gt)
        # apply mask
        height_gt = height_gt[mask_valid]
        height_pred = height_pred[mask_valid]
        weights = weights[mask_valid]

        # compute weighted loss
        loss = (self.loss_fn(height_pred, height_gt) * weights).mean()
        return loss

    def map_consistency_loss(self, height, map_pose, vis=False):
        assert len(height) == len(map_pose), 'Heightmaps and map poses must have the same length'
        assert len(height) > 1, 'Map consistency loss requires at least 2 heightmaps'

        clouds = []
        for p, h in zip(map_pose, height):
            hm_cloud = hm_to_cloud(h.squeeze(), self.cfg)
            hm_cloud = transform_cloud(hm_cloud, p)
            clouds.append(hm_cloud)

        # pytorch3d pointcloud
        src_cloud = Pointclouds(points=[torch.cat(clouds[::2])])
        tgt_cloud = Pointclouds(points=[torch.cat(clouds[1::2])])
        # chamfer distance
        chamfer_dist, _ = chamfer_distance(src_cloud, tgt_cloud)

        if vis:
            import open3d as o3d
            with torch.no_grad():
                global_hm_cloud = torch.cat(clouds, dim=0)
                # plot global cloud with open3d
                hm_pcd = o3d.geometry.PointCloud()
                hm_pcd.points = o3d.utility.Vector3dVector(global_hm_cloud.cpu().numpy())
                o3d.visualization.draw_geometries([hm_pcd])

        return chamfer_dist

    def epoch(self, train=True):
        assert len(self.train_loaders) == len(self.val_loaders), 'Train and val loaders must have the same length'
        loaders = self.train_loaders if train else self.val_loaders
        counter = self.train_counter if train else self.val_counter

        epoch_loss = 0.0
        max_grad_norm = 5.0

        for loader in loaders:
            loader_loss = 0.0
            for batch in tqdm(loader, total=len(loader)):
                batch = [torch.as_tensor(b, dtype=torch.float32, device=self.cfg.device) for b in batch]
                imgs, rots, trans, intrins, post_rots, post_trans, hm_lidar, hm_traj, map_pose = batch
                height_lidar, weights_lidar = hm_lidar[:, 0:1], hm_lidar[:, 1:2]
                height_traj, weights_traj = hm_traj[:, 0:1], hm_traj[:, 1:2]

                inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
                voxel_feats = self.model.get_voxels(*inputs)
                height_pred_geom, height_pred_diff = self.model.bevencode(voxel_feats)
                height_pred_rigid = height_pred_geom - height_pred_diff

                loss_lidar = self.lidar_hm_loss(height_pred_geom, height_lidar, weights_lidar)
                loss_traj = self.traj_hm_loss(height_pred_rigid, height_traj, weights_traj)

                # add height difference loss
                loss_hdiff = height_pred_diff.std()

                loss = 1.*loss_lidar + 10.*loss_traj + 1e-4*loss_hdiff
                if self.map_consistency and len(height_pred_rigid) > 1:
                    loss_map = self.map_consistency_loss(height_pred_rigid, map_pose)
                    loss += 0.1*loss_map
                else:
                    loss_map = torch.tensor(np.nan, device=self.cfg.device)

                if train:
                    self.optimizer.zero_grad()
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_grad_norm)
                    self.optimizer.step()
                loader_loss += loss.item()

                counter += 1
                self.writer.add_scalar(f"{'train' if train else 'val'}/iter_loss_geom", loss_lidar, counter)
                self.writer.add_scalar(f"{'train' if train else 'val'}/iter_loss_rigid", loss_traj, counter)
                self.writer.add_scalar(f"{'train' if train else 'val'}/iter_loss_hdiff", loss_hdiff, counter)
                self.writer.add_scalar(f"{'train' if train else 'val'}/iter_loss_map", loss_map, counter)
                self.writer.add_scalar(f"{'train' if train else 'val'}/iter_loss", loss, counter)

            if len(loader) > 0:
                loader_loss /= len(loader)
            epoch_loss += loader_loss
        if len(loaders) > 0:
            epoch_loss /= len(loaders)

        return epoch_loss, counter

    def train(self):
        for e in range(self.nepochs):
            # training epoch
            train_loss, self.train_counter = self.epoch(train=True)
            print('Epoch:', e, 'Train loss:', train_loss)
            self.writer.add_scalar('train/epoch_loss', train_loss, e)

            if train_loss < self.min_train_loss:
                self.min_train_loss = train_loss
                print('Saving train model...')
                torch.save(self.model.state_dict(), os.path.join(self.log_dir, 'train_lss.pt'))

                # visualize training predictions
                fig = self.vis_pred(self.train_loaders[0])
                self.writer.add_figure('train/prediction', fig, e)

            # validation epoch
            with torch.no_grad():
                val_loss, self.val_counter = self.epoch(train=False)
                print('Epoch:', e, 'Validation loss:', val_loss)
                self.writer.add_scalar('val/epoch_loss', val_loss, e)
                if val_loss < self.min_loss:
                    self.min_loss = val_loss
                    self.model.eval()
                    print('Saving model...')
                    torch.save(self.model.state_dict(), os.path.join(self.log_dir, 'lss.pt'))
                    self.model.train()

                    # visualize validation predictions
                    fig = self.vis_pred(self.val_loaders[0])
                    self.writer.add_figure('val/prediction', fig, e)

    def vis_pred(self, loader):
        model = self.model
        grid_conf = self.grid_conf
        device = self.cfg.device

        fig = plt.figure(figsize=(20, 12))
        ax1 = fig.add_subplot(341)
        ax2 = fig.add_subplot(342, projection='3d')
        ax3 = fig.add_subplot(343, projection='3d')
        ax4 = fig.add_subplot(344, projection='3d')
        ax5 = fig.add_subplot(345)
        ax6 = fig.add_subplot(346)
        ax7 = fig.add_subplot(347)
        ax8 = fig.add_subplot(348)
        ax9 = fig.add_subplot(349)
        ax10 = fig.add_subplot(3, 4, 10)
        ax11 = fig.add_subplot(3, 4, 11)
        ax12 = fig.add_subplot(3, 4, 12)

        axes = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12]

        # visualize training predictions
        with torch.no_grad():
            imgs, rots, trans, intrins, post_rots, post_trans, hm_lidar, hm_traj, map_pose = next(iter(loader))
            inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
            inputs = [torch.as_tensor(i, dtype=torch.float32, device=device) for i in inputs]
            hm_lidar = torch.as_tensor(hm_lidar, dtype=torch.float32, device=device)
            voxel_feats = model.get_voxels(*inputs)
            height_pred_geom, height_pred_diff = model.bevencode(voxel_feats)
            height_pred = height_pred_geom - height_pred_diff

            for ax in axes:
                ax.clear()

            # plot image
            img = denormalize_img(imgs[0][0])
            ax1.imshow(img)

            # plot prediction as surface
            ax2.set_title('Pred Surface')
            height_pred = height_pred[0][0].cpu().numpy().T
            height_pred_geom = height_pred_geom[0][0].cpu().numpy().T
            height_pred_diff = height_pred_diff[0][0].cpu().numpy().T
            height_lidar = hm_lidar[0][0].cpu().numpy().T
            height_traj = hm_traj[0][0].cpu().numpy().T
            mask = hm_lidar[0][1].bool().cpu().numpy().T
            x_grid = np.arange(grid_conf['xbound'][0], grid_conf['xbound'][1], grid_conf['xbound'][2])
            y_grid = np.arange(grid_conf['ybound'][0], grid_conf['ybound'][1], grid_conf['ybound'][2])
            x_grid, y_grid = np.meshgrid(x_grid, y_grid)
            ax2.plot_surface(x_grid, y_grid, height_pred, cmap='jet', vmin=-1.0, vmax=1.0)
            ax2.set_zlim(-1.0, 1.0)
            ax2.set_xlabel('x [m]')
            ax2.set_ylabel('y [m]')
            ax2.set_zlabel('z [m]')

            # plot ground truth as surface
            ax3.set_title('Lidar Surface')
            ax3.plot_surface(x_grid, y_grid, height_lidar, cmap='jet', vmin=-1.0, vmax=1.0)
            ax3.set_zlim(-1.0, 1.0)
            ax3.set_xlabel('x [m]')
            ax3.set_ylabel('y [m]')
            ax3.set_zlabel('z [m]')

            # plot traj heightmap as surface
            ax4.set_title('Traj Surface')
            ax4.plot_surface(x_grid, y_grid, height_traj, cmap='jet', vmin=-1.0, vmax=1.0)

            # plot prediction as image
            ax5.set_title('Prediction')
            ax5.imshow(height_pred, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            ax6.set_title('Masked Prediction')
            height_pred_vis = np.zeros_like(height_pred)
            height_pred_vis[mask] = height_pred[mask]
            ax6.imshow(height_pred_vis, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            ax7.set_title('Lidar')
            ax7.imshow(height_lidar, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            ax8.set_title('Traj')
            ax8.imshow(height_traj, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            # predicted geometric height
            ax9.set_title('Geom Pred')
            ax9.imshow(height_pred_geom, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            # masked predicted geometric height
            ax10.set_title('Masked Geom Pred')
            height_pred_geom_vis = np.zeros_like(height_pred)
            height_pred_geom_vis[mask] = height_pred_geom[mask]
            ax10.imshow(height_pred_geom_vis, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            # predicted diff height
            ax11.set_title('Diff Pred')
            ax11.imshow(height_pred_diff, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            # masked predicted diff height
            ax12.set_title('Masked Diff Pred')
            height_pred_diff_vis = np.zeros_like(height_pred)
            height_pred_diff_vis[mask] = height_pred_diff[mask]
            ax12.imshow(height_pred_diff_vis, origin='lower', cmap='jet', vmin=-1.0, vmax=1.0)

            return fig


def main():
    bsz = 24
    nworkers = 12
    nepochs = 500

    cfg = Config()
    config_path = '../config/cfg.yaml'
    assert os.path.isfile(config_path), 'Config file %s does not exist' % config_path
    cfg.from_yaml(config_path)
    cfg.hm_interp_method = None

    # load LSS config
    lss_config_path = '../config/lss.yaml'
    assert os.path.isfile(lss_config_path), 'LSS config file %s does not exist' % lss_config_path
    lss_config = read_yaml(lss_config_path)
    grid_conf = lss_config['grid_conf']
    data_aug_conf = lss_config['data_aug_conf']

    log_dir = os.path.join('../config/tb_runs', 'lss_' + datetime.now().strftime("%Y_%m_%d_%H_%M_%S"))
    pretrained_model_path = '../config/weights/lss/train_lss.pt'
    # pretrained_model_path = None
    debug = False
    vis = False

    ds_paths = seq_paths[:3]
    # ds_paths = sim_seq_paths

    trainer = Trainer(data_paths=ds_paths,
                      cfg=cfg, data_aug_conf=data_aug_conf, grid_conf=grid_conf,
                      bsz=bsz, nworkers=nworkers, nepochs=nepochs,
                      pretrained_model_path=pretrained_model_path,
                      map_consistency=False,
                      log_dir=log_dir, debug=debug, vis=vis)
    trainer.train()


if __name__ == '__main__':
    main()
