#!/usr/bin/env python

import os
import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np
import torch
from torch.utils.data import ConcatDataset
from monoforce.models.lss.tools import denormalize_img, ego_to_cam, get_only_in_img_mask
from monoforce.models.lss.model import compile_model
from monoforce.datasets.data import OmniDEMData, OmniDEMDataVis, explore_data, TravDataCamSynchVis, TravDataVis
from monoforce.config import Config
from monoforce.datasets import robingas_husky_seq_paths, sim_seq_paths, oru_seq_paths
from monoforce.losses import RMSE
from monoforce.utils import read_yaml
from tqdm import tqdm

torch.set_default_dtype(torch.float32)


def hm_to_imgs_projection_demo(seq_path, data_aug_conf, grid_conf, cfg, modelf, bsz=1, nworkers=10):
    model = compile_model(grid_conf, data_aug_conf, outC=1)
    print('loading', modelf)
    model.load_state_dict(torch.load(modelf))
    model.to(cfg.device)
    model.eval()

    ds = OmniDEMDataVis(seq_path, is_train=False, data_aug_conf=data_aug_conf, cfg=cfg)
    loader = torch.utils.data.DataLoader(ds, batch_size=bsz, shuffle=False, num_workers=nworkers)

    loss_fn = RMSE()

    fig = plt.figure(figsize=(20, 10))
    gs = mpl.gridspec.GridSpec(3, 6)
    gs.update(wspace=0.0, hspace=0.0, left=0.0, right=1.0, top=1.0, bottom=0.0)
    with torch.no_grad():
        for batchi, (imgs, rots, trans, intrins, post_rots, post_trans, hm_gt, points) in tqdm(enumerate(loader), total=len(loader)):
            inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
            inputs = [torch.as_tensor(i, dtype=torch.float32, device=cfg.device) for i in inputs]
            height_pred = model(*inputs)

            # compute loss
            hm_gt = hm_gt.to(cfg.device)
            B, D, H, W = hm_gt.shape
            height_gt, mask_measured = hm_gt[:, 0].view(B, 1, H, W), hm_gt[:, 1].view(B, 1, H, W)
            mask_measured = mask_measured.bool()
            loss = loss_fn(height_pred[mask_measured], height_gt[mask_measured])

            # figure title
            fig.suptitle(f'Loss: {loss.item():.3f}')

            # clear grid axes
            plt.clf()

            # create height map grid
            z_grid = height_pred[0, 0].cpu()
            # z_grid = height_gt[0, 0].cpu()
            x_grid = torch.arange(-cfg.d_max, cfg.d_max, cfg.grid_res)
            y_grid = torch.arange(-cfg.d_max, cfg.d_max, cfg.grid_res)
            x_grid, y_grid = torch.meshgrid(x_grid, y_grid)
            hm_points = torch.stack([x_grid, y_grid, z_grid], dim=-1)
            # filter out height map points that are not measured by lidar
            hm_points = hm_points[mask_measured[0, 0].cpu()]
            hm_points = hm_points.view(-1, 3).T
            # hm_points = points[0].cpu()[:, ::2]

            # plot images and height map points
            for img_gs_ids, imgi in zip([(1, 2), (0, 1), (1, 0), (2, 1)], range(imgs.shape[1])):
                i, j = img_gs_ids
                ax = plt.subplot(gs[i, j])
                si = 0
                img = imgs[si, imgi]
                img = denormalize_img(img)
                # project height map points to image
                ego_pts = ego_to_cam(hm_points, rots[si, imgi], trans[si, imgi], intrins[si, imgi])
                img_H, img_W = data_aug_conf['H'], data_aug_conf['W']
                mask = get_only_in_img_mask(ego_pts, img_H, img_W)
                plot_pts = post_rots[si, imgi].matmul(ego_pts) + post_trans[si, imgi].unsqueeze(1)
                ax.imshow(img)
                ax.scatter(plot_pts[0, mask], plot_pts[1, mask], s=0.5, c=hm_points[2, mask],
                           cmap='jet', vmin=-1.0, vmax=1.0)
                ax.axis('off')
            
            # plot prediction as image
            ax = plt.subplot(gs[1, 1])
            ax.imshow(z_grid.T, cmap='jet', vmin=-1.0, vmax=1.0, origin='lower')

            # plot prediction as surface
            ax = plt.subplot(gs[:, 3:6], projection='3d')
            ax.plot_surface(x_grid, y_grid, z_grid, cmap='jet', vmin=-1.0, vmax=1.0)
            ax.set_zlim(-2.0, 2.0)
            # set up view
            ax.view_init(elev=60., azim=-80.)
            ax.set_xlabel('x [m]')
            ax.set_ylabel('y [m]')
            ax.set_zlabel('z [m]')
            
            plt.pause(1.)
            plt.draw()


def eval(paths, data_aug_conf, grid_conf, cfg, modelf=None, bsz=2, nworkers=10):
    model = compile_model(grid_conf, data_aug_conf, outC=1)
    if modelf is not None:
        print('loading', modelf)
        model.load_state_dict(torch.load(modelf))
    model.to(cfg.device)
    model.eval()

    loss_fn = RMSE()

    all_seqs_mean_loss = 0.0
    for path in paths:
        print(f'Evaluation on {os.path.basename(path)}...')
        # explore_data(path, grid_conf, data_aug_conf, cfg, modelf, save=False)

        val_ds = OmniDEMData(path, is_train=False, data_aug_conf=data_aug_conf, cfg=cfg)
        valloader = torch.utils.data.DataLoader(val_ds, batch_size=bsz, shuffle=False, num_workers=nworkers)

        # validation epoch
        with torch.no_grad():
            eval_loss = 0.0
            for batchi, (imgs, rots, trans, intrins, post_rots, post_trans, hm_gt)\
                    in tqdm(enumerate(valloader), total=len(valloader)):
                inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
                inputs = [torch.as_tensor(i, dtype=torch.float32, device=cfg.device) for i in inputs]
                height_pred = model(*inputs)

                # compute loss
                hm_gt = hm_gt.to(cfg.device)
                B, D, H, W = hm_gt.shape
                height_gt, mask_measured = hm_gt[:, 0].view(B, 1, H, W), hm_gt[:, 1].view(B, 1, H, W)
                loss = loss_fn(height_pred[mask_measured.bool()], height_gt[mask_measured.bool()])

                eval_loss += loss.item()
            eval_loss /= len(valloader)

        print(f'For seq {os.path.basename(path)} mean loss: {eval_loss:.3f}')
        all_seqs_mean_loss += eval_loss
    all_seqs_mean_loss /= len(paths)
    print(f'Average evaluation loss: {all_seqs_mean_loss:.3f}')


def main():
    cfg = Config()
    config_path = '../config/cfg.yaml'
    assert os.path.isfile(config_path), 'Config file %s does not exist' % config_path
    cfg.from_yaml(config_path)

    # load LSS config
    lss_config_path = '../config/lss.yaml'
    assert os.path.isfile(lss_config_path), 'LSS config file %s does not exist' % lss_config_path
    lss_config = read_yaml(lss_config_path)
    grid_conf = lss_config['grid_conf']
    data_aug_conf = lss_config['data_aug_conf']

    # modelf = '../config/weights/lss/lss.pt'
    modelf = '../config/tb_runs/lss_2024_02_23_18_16_02/train_lss.pt'
    # modelf = '../config/weights/lss/lss_sim.pt'
    # modelf = None

    paths = robingas_husky_seq_paths
    # paths = sim_seq_paths
    # paths = oru_seq_paths

    # eval(paths, data_aug_conf, grid_conf, cfg, modelf, bsz=1)
    for path in paths:
        explore_data(path, grid_conf, data_aug_conf, cfg,
                     save=True, is_train=False, sample_range='all', DataClass=TravDataCamSynchVis)
        # hm_to_imgs_projection_demo(path, data_aug_conf, grid_conf, cfg, modelf)


if __name__ == '__main__':
    main()
