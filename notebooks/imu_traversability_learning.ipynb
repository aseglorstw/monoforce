{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.recfunctions import structured_to_unstructured, unstructured_to_structured\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import cm\n",
    "import os\n",
    "from differentiable_physics.vis import show_cloud\n",
    "from differentiable_physics.utils import normalize, create_model\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e837ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "def horizontal_shift(img, shift):\n",
    "    if shift > 0:\n",
    "        img_shifted = np.zeros_like(img)\n",
    "        img_shifted[..., :shift] = img[..., -shift:]\n",
    "        img_shifted[..., shift:] = img[..., :-shift]\n",
    "    else:\n",
    "        img_shifted = img\n",
    "    return img_shifted\n",
    "    \n",
    "class TraversabilityData(object):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.ids = [f[:-4] for f in os.listdir(os.path.join(path, 'points'))]\n",
    "        self.proj_fov_up = 45\n",
    "        self.proj_fov_down = -45\n",
    "        self.proj_H = 128\n",
    "        self.proj_W = 1024\n",
    "        self.ignore_label = 255\n",
    "\n",
    "    def range_projection(self, points, labels):\n",
    "        \"\"\" Project a point cloud into a sphere.\n",
    "        \"\"\"\n",
    "        # laser parameters\n",
    "        fov_up = self.proj_fov_up / 180.0 * np.pi  # field of view up in rad\n",
    "        fov_down = self.proj_fov_down / 180.0 * np.pi  # field of view down in rad\n",
    "        fov = abs(fov_down) + abs(fov_up)  # get field of view total in rad\n",
    "\n",
    "        # get depth of all points\n",
    "        depth = np.linalg.norm(points, 2, axis=1)\n",
    "\n",
    "        # get scan components\n",
    "        scan_x = points[:, 0]\n",
    "        scan_y = points[:, 1]\n",
    "        scan_z = points[:, 2]\n",
    "\n",
    "        # get angles of all points\n",
    "        yaw = -np.arctan2(scan_y, scan_x)\n",
    "        pitch = np.arcsin(scan_z / (depth + 1e-8))\n",
    "\n",
    "        # get projections in image coords\n",
    "        proj_x = 0.5 * (yaw / np.pi + 1.0)  # in [0.0, 1.0]\n",
    "        proj_y = 1.0 - (pitch + abs(fov_down)) / fov  # in [0.0, 1.0]\n",
    "\n",
    "        # scale to image size using angular resolution\n",
    "        proj_x *= self.proj_W  # in [0.0, W]\n",
    "        proj_y *= self.proj_H  # in [0.0, H]\n",
    "\n",
    "        # round and clamp for use as index\n",
    "        proj_x = np.floor(proj_x)\n",
    "        proj_x = np.minimum(self.proj_W - 1, proj_x)\n",
    "        proj_x = np.maximum(0, proj_x).astype(np.int32)  # in [0,W-1]\n",
    "\n",
    "        proj_y = np.floor(proj_y)\n",
    "        proj_y = np.minimum(self.proj_H - 1, proj_y)\n",
    "        proj_y = np.maximum(0, proj_y).astype(np.int32)  # in [0,H-1]\n",
    "\n",
    "        # order in decreasing depth\n",
    "        indices = np.arange(depth.shape[0])\n",
    "        order = np.argsort(depth)[::-1]\n",
    "        depth = depth[order]\n",
    "        proj_y = proj_y[order]\n",
    "        proj_x = proj_x[order]\n",
    "        indices = indices[order]\n",
    "\n",
    "        # assing to image\n",
    "        proj_range = np.full((self.proj_H, self.proj_W), -1, dtype=np.float32)\n",
    "        proj_range[proj_y, proj_x] = depth\n",
    "\n",
    "        # projected index (for each pixel, what I am in the pointcloud)\n",
    "        # [H,W] index (-1 is no data)\n",
    "        proj_idx = np.full((self.proj_H, self.proj_W), -1, dtype=np.int32)\n",
    "        proj_idx[proj_y, proj_x] = indices\n",
    "        # only map colors to labels that exist\n",
    "        mask = proj_idx >= 0\n",
    "\n",
    "        # projection color with semantic labels\n",
    "        proj_sem_label = np.full((self.proj_H, self.proj_W), self.ignore_label, dtype=np.float32)  # [H,W]  label\n",
    "        proj_sem_label[mask] = labels[proj_idx[mask]]\n",
    "\n",
    "        return proj_range, proj_sem_label\n",
    "        \n",
    "    def __getitem__(self, i, visualize=False):\n",
    "        ind = self.ids[i]\n",
    "        cloud = np.load(os.path.join(self.path, 'points', '%s.npz' % ind))['cloud']\n",
    "        \n",
    "        if cloud.ndim == 2:\n",
    "            cloud = cloud.reshape((-1,))\n",
    "            \n",
    "        points = structured_to_unstructured(cloud[['x', 'y', 'z']])\n",
    "        trav = np.asarray(cloud['traversability'], dtype=points.dtype)\n",
    "        if visualize:\n",
    "            show_cloud(points, trav, min=0, max=1, colormap=cm.jet)\n",
    "\n",
    "        depth_range, label_range = self.range_projection(points, trav)\n",
    "        \n",
    "        # data augmentation\n",
    "        # add rotation around vertical axis (Z)\n",
    "        H, W = depth_range.shape\n",
    "        shift = np.random.choice(range(W))\n",
    "        depth_range = horizontal_shift(depth_range, shift=shift)\n",
    "        label_range = horizontal_shift(label_range, shift=shift)\n",
    "\n",
    "        return depth_range[None], label_range[None], points\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, dataset, batch_size=4, lr=1e-3, epochs=1):\n",
    "        self.ds = dataset\n",
    "        self.dataloader = DataLoader(self.ds, batch_size=batch_size, shuffle=True)\n",
    "        self.epochs = epochs\n",
    "        self.device = torch.device('cuda:0')\n",
    "        self.model = create_model('deeplabv3_resnet50', n_inputs=1, n_outputs=1)\n",
    "        self.model = self.model.train()\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(lr=lr, params=self.model.parameters())\n",
    "        # self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        # self.loss_fn = smp.losses.LovaszLoss(mode='multilabel', from_logits=False, ignore_index=self.ds.ignore_label)\n",
    "        self.loss_fn = smp.losses.LovaszLoss(mode='multilabel', from_logits=False)\n",
    "\n",
    "    def train(self, vis=False):\n",
    "        losses = []\n",
    "        \n",
    "        for e in range(self.epochs):\n",
    "            print('Training epoch %i' % e)\n",
    "            \n",
    "            for i, sample in tqdm(enumerate(self.dataloader)):\n",
    "\n",
    "                depth, label, points = sample\n",
    "                depth = depth.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "\n",
    "                pred = self.model(depth)['out']\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_fn(pred, label)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                if vis and i % (len(self.ds) // 10) == 0:\n",
    "                    # visualize(pred, label, depth, points)\n",
    "                    visualize(pred, label, depth)\n",
    "                \n",
    "                # print('Training loss: %f' % loss.item())\n",
    "            \n",
    "            self.optimizer.param_groups[0]['lr'] = self.optimizer.param_groups[0]['lr'] / 10.\n",
    "            print('Decrease decoder learning rate to: %f' % self.optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "            # plot losses\n",
    "            plt.figure()\n",
    "            plt.grid()\n",
    "            plt.plot(losses)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc022257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(pred, label, depth_range, points=None, ignore_label=255):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.title('Prediction')\n",
    "    pred_vis = torch.clone(pred)\n",
    "    pred_vis = normalize(pred_vis.detach().cpu())\n",
    "#     pred_vis[label == ignore_label] = 0\n",
    "    pred_vis = pred_vis[0].squeeze()\n",
    "    plt.imshow(pred_vis)\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.title('Label')\n",
    "    label_vis = torch.clone(label)\n",
    "    label_vis = normalize(label_vis.detach().cpu())\n",
    "    label_vis[label == ignore_label] = 0\n",
    "    label_vis = label_vis[0].squeeze()\n",
    "    plt.imshow(label_vis)\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.title('Range image')\n",
    "    depth_vis = normalize(torch.clone(depth_range)[0].squeeze().detach().cpu().numpy())\n",
    "    plt.imshow(depth_vis)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if points is not None:\n",
    "        show_cloud(points[0], pred[0].squeeze().detach().cpu().numpy().reshape((-1,)), min=0, max=1)\n",
    "        show_cloud(points[0], label[0].squeeze().detach().cpu().numpy().reshape((-1,)), min=0, max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ruslan/data/robingas/data/22-09-27-unhost/husky/husky_2022-09-27-15-01-44/'\n",
    "assert os.path.exists(path)\n",
    "ds = TraversabilityData(path)\n",
    "\n",
    "# visualize a sample from the data set\n",
    "for i in np.random.choice(range(len(ds)), 5):\n",
    "    _ = ds.__getitem__(i, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b72dba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(ds, batch_size=8, lr=1e-3, epochs=2)\n",
    "trainer.train(vis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31430921",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97aaa4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test the trained model\n",
    "\n",
    "for _ in range(5):\n",
    "    sample = next(iter(trainer.dataloader))\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    depth, label, points = sample\n",
    "    depth = depth.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    model = trainer.model.to(device)\n",
    "    pred = model(depth)['out']\n",
    "\n",
    "#     visualize(pred, label, depth, points)\n",
    "    visualize(pred, label, depth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
