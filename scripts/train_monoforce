#!/usr/bin/env python

import os
import numpy as np
from datetime import datetime
import torch
from torch.utils.data import DataLoader, ConcatDataset
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import matplotlib.pyplot as plt
from monoforce.datasets import MonoDemDataset
from monoforce.config import Config
from monoforce.models import monolayout
from monoforce.utils import normalize
from argparse import ArgumentParser


def str2bool(v):
    return v.lower() in ('1', 'yes', 'true', 't', 'y')

def parse_args():
    parser = ArgumentParser(description='Train Monolayout')
    parser.add_argument('--visualize', type=str2bool, default=False)
    parser.add_argument('--save', type=str2bool, default=True)
    parser.add_argument('--batch_size', type=int, default=16)
    parser.add_argument('--lr', type=float, default=1e-5)
    parser.add_argument('--n_epochs', type=int, default=500)
    parser.add_argument('--img_size', type=int, default=512)
    parser.add_argument('--regularization', type=float, default=0.2)
    parser.add_argument('--weighted_loss', type=str2bool, default=False)
    return parser.parse_args()


class Trainer(object):
    def __init__(self, train_dataset, val_dataset, img_size=(512, 512),
                 batch_size=1, lr=1e-3,
                 regularization=None, weighted_loss=False,
                 pretrained_paths=None,
                 vis=False, save=True):
        self.train_ds = train_dataset
        self.val_ds = val_dataset
        self.train_dataloader = DataLoader(self.train_ds, batch_size=batch_size, shuffle=True)
        self.val_dataloader = DataLoader(self.val_ds, batch_size=batch_size, shuffle=False)
        self.regularization = regularization
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.img_size = img_size

        # models
        self.models = self.init_models(pretrained_paths=pretrained_paths)

        # optimizer
        self.parameters_to_train = []
        for key in self.models.keys():
            self.models[key].to(self.device)
            self.parameters_to_train += list(self.models[key].parameters())
        self.optimizer = torch.optim.Adam(params=self.parameters_to_train, lr=lr)

        self.weighted_loss = weighted_loss
        if self.weighted_loss:
            # no loss reduction to apply weights first: https://discuss.pytorch.org/t/how-to-weight-the-loss/66372/2
            self.loss_fn = torch.nn.MSELoss(reduction='none')
        else:
            self.loss_fn = torch.nn.MSELoss(reduction='mean')
        self.min_val_loss = np.inf
        self.min_train_loss = np.inf

        self.vis = vis
        self.save = save

        # logging: tensorboard and weights
        path = os.path.dirname(os.path.realpath(__file__))
        time_label = datetime.now().strftime("%Y_%m_%d-%H:%M:%S")
        self.writer = SummaryWriter(log_dir=os.path.join(path, '../config/tb_runs/monolayout/%s/' % time_label))
        self.weights_dir_path = os.path.join(path, '../config/weights/monolayout/%s/' % time_label)

    def init_models(self, pretrained_paths=None):
        assert isinstance(pretrained_paths, dict) or pretrained_paths is None
        models = {}
        models["encoder"] = monolayout.Encoder(num_layers=18, img_ht=self.img_size[0], img_wt=self.img_size[1], pretrained=True)
        models["decoder"] = monolayout.Decoder(models["encoder"].resnet_encoder.num_ch_enc)

        if pretrained_paths is not None:
            assert "encoder" in pretrained_paths.keys() and "decoder" in pretrained_paths.keys()
            print('Loading pretrained weights for encoder and decoder from:\n%s...' % pretrained_paths)

            encoder_dict = torch.load(pretrained_paths["encoder"], map_location=self.device)
            filtered_dict_enc = {k: v for k, v in encoder_dict.items() if k in models["encoder"].state_dict()}
            models["encoder"].load_state_dict(filtered_dict_enc)
            models["decoder"].load_state_dict(torch.load(pretrained_paths["decoder"], map_location=self.device))

        for key in models.keys():
            models[key].train()
            models[key].to(self.device)

        return models

    def visualize(self, img, height_label, height_pred, height_reg, weights_trav, weights_reg):
        plt.figure(figsize=(20, 5))
        plt.subplot(1, 5, 1)
        plt.title('Input Image')
        img_vis = img[0].cpu().numpy().transpose((1, 2, 0))
        # img_vis = self.val_ds.destandardize_img(img_vis)
        plt.imshow(img_vis)

        plt.subplot(1, 5, 2)
        plt.title('Height Label')
        plt.imshow(height_label[0].squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()
        plt.imshow(weights_trav[0].squeeze().cpu().numpy(), alpha=0.5, cmap='jet')

        plt.subplot(1, 5, 3)
        plt.title('Height Prediction')
        plt.imshow(height_pred[0].squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()

        plt.subplot(1, 5, 4)
        plt.title('Height Regularization')
        plt.imshow(height_reg[0].squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()

        plt.subplot(1, 5, 5)
        plt.title('Weights Regularization')
        plt.imshow(weights_reg[0].squeeze().cpu().numpy(), cmap='jet')
        plt.colorbar()

        plt.show()

    def train_epoch(self, epoch_n):
        loss_sum = torch.as_tensor(0.0, device=self.device)
        for i, batch in tqdm(enumerate(self.train_dataloader)):
            # get sample from data loader (front image, height map label and height map regularization)
            img, height_label, height_reg, weights_traversed, weights_reg = batch
            img = img.to(self.device)
            height_label = height_label.to(self.device)
            height_reg = height_reg.to(self.device)
            weights_traversed = weights_traversed.to(self.device)
            weights_reg = weights_reg.to(self.device)

            # model inference
            features = self.models['encoder'](img)
            height_pred = self.models['decoder'](features, is_training=True)

            # loss is computed for the part of the predicted height map covered by robot's trajectory
            if self.weighted_loss:
                loss = self.loss_fn(height_pred, height_label)
                loss = loss * weights_traversed
                loss = loss.sum() / (weights_traversed.sum() + 1e-6)
            else:
                loss = self.loss_fn(height_pred * weights_traversed, height_label * weights_traversed)
            # print('Loss: %f' % loss.item())
            self.writer.add_scalar('Loss(iter)/train', loss.item(), i + epoch_n * len(self.train_dataloader))

            # add regularization loss
            if self.regularization is not None:
                if self.weighted_loss:
                    loss_reg = self.loss_fn(height_pred, height_reg)
                    loss_reg = loss_reg * weights_reg
                    loss_reg = loss_reg.sum() / (weights_reg.sum() + 1e-6)
                else:
                    loss_reg = self.loss_fn(height_pred, height_reg)

                # print('Loss reg: %f' % loss_reg.item())
                self.writer.add_scalar('Loss_reg(iter)/train', loss_reg.item(), i + epoch_n * len(self.train_dataloader))
                loss += self.regularization * loss_reg

            # backpropagate gradients and update model params
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            loss_sum += loss
            # print('Iter: %i, training loss: %f' % (i, loss_sum.item()))
            self.writer.add_scalar('Loss_sum(iter)/train', loss_sum.item(), i + epoch_n * len(self.train_dataloader))

        loss_sum /= len(self.train_ds)

        return loss_sum

    def val_epoch(self, epoch_n):
        loss_sum = torch.as_tensor(0.0, device=self.device)
        for i, batch in tqdm(enumerate(self.val_dataloader)):
            # get sample from data loader (front image, height map label and height map regularization)
            img, height_label, height_reg, weights_traversed, weights_reg = batch
            img = img.to(self.device)
            height_label = height_label.to(self.device)
            height_reg = height_reg.to(self.device)
            weights_traversed = weights_traversed.to(self.device)
            weights_reg = weights_reg.to(self.device)

            # model inference
            features = self.models['encoder'](img)
            height_pred = self.models['decoder'](features, is_training=True)

            # loss is computed for the part of the predicted height map covered by robot's trajectory
            loss = self.loss_fn(height_pred, height_label)
            loss = loss * weights_traversed
            loss = loss.sum() / (weights_traversed.sum() + 1e-6)
            # print('Loss: %f' % loss.item())
            # tensorboard logger
            self.writer.add_scalar('Loss(iter)/val', loss.item(), i + epoch_n * len(self.val_dataloader))

            # add regularization loss
            if self.regularization is not None:
                loss_reg = self.loss_fn(height_pred, height_reg)
                loss_reg = loss_reg * weights_reg
                loss_reg = loss_reg.sum() / (weights_reg.sum() + 1e-6)
                # print('Loss reg: %f' % loss_reg.item())
                self.writer.add_scalar('Loss_reg(iter)/val', loss_reg.item(), i + epoch_n * len(self.val_dataloader))
                loss += self.regularization * loss_reg

            loss_sum += loss
            # print('Iter: %i, validation loss: %f' % (i, loss_sum.item()))
            self.writer.add_scalar('Loss_sum(iter)/val', loss_sum.item(), i + epoch_n * len(self.val_dataloader))

        loss_sum /= len(self.val_ds)

        # visualize
        if self.vis:
            self.visualize(img, height_label, height_pred, height_reg, weights_traversed, weights_reg)

        # add input image to tensorboard logger
        self.writer.add_images('Input Image', img, 0)
        # add predictions to tensorboard logger
        self.writer.add_images('Height Label', normalize(height_label), 0)
        self.writer.add_images('Height Prediction', normalize(height_pred), 0)
        self.writer.add_images('Height Regularization', normalize(height_reg), 0)
        self.writer.add_images('Mask Traversed', weights_traversed, 0)
        self.writer.add_images('Mask Regularization', weights_reg, 0)

        return loss_sum

    def train(self, n_epochs=1):
        for e in range(n_epochs):
            print('Training epoch %i...' % e)
            train_loss = self.train_epoch(e)
            print('Validation epoch %i...' % e)
            with torch.no_grad():
                val_loss = self.val_epoch(e)

            # log losses on the same plot
            self.writer.add_scalars('Loss(epoch)', {'train': train_loss.item(), 'val': val_loss.item()}, e)

            if self.save:
                # save better model
                if self.min_val_loss > val_loss:
                    self.min_val_loss = val_loss
                    print('Saving better val model...')
                    for key in self.models.keys():
                        os.makedirs(self.weights_dir_path, exist_ok=True)
                        torch.save(self.models[key].state_dict(), os.path.join(self.weights_dir_path, '%s_val.pth' % key))

                if self.min_train_loss > train_loss:
                    self.min_train_loss = train_loss
                    print('Saving better train model...')
                    for key in self.models.keys():
                        os.makedirs(self.weights_dir_path, exist_ok=True)
                        torch.save(self.models[key].state_dict(), os.path.join(self.weights_dir_path, '%s_train.pth' % key))


def main():
    args = parse_args()

    data_paths = [
        '../data/robingas/data/22-08-12-cimicky_haj/marv/ugv_2022-08-12-16-37-03_trav/',
        '../data/robingas/data/22-09-27-unhost/husky/husky_2022-09-27-15-01-44_trav/',
        '../data/robingas/data/22-08-12-cimicky_haj/marv/ugv_2022-08-12-15-18-34_trav/',
    ]

    # create dataset for MonoLayout training
    datasets = []
    img_size = (args.img_size, args.img_size)
    train_paths = data_paths[:-1]
    val_path = data_paths[-1]
    print('Train paths:', train_paths)
    print('Val path:', val_path)
    for path in train_paths:
        assert os.path.exists(path)

        cfg = Config()
        cfg.from_yaml(os.path.join(path, 'terrain', 'train_log', 'cfg.yaml'))
        cfg.hm_interp_method = 'linear'

        # create dataset for MonoDEM training
        train_ds = MonoDemDataset(path, img_size=img_size, is_train=True, cfg=cfg)
        # print('Dataset size:', len(train_ds))

        if args.visualize:
            # visualize a data sample from the dataset
            for _ in range(1):
                i = np.random.choice(len(train_ds))
                train_ds.__getitem__(i, visualize=True)

        datasets.append(train_ds)
    train_ds = ConcatDataset(datasets)
    print('Training dataset size:', len(train_ds))

    # create validation dataset
    cfg_val = Config()
    cfg_val.from_yaml(os.path.join(val_path, 'terrain', 'train_log', 'cfg.yaml'))
    cfg_val.hm_interp_method = 'nearest'
    val_ds = MonoDemDataset(val_path, img_size=img_size, is_train=False, cfg=cfg_val)
    print('Validation dataset size:', len(val_ds))

    # pretrained weights paths for MonoDEM (encoder and decoder)
    pretrained_paths = {
        "encoder": "../config/weights/monolayout/encoder.pth",
        "decoder": "../config/weights/monolayout/decoder.pth",
    }

    # MonoDEM Training
    trainer = Trainer(train_ds, val_ds,
                      img_size=img_size,
                      batch_size=args.batch_size, lr=args.lr,
                      regularization=args.regularization, weighted_loss=args.weighted_loss,
                      pretrained_paths=pretrained_paths,
                      vis=args.visualize, save=args.save)
    trainer.train(n_epochs=args.n_epochs)


if __name__ == '__main__':
    main()
