#!/usr/bin/env python

import os
import numpy as np
import torch
from monoforce.datasets import RobinGasVis, robingas_tradr_seq_paths, robingas_husky_seq_paths
from monoforce.config import DPhysConfig
from monoforce.models import dphysics
from monoforce.models.lss.model import compile_model
from monoforce.models.lss.utils import denormalize_img
from monoforce.utils import read_yaml
from mayavi import mlab
from monoforce.vis import visualize_imgs


np.random.seed(0)
torch.manual_seed(0)

class MonoForce:
    def __init__(self, robot='tradr'):
        self.robot = robot  # 'husky' or 'tradr
        # choose data sample
        seqs = robingas_husky_seq_paths if self.robot == 'husky' else robingas_tradr_seq_paths
        seq_i = np.random.choice(range(len(seqs)))
        self.data_seq = seqs[seq_i]

        self.dphys_cfg = DPhysConfig()
        self.base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.dphys_config_path = os.path.join(self.base_path, 'config/dphys_cfg.yaml')
        assert os.path.isfile(self.dphys_config_path), 'Config file %s does not exist' % self.dphys_config_path
        self.dphys_cfg.from_yaml(self.dphys_config_path)

        # load LSS config
        self.lss_config_path = os.path.join(self.base_path, f'config/lss_cfg_{self.robot}.yaml')
        assert os.path.isfile(self.lss_config_path), 'LSS config file %s does not exist' % self.lss_config_path
        self.lss_config = read_yaml(self.lss_config_path)

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        if self.dphys_cfg.n_samples / self.dphys_cfg.total_sim_time != 100:
            raise 'Simulated time and number of predicted trajectory samples do not match the default rate of 100 Hz.'
        self.rate = self.dphys_cfg.n_samples / self.dphys_cfg.total_sim_time
        self.modelf = os.path.join(self.base_path, 'config/weights/lss/lss.pt')
        self.model = self.load_model()

    def load_model(self):
        model = compile_model(self.lss_config['grid_conf'], self.lss_config['data_aug_conf'], outC=1)
        print('Loading model from: %s' % self.modelf)
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.load_state_dict(torch.load(self.modelf, map_location=device))
        model.eval()
        return model

    def poses_from_states(self, states):
        xyz = states[0].cpu().numpy()
        Rs = states[1].cpu().numpy()
        poses = np.stack([np.eye(4) for _ in range(len(xyz))])
        poses[:, :3, :3] = Rs
        poses[:, :3, 3:4] = xyz
        poses[:, 2, 3] += self.dphys_cfg.robot_clearance + 0.1
        # poses inside the heightmap
        mask = (xyz[:, 0] > -self.dphys_cfg.d_max) & (xyz[:, 0] < self.dphys_cfg.d_max) & \
               (xyz[:, 1] > -self.dphys_cfg.d_max) & (xyz[:, 1] < self.dphys_cfg.d_max)
        mask = np.asarray(mask, dtype=bool).flatten()
        poses = poses[mask]
        return poses

    def predict_states(self, height, v, w):
        if isinstance(height, torch.Tensor):
            height = height.squeeze().cpu().numpy()
        # constant linear and angular velocities as control inputs
        tt = torch.linspace(0., self.dphys_cfg.total_sim_time, self.dphys_cfg.n_samples)
        vs = v * torch.ones(self.dphys_cfg.n_samples)
        ws = w * torch.ones(self.dphys_cfg.n_samples)
        controls = {'stamps': tt, 'linear_v': vs, 'angular_w': ws}
        states, system = dphysics(height, controls, dphys_cfg=self.dphys_cfg, device=self.device)
        return states, system.robot_points

    def run(self):
        ds = RobinGasVis(self.data_seq, dphys_cfg=self.dphys_cfg, lss_cfg=self.lss_config, is_train=False)
        print('Loaded dataset with %d samples from path: %s' % (len(ds), self.data_seq))
        sample_i = np.random.choice(range(len(ds)))
        print('Using sample %d' % sample_i)
        imgs, rots, trans, intrins, post_rots, post_trans = ds.get_images_data(sample_i)
        print('Loaded images with shapes: %s' % str([i.shape for i in imgs]))

        # draw images
        imgs_vis = [np.asarray(denormalize_img(img)) for img in imgs]
        visualize_imgs(imgs_vis)

        # get heightmap prediction
        with torch.no_grad():
            inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
            inputs = [torch.as_tensor(i[None]) for i in inputs]
            height_terrain_pred = self.model(*inputs)
            height = height_terrain_pred.squeeze().cpu().numpy()

            # predict path poses
            v = np.random.uniform(0.4, 0.8)
            if np.random.random() > 0.5:
                v = -v
            w = np.random.uniform(-0.2, 0.2)
            print('Predicting path with v=%.3f, w=%.3f' % (v, w))
            states, robot_points0 = self.predict_states(height, v=v, w=w)
            poses = self.poses_from_states(states)
            print('Predicted poses shape: %s' % str(poses.shape))
            forces = states[4].cpu().numpy()
            print('Predicted forces shape: %s' % str(forces.shape))
            robot_points0 = robot_points0.cpu().numpy()
            print('Robot contact points shape: %s' % str(robot_points0.shape))

        # visualize
        mlab.figure(bgcolor=(1, 1, 1), size=(800, 800))
        h, w = height.shape
        x_grid, y_grid = np.mgrid[-h//2:h//2, -w//2:w//2] * self.dphys_cfg.grid_res
        mlab.surf(x_grid, y_grid, height, colormap='terrain')
        mlab.plot3d(poses[:, 0, 3], poses[:, 1, 3], poses[:, 2, 3], color=(0, 0, 0), line_width=2.0)
        visu_robot = mlab.points3d(robot_points0[0, :], robot_points0[1, :], robot_points0[2, :],
                                   color=(0, 0, 1), scale_factor=0.2)
        visu_forces = mlab.quiver3d(robot_points0[0, :], robot_points0[1, :], robot_points0[2, :],
                                    forces[0, 0, :], forces[0, 1, :], forces[0, 2, :],
                                    line_width=4.0, scale_factor=0.005)
        for i in range(len(poses)):
            robot_points = poses[i, :3, :3] @ robot_points0 + poses[i, :3, 3:4]
            robot_points[2] -= ds.calib['clearance']
            visu_robot.mlab_source.set(x=robot_points[0, :], y=robot_points[1, :], z=robot_points[2, :])
            visu_forces.mlab_source.set(x=robot_points[0, :], y=robot_points[1, :], z=robot_points[2, :],
                                        u=forces[i, 0, :], v=forces[i, 1, :], w=forces[i, 2, :])
            mlab.view(azimuth=i / 2., elevation=60, distance=20)
            # mlab pause
            if i % 5 == 0:
                os.makedirs('./output', exist_ok=True)
                mlab.savefig(f'./output/pose_{i//5}.png')
        mlab.show()


def main():
    monoforce = MonoForce()
    monoforce.run()


if __name__ == '__main__':
    main()
