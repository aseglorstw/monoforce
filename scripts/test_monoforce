#!/usr/bin/env python

import os
import numpy as np
import torch
import matplotlib.pyplot as plt
from monoforce.datasets import MonoDemDataset
from monoforce.config import Config
from monoforce.models import monolayout
from monoforce.vis import set_axes_equal
from monoforce.segmentation import filter_grid, position
from monoforce.transformations import transform_cloud
from tqdm import tqdm


def demo():
    # path = '../data/robingas/data/22-08-12-cimicky_haj/marv/ugv_2022-08-12-15-18-34_trav/'
    # path = '../data/robingas/data/22-09-27-unhost/husky/husky_2022-09-27-15-01-44_trav/'
    path = '../data/robingas/data/22-08-12-cimicky_haj/marv/ugv_2022-08-12-16-37-03_trav/'
    sequence = path.split('/')[-2]
    img_size = (512, 512)
    assert os.path.exists(path)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    H, W = img_size
    models = {}
    # load encoder weights
    models["encoder"] = monolayout.Encoder(num_layers=18, img_ht=H, img_wt=W, pretrained=False)
    # encoder_path = '../config/weights/monolayout/encoder.pth'
    encoder_path = '../config/weights/monolayout/2023_09_20-15:31:11/encoder_train.pth'
    encoder_dict = torch.load(encoder_path, map_location=device)
    filtered_dict_enc = {k: v for k, v in encoder_dict.items() if k in models["encoder"].state_dict()}
    models["encoder"].load_state_dict(filtered_dict_enc)

    # load decoder weights
    # decoder_path = '../config/weights/monolayout/decoder.pth'
    decoder_path = '../config/weights/monolayout/2023_09_20-15:31:11/decoder_train.pth'
    models["decoder"] = monolayout.Decoder(models["encoder"].resnet_encoder.num_ch_enc)
    models["decoder"].load_state_dict(torch.load(decoder_path, map_location=device))

    cfg = Config()
    cfg.from_yaml(os.path.join(path, 'terrain', 'train_log', 'cfg.yaml'))

    camera = 'camera_fisheye_front' if 'marv' in path else 'camera_front'

    # create dataset for MonoDEM training
    ds = MonoDemDataset(path, cameras=[camera], img_size=img_size, cfg=cfg)
    fig = plt.figure(figsize=(20, 10))

    for i in tqdm(range(len(ds))):
        # print('Sample index: {}'.format(i))
        img, height_opt, height_est, mask_traversed, mask_reg = ds[i]
        cloud = ds.get_cloud(i)
        poses = ds.get_traj(i)['poses']

        # transform point cloud to robot frame
        Tr = np.linalg.inv(poses[0])
        cloud = transform_cloud(cloud, Tr)
        poses = np.asarray([np.matmul(Tr, pose) for pose in poses])

        # if robot went backwards, skip
        if np.any(poses[:, 0, 3] < -0.1):
            print('Robot went backwards, skipping sample')
            continue

        # grid filter
        cloud = filter_grid(cloud, cfg.grid_res)
        points = position(cloud)
        # filter point cloud in height map box range
        mask_x = np.logical_and(cloud['x'] > 0., cloud['x'] < cfg.d_max)
        mask_y = np.logical_and(cloud['y'] > -cfg.d_max / 2., cloud['y'] < cfg.d_max / 2.)
        mask_z = np.logical_and(cloud['z'] > 0., cloud['z'] < cfg.h_max)
        mask = np.logical_and(mask_x, mask_y)
        mask = np.logical_and(mask, mask_z)
        cloud_hm = cloud[mask]
        points_hm = points[mask]

        with torch.no_grad():
            # model inference
            img_tensor = torch.from_numpy(img).unsqueeze(0)
            features = models['encoder'](img_tensor)
            height_pred = models['decoder'](features, is_training=True)

        # visualize results
        plt.clf()
        img_vis = img.transpose((1, 2, 0)) * ds.img_std.reshape((1, 1, 3)) + ds.img_mean.reshape((1, 1, 3))
        plt.subplot(231)
        plt.imshow(img_vis[..., (2, 1, 0)])  # RGB
        plt.title('Input image')

        plt.subplot(232)
        plt.imshow(height_est.squeeze(), cmap='jet')
        plt.title('Height from lidar')
        plt.colorbar()

        plt.subplot(233)
        plt.imshow(height_pred.squeeze().cpu().numpy(), cmap='jet')
        plt.title('Height prediction')
        plt.colorbar()

        # visualize results in 3D
        x_grid = np.arange(0, cfg.d_max, cfg.grid_res)
        y_grid = np.arange(-cfg.d_max / 2., cfg.d_max / 2., cfg.grid_res)
        x_grid, y_grid = np.meshgrid(x_grid, y_grid)

        ax = fig.add_subplot(235, projection='3d')
        ax.set_title('Height from lidar')
        # plot estimated heightmap surface
        height_vis = height_est.squeeze()
        height_vis = np.fliplr(height_vis)
        height_vis = np.rot90(height_vis, k=1, axes=(1, 0))
        ax.plot_surface(x_grid, y_grid, height_vis, cmap='jet', alpha=0.7)
        # plot point cloud
        # ax.scatter(cloud['x'], cloud['y'], cloud['z'], s=0.2)
        # plot height map cloud
        ax.scatter(cloud_hm['x'], cloud_hm['y'], cloud_hm['z'], s=0.2, alpha=0.5)
        ax.set_xlabel('x')
        ax.set_ylabel('y')
        ax.set_zlabel('z')
        set_axes_equal(ax)
        # set up view point
        ax.view_init(elev=60, azim=180)

        ax = fig.add_subplot(236, projection='3d')
        ax.set_title('Height prediction')
        # plot predicted heightmap surface
        height_vis = height_pred.squeeze().cpu().numpy()
        height_vis = np.fliplr(height_vis)
        height_vis = np.rot90(height_vis, k=1, axes=(1, 0))
        ax.plot_surface(x_grid, y_grid, height_vis, cmap='jet', alpha=0.7)
        # # plot point cloud
        # ax.scatter(cloud['x'], cloud['y'], cloud['z'], s=0.2)
        # plot height map cloud
        ax.scatter(cloud_hm['x'], cloud_hm['y'], cloud_hm['z'], s=0.2, alpha=0.5)
        ax.set_xlabel('x')
        ax.set_ylabel('y')
        ax.set_zlabel('z')
        set_axes_equal(ax)
        # set up view point
        ax.view_init(elev=60, azim=180)

        plt.pause(0.01)
        plt.draw()

    plt.show()


def main():
    demo()


if __name__ == '__main__':
    main()
