#! /usr/bin/env python3
import os
import torch
from pytorch3d.loss import (
        chamfer_distance,
        mesh_edge_loss,
        mesh_laplacian_smoothing,
        mesh_normal_consistency,
    )
from pytorch3d.structures import Meshes, Pointclouds
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from monoforce.cloudproc import hm_to_cloud
from monoforce.datasets.data import DepthDEMDataVis, DepthDEMData, TravData, TravDataVis
from monoforce.datasets.data import seq_paths
from monoforce.config import Config
from monoforce.models.lss.tools import ego_to_cam, get_only_in_img_mask
from monoforce.transformations import transform_cloud
from monoforce.utils import read_yaml
from monoforce.models.lss.model import compile_model
import matplotlib as mpl
import open3d as o3d
# mpl.use('Qt5Agg')


torch.set_default_dtype(torch.float32)

def explore_data(path, grid_conf, data_aug_conf, cfg, is_train=False):
    assert os.path.exists(path)

    model = compile_model(grid_conf, data_aug_conf, outC=1)
    ds = DepthDEMDataVis(path, is_train=is_train, data_aug_conf=data_aug_conf, cfg=cfg)
    # ds = OmniDEMDataVis(path, is_train=is_train, data_aug_conf=data_aug_conf, cfg=cfg)

    H, W = data_aug_conf['H'], data_aug_conf['W']
    cams = data_aug_conf['cams']
    rat = H / W
    val = 10.1

    sample_range = [0]

    for sample_i in sample_range:
        fig = plt.figure(figsize=(val + val/3*2*rat*3, val/3*2*rat))
        gs = mpl.gridspec.GridSpec(2, 5, width_ratios=(1, 1, 1, 2 * rat, 2 * rat))
        gs.update(wspace=0.0, hspace=0.0, left=0.0, right=1.0, top=1.0, bottom=0.0)

        sample = ds[sample_i]
        sample = [s[np.newaxis] for s in sample]
        imgs, rots, trans, intrins, post_rots, post_trans, hm_lidar, pts = sample

        img_pts = model.get_geometry(rots, trans, intrins, post_rots, post_trans)

        for si in range(imgs.shape[0]):
            plt.clf()
            final_ax = plt.subplot(gs[:, 4:5])
            for imgi, img in enumerate(imgs[si]):
                ego_pts = ego_to_cam(pts[si], rots[si, imgi], trans[si, imgi], intrins[si, imgi])
                mask = get_only_in_img_mask(ego_pts, H, W)
                plot_pts = post_rots[si, imgi].matmul(ego_pts) + post_trans[si, imgi].unsqueeze(1)

                ax = plt.subplot(gs[imgi // 2, imgi % 2])
                showimg = img.permute((1, 2, 0))

                plt.imshow(showimg)
                plt.scatter(plot_pts[0, mask], plot_pts[1, mask], c=ego_pts[2, mask], s=2, alpha=0.9)
                plt.axis('off')
                # camera name as text on image
                plt.text(0.5, 0.9, cams[imgi].replace('_', ' '),
                         horizontalalignment='center', verticalalignment='top',
                         transform=ax.transAxes, fontsize=10)

                plt.sca(final_ax)
                plt.plot(img_pts[si, imgi, :, :, :, 0].view(-1), img_pts[si, imgi, :, :, :, 1].view(-1), '.',
                         label=cams[imgi].replace('_', ' '))

            plt.legend(loc='upper right')
            final_ax.set_aspect('equal')
            plt.xlim((-cfg.d_max, cfg.d_max))
            plt.ylim((-cfg.d_max, cfg.d_max))

            ax = plt.subplot(gs[:, 2:3])
            plt.imshow(hm_lidar[si][0].T, origin='lower', cmap='jet', vmin=-1., vmax=1.)
            plt.colorbar()

            # plot point cloud in 2D
            ax = plt.subplot(gs[:, 3:4])
            plt.scatter(pts[si][0, :], pts[si][1, :], s=1, c=pts[si][2, :], cmap='Greys', vmin=-1., vmax=1.)

            plt.show()

def feed_depth():
    path = '/home/ruslan/data/bags/husky_sim/depth/husky_simcity_2024-01-16-11-23-56_depth_trav/'
    # path = seq_paths[0]

    # lss model
    cfg = Config()
    cfg.from_yaml('../config/cfg.yaml')
    cfg.hm_interp_method = 'nearest'

    # load LSS config
    lss_config = read_yaml('../config/lss.yaml')
    grid_conf, data_aug_conf = lss_config['grid_conf'], lss_config['data_aug_conf']
    explore_data(path, grid_conf, data_aug_conf, cfg, is_train=False)

    ds = DepthDEMData(path, data_aug_conf, is_train=False, cfg=cfg)
    # ds = OmniDEMData(path, data_aug_conf, is_train=False, cfg=cfg)
    loader = torch.utils.data.DataLoader(ds, batch_size=4, shuffle=False)
    model = compile_model(grid_conf, data_aug_conf, outC=1)
    model.train()
    model.to(cfg.device)

    # imgs, rots, trans, intrins, post_rots, post_trans, height = ds[0]
    # inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
    # inputs = [s[np.newaxis] for s in inputs]
    # imgs, rots, trans, intrins, post_rots, post_trans = inputs

    # height = model(*inputs)
    # print(height.shape)

    # with torch.no_grad():
    #     img_pts = model.get_geometry(rots, trans, intrins, post_rots, post_trans)
    #     cam_feats = model.get_cam_feats(imgs)
    #     B, N, C, H, W = imgs.shape
    #     depth = model.camencode.get_depth_feat(imgs.view((B*N, C, H, W)))[0]
    #     print(img_pts.shape, cam_feats.shape, depth.shape)
    #     pts_vis = img_pts.reshape([-1, 3]).cpu().numpy()
    #     # colors = cam_feats.reshape([-1, 64]).cpu().numpy()[..., 0]
    #     colors = depth.reshape([-1]).cpu().numpy()
    #     show_cloud(pts_vis, colors)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    criterion = torch.nn.MSELoss()
    max_grad_norm = 5.0

    # train on a single example
    sample_i = np.random.randint(len(ds))
    imgs, rots, trans, intrins, post_rots, post_trans, hm = ds[sample_i]
    inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
    inputs = [s[np.newaxis] for s in inputs]
    inputs = [torch.as_tensor(i, device=cfg.device) for i in inputs]

    hm = torch.as_tensor(hm[np.newaxis], device=cfg.device)
    height_gt, mask = hm[:, 0:1], hm[:, 1:2]

    losses = []
    for i in range(101):
        height_pred = model(*inputs)
        loss = criterion(height_pred[mask.bool()], height_gt[mask.bool()])

        print(loss.item())
        losses.append(loss.item())

        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        optimizer.step()

        if i % 50 == 0:
            # plot the result
            plt.figure(figsize=(20, 5))
            plt.subplot(1, 4, 1)
            plt.title('Ground truth')
            plt.imshow(height_gt[0, 0].cpu().numpy(), cmap='jet', vmin=-1, vmax=1)
            plt.colorbar()

            plt.subplot(1, 4, 2)
            plt.title('Prediction')
            plt.imshow(height_pred[0, 0].detach().cpu().numpy(), cmap='jet', vmin=-1, vmax=1)
            plt.colorbar()

            plt.subplot(1, 4, 3)
            plt.title('Difference')
            plt.imshow((height_pred[0, 0] - height_gt[0, 0]).detach().cpu().numpy(), cmap='jet', vmin=-1, vmax=1)
            plt.colorbar()

            plt.subplot(1, 4, 4)
            plt.title('Loss')
            plt.plot(losses)
            plt.show()

    # # training loop
    # for imgs, rots, trans, intrins, post_rots, post_trans, hm in loader:
    #     inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
    #     inputs = [torch.as_tensor(i, device=cfg.device) for i in inputs]
    #     height_pred = model(*inputs)
    #
    #     hm = torch.as_tensor(hm, device=cfg.device)
    #     height_gt, mask = hm[:, 0:1], hm[:, 1:2]
    #     loss = criterion(height_pred[mask.bool()], height_gt[mask.bool()])
    #
    #     optimizer.zero_grad()
    #     loss.backward()
    #     torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
    #     optimizer.step()
    #
    #     print(loss.item())


def map_consistency():
    cfg = Config()
    cfg.from_yaml('../config/cfg.yaml')
    cfg.hm_interp_method = None
    cfg.device = 'cuda'

    predicted_map = True
    vis = True

    lss_cfg = read_yaml('../config/lss.yaml')
    data_aug_conf = lss_cfg['data_aug_conf']
    grid_conf = lss_cfg['grid_conf']

    ds = TravData(seq_paths[0], is_train=False, data_aug_conf=data_aug_conf, cfg=cfg)
    loader = torch.utils.data.DataLoader(ds, batch_size=6, shuffle=False)
    # ds.global_cloud(vis=True)
    # ds.global_hm_cloud(vis=True)

    model = compile_model(grid_conf, data_aug_conf, outC=1)
    modelf = '../config/weights/lss/train_lss.pt'
    model.load_state_dict(torch.load(modelf))
    model.eval()
    model.to(cfg.device)

    # create global heightmap
    for batch in tqdm(loader):
        with torch.no_grad():
            batch = [torch.as_tensor(b, dtype=torch.float32, device=cfg.device) for b in batch]
            imgs, rots, trans, intrins, post_rots, post_trans, hm_lidar, hm_traj, map_pose = batch

            if predicted_map:
                inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
                height_pred = model(*inputs)
                height = height_pred
                # mask = torch.ones_like(height)
                mask = hm_lidar[:, 1:2]
            else:
                height = hm_lidar[:, 0:1]
                mask = hm_lidar[:, 1:2]

            global_hm_clouds = []
            for p, h, m in zip(map_pose, height, mask):
                hm_cloud = hm_to_cloud(h.squeeze(), cfg, mask=m.squeeze())
                hm_cloud = transform_cloud(hm_cloud, p)
                global_hm_clouds.append(hm_cloud)

            # pytorch3d pointcloud
            src_cloud = Pointclouds(points=[torch.cat(global_hm_clouds[::2])])
            tgt_cloud = Pointclouds(points=[torch.cat(global_hm_clouds[1::2])])
            # chamfer distance
            chamfer_dist, _ = chamfer_distance(src_cloud, tgt_cloud)
            print('Chamfer distance:', chamfer_dist)

            if vis:
                global_hm_cloud = torch.cat(global_hm_clouds, dim=0)
                # plot global cloud with open3d
                hm_pcd = o3d.geometry.PointCloud()
                hm_pcd.points = o3d.utility.Vector3dVector(global_hm_cloud.cpu().numpy())
                o3d.visualization.draw_geometries([hm_pcd])


def main():
    # feed_depth()
    map_consistency()


if __name__ == '__main__':
    main()
