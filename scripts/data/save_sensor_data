#!/usr/bin/env python
"""Generate self-supervised data from ROS bag files with robot trajectories.
Assign traversability values to points travelled by a robot.

Paramaters:
- Simplified robot model from primitives (bounding boxes, spheres).
- Lookahead time / distance to mark traversed-through points.

Multi-pass processing:
1. Load transforms from bag files into a buffer. There have to be a transform
   from the fixed frame to the robot.
2. Process bags again and annotate points within given horizon contained in
   the model primitives.
"""
from __future__ import absolute_import, division, print_function
from argparse import ArgumentParser
import numpy as np
from numpy.lib.recfunctions import merge_arrays, unstructured_to_structured
import os
import csv
import cv2
from cv_bridge import CvBridge
from ros_numpy import msgify, numpify
from rosbag import Bag, Compression
import rospy
from sensor_msgs.msg import PointCloud2
from tf2_ros import BufferCore, TransformException
from monoforce.segmentation import affine, Body, Box, inverse  # needed for eval
from monoforce.cloudproc import position, valid_point_mask
from monoforce.ros import (load_tf_buffer,
                            get_cams_lidar_transformations,
                            get_camera_infos,
                            append_transformation, get_closest_msg, rgb_msg_to_cv2)
from monoforce.utils import slots
from monoforce.vis import show_cloud
from tqdm import tqdm


LABEL_FIELD_NAME = 'traversability'
LABEL_TRAVERSABLE = 1
LABEL_IGNORE = 255
MIN_VALID_LABELS = 0.0  # [%]
MIN_TRAVERSED_PTS = 0.0  # [%]
MIN_TRAJECTORY_LENGTH = 1.0


def str2bool(v):
    return v.lower() in ('1', 'yes', 'true', 't', 'y')


def arg_parser():
    parser = ArgumentParser(epilog="""Path format uses following placeholders:
    {dir} - parent directory of the first bag file,
    {name} - name without extension of the first bag file,
    {topic} - name of the topic as read from bag file,
    {secs}, {nsecs} - timestamp from the header (if available).
    """)
    parser.add_argument('--cloud-topics', type=str, nargs='+')
    parser.add_argument('--lidar-frame', type=str, default='os_sensor')
    parser.add_argument('--camera-topics', type=str, nargs='+')
    parser.add_argument('--camera-info-topics', type=str, nargs='+')
    parser.add_argument('--fixed-frame', type=str, default='map')
    parser.add_argument('--robot-frame', type=str, default='base_link')
    parser.add_argument('--exclude-times', type=str, default=None)
    parser.add_argument('--discard-empty', type=bool, default=True)
    parser.add_argument('--input-step', type=int, default=1)
    parser.add_argument('--input-start', type=float, default=-float('inf'), help='Start time in seconds.')
    parser.add_argument('--input-end', type=float, default=float('inf'), help='End time in seconds.')
    parser.add_argument('--discard-model', type=str, default=None,
                        help='Model at current position discarding points.')
    parser.add_argument('--robot-model', type=str, default=None,
                        help='Model to move along robot path marking points traversable.')
    parser.add_argument('--distance-horizon', '-d', type=float, default=10.0)
    parser.add_argument('--time-horizon', '-t', type=float, nargs=2, default=[0.0, 10.0])
    parser.add_argument('--time-step', '-s', type=float, default=0.5)
    parser.add_argument('--output-path', '-o', type=str, default='{dir}/{name}/clouds/{secs}_{nsecs:09d}.npz')
    parser.add_argument('--output-img-path', type=str, default='{dir}/{name}/images/{secs}_{nsecs:09d}_{camera}.png')
    parser.add_argument('--output-bag-path', '-O', type=str, default='{dir}/{name}_segmented.bag')
    parser.add_argument('--output-traj-path', type=str, default='{dir}/{name}/trajectories/{secs}_{nsecs:09d}.csv')
    parser.add_argument('--output-global-poses-path', type=str, default='{dir}/{name}/traj_poses.csv')
    parser.add_argument('--output-topic', type=str, default='{topic}_segmented')
    parser.add_argument('--output-period', type=float, default=None)
    parser.add_argument('--visualize', type=str2bool, default=False)
    parser.add_argument('--save-data', type=str2bool, default=True)
    parser.add_argument('--bag-paths', type=str, nargs='+')
    return parser


def get_topic_types(bag):
    return {k: v.msg_type for k, v in bag.get_type_and_topic_info().topics.items()}

def trajectory_length(poses):
    assert isinstance(poses, np.ndarray) or isinstance(poses, list)
    poses = np.asarray(poses)
    assert poses.ndim == 3
    N = len(poses)
    assert poses.shape == (N, 4, 4)
    xyz = poses[:, :3, 3]
    assert xyz.shape == (N, 3)
    return np.sum(np.linalg.norm(np.diff(xyz, axis=0), axis=1)).item()


def segment_cloud(robot_model, arr, input_to_robot_tfs, discard_tf=None, discard_model=None):
    assert robot_model is None or isinstance(robot_model, Body)
    assert isinstance(arr, np.ndarray)
    assert discard_model is None or isinstance(discard_model, Body)

    # Use only valid points for all operations.
    # Assign results to valid points in the end.
    valid = valid_point_mask(arr, discard_tf=discard_tf, discard_model=discard_model)
    arr_valid = arr[valid]
    valid_ind = np.flatnonzero(valid)
    x = position(arr_valid).reshape((-1, 3))
    x = x.T

    # Initialize all labels as unknown.
    labels = np.full(arr.shape, LABEL_IGNORE, dtype=float).ravel()

    # Mark valid points which are contained by future model poses as empty.
    traversable = np.zeros((x.shape[1],), dtype=bool)
    for input_to_robot_tf in input_to_robot_tfs:
        assert isinstance(input_to_robot_tf, np.ndarray)

        x_robot = affine(input_to_robot_tf, x)

        if robot_model:
            robot_points = robot_model.contains_point(x_robot)
            traversable = np.logical_or(traversable, robot_points)

    traversed_pts_ratio = traversable.mean()
    # print('Traversed points ratio: %.3f' % traversed_pts_ratio)

    if traversed_pts_ratio > 0:
        labels[valid_ind[traversable]] = LABEL_TRAVERSABLE

    labels = labels.reshape(arr.shape)
    return labels, traversed_pts_ratio


def get_clouds_and_trajs(bag_paths=None, cloud_topics=None, fixed_frame=None, robot_frame=None,
                         exclude_times=None, input_step=1, input_start=0.0, input_end=float('inf'),
                         discard_model=None, robot_model=None,
                         discard_empty=True, distance_horizon=None, time_horizon=None, time_step=None,
                         output_path=None, output_bag_path=None, output_traj_path=None, output_global_poses_path=None,
                         output_topic=None, output_period=None,
                         visualize=False, save_data=True, tf_buffer=None):
    assert bag_paths, bag_paths
    assert not exclude_times or all(len(t) == 2 for t in exclude_times), exclude_times
    assert len(time_horizon) == 2, time_horizon
    # TODO: Always look up t=0.
    assert 0.0 <= time_horizon[0] < time_horizon[1], time_horizon
    print('Time horizon:', time_horizon)

    dir = os.path.dirname(bag_paths[0])
    name, _ = os.path.splitext(os.path.basename(bag_paths[0]))
    fmt_kwargs = {'dir': dir, 'name': name}

    n = [int(np.floor(h / time_step)) for h in time_horizon]

    last_out = {}

    if output_bag_path:
        output_bag_path = output_bag_path.format(dir=dir, name=name)
        if output_bag_path in bag_paths:
            print('Output %s removed from input bag files.' % output_bag_path)
            del bag_paths[bag_paths.index(output_bag_path)]
        os.makedirs(os.path.dirname(output_bag_path), exist_ok=True)
        output_bag = Bag(output_bag_path, 'w')
    else:
        output_bag = None

    if tf_buffer is None:
        tf_buffer = load_tf_buffer(bag_paths)

    recorded_traj_poses_header = False

    cloud_stamps = []
    for bag_path in bag_paths:

        with Bag(bag_path, 'r') as bag:

            topic_types = get_topic_types(bag)
            i = -1
            for topic, msg, stamp in tqdm(bag.read_messages(topics=cloud_topics),
                                          desc='%s: generating data' % bag_path.split('/')[-1],
                                          total=bag.get_message_count(topic_filters=cloud_topics)):
                i += 1
                if i % input_step != 0:
                    continue
                if stamp.to_sec() < input_start or stamp.to_sec() > input_end:
                    print('Skipping %s at %.3f s (outside input interval).' % (topic, stamp.to_sec()))
                    continue
                if exclude_times and any(t[0] <= stamp.to_sec() <= t[1] for t in exclude_times):
                    print('Skipping %s at %.3f s (excluded).' % (topic, stamp.to_sec()))
                    continue
                # print('Processing %s at %.3f s.' % (topic, stamp.to_sec()))

                if hasattr(msg, 'header'):
                    secs, nsecs = msg.header.stamp.secs, msg.header.stamp.nsecs
                    start = msg.header.stamp.to_sec()
                else:
                    secs, nsecs = stamp.secs, stamp.nsecs
                    start = stamp.to_sec()
                fmt_kwargs['secs'], fmt_kwargs['nsecs'] = secs, nsecs

                if output_period and topic in last_out and start - last_out[topic] < output_period:
                    continue

                # Find transform from input cloud to fixed frame.
                try:
                    input_to_fixed = tf_buffer.lookup_transform_core(fixed_frame, msg.header.frame_id, msg.header.stamp)
                except TransformException as ex:
                    print('Could not transform from %s to %s at %.3f s.' %
                          (msg.header.frame_id, fixed_frame, msg.header.stamp.to_sec()))
                    continue
                input_to_fixed_tf = numpify(input_to_fixed.transform)

                # Find transforms from input cloud to robot positions within the horizon.
                input_to_robot_tfs = []
                stamps_within_horizon = np.linspace(start - n[0] * time_step, start + n[1] * time_step, sum(n) + 1)
                traj_stamps = []
                for t in stamps_within_horizon:
                    try:
                        tf = tf_buffer.lookup_transform_full_core(robot_frame, rospy.Time.from_seconds(t),
                                                                  msg.header.frame_id, msg.header.stamp,
                                                                  fixed_frame)
                    except TransformException as ex:
                        # print('Could not transform from %s to %s at %.3f s.' % (msg.header.frame_id, robot_frame, t))
                        continue
                    T = numpify(tf.transform)
                    if input_to_robot_tfs:
                        # Check distance horizon.
                        diff = np.matmul(input_to_robot_tfs[n[0]], inverse(T))
                        distance = np.linalg.norm(diff[:-1, -1])
                        if distance > distance_horizon:
                            print('Distance horizon reached, %.3f m > %.3f m.' % (distance, distance_horizon))
                            break
                    input_to_robot_tfs.append(T)
                    traj_stamps.append(t)

                if not input_to_robot_tfs:
                    continue

                if topic_types[topic] == 'sensor_msgs/PointCloud2':
                    msg = PointCloud2(*slots(msg))
                    input_struct = numpify(msg)
                    if input_struct.ndim == 2:
                        input_struct = input_struct.reshape((-1,))
                    # print('Input struct:', input_struct.shape)

                    # H x W unstructured label image.
                    label, traversed_pts_ratio = segment_cloud(robot_model, input_struct, input_to_robot_tfs,
                                                           discard_tf=input_to_robot_tfs[n[0]], discard_model=discard_model)
                    # H x W structured label cloud.
                    label_struct = label.reshape((input_struct.size, -1))
                    label_struct = unstructured_to_structured(label_struct, names=[LABEL_FIELD_NAME])

                    cloud_struct = merge_arrays([input_struct, label_struct], flatten=True)
                    cloud_struct = cloud_struct.reshape(input_struct.shape)
                    # print('Cloud struct:', cloud_struct.shape)
                    assert cloud_struct.shape == input_struct.shape

                    valid_labels_ratio = np.mean(label != LABEL_IGNORE)
                    if discard_empty and (valid_labels_ratio < MIN_VALID_LABELS):
                        print('Discarding cloud with not enough valid labels (%.2f < %.2f).'
                              % (valid_labels_ratio, MIN_VALID_LABELS))
                        continue

                    if traversed_pts_ratio < MIN_TRAVERSED_PTS:
                        print('Discarding cloud with not enough traversed points (%.2f < %.2f).'
                              % (traversed_pts_ratio, MIN_TRAVERSED_PTS))
                        continue

                    robot_to_input_tfs = [np.linalg.inv(T) for T in input_to_robot_tfs]
                    l = trajectory_length(robot_to_input_tfs)
                    if l < MIN_TRAJECTORY_LENGTH:
                        print('Discarding cloud with short trajectory length (%.2f < %.2f).' % (l, MIN_TRAJECTORY_LENGTH))
                        continue

                    last_out[topic] = start

                    traj_poses = robot_to_input_tfs

                    cloud_stamps.append(rospy.Time(fmt_kwargs['secs'], fmt_kwargs['nsecs']))

                    if visualize:
                        points = position(cloud_struct)
                        show_cloud(points, label)

                    if save_data:
                        # print('Storing cloud with %.2f valid labels and %.2f traversed points.' %
                        #       (valid_labels_ratio, traversed_pts_ratio))
                        # write np arrays
                        if output_path is not None:
                            p = output_path.format(**fmt_kwargs)
                            os.makedirs(os.path.dirname(p), exist_ok=True)
                            np.savez_compressed(p, cloud=cloud_struct)

                        # write segmented point cloud topic to a bag file
                        if output_bag is not None:
                            t = output_topic.format(topic=topic)
                            segmented_msg = msgify(PointCloud2, cloud_struct)
                            segmented_msg.header = msg.header
                            output_bag.write(t, segmented_msg, stamp)

                        # write robot traversed trajectory
                        if output_traj_path is not None:
                            p = output_traj_path.format(**fmt_kwargs)
                            os.makedirs(os.path.dirname(p), exist_ok=True)
                            # np.savez_compressed(p, traj=np.asarray(robot_to_input_tfs))
                            # save timestamps and transforms to a csv file
                            with open(p, 'w') as f:
                                writer = csv.writer(f)
                                writer.writerow(['stamp', 'T00', 'T01', 'T02', 'T03',
                                                 'T10', 'T11', 'T12', 'T13',
                                                 'T20', 'T21', 'T22', 'T23'])
                                for stamp, T in zip(traj_stamps, traj_poses):
                                    writer.writerow([stamp] + T[:3, :4].flatten().tolist())

                        # write cloud poses relative to fixed frame
                        if output_global_poses_path is not None:
                            p = output_global_poses_path.format(**fmt_kwargs)
                            os.makedirs(os.path.dirname(p), exist_ok=True)
                            if not recorded_traj_poses_header and os.path.exists(p):
                                # delete file if it exists (overwrite)
                                os.remove(p)
                            with open(p, 'a') as f:
                                writer = csv.writer(f)
                                # if file is empty, write header
                                if not recorded_traj_poses_header:
                                    writer.writerow(['stamp', 'T00', 'T01', 'T02', 'T03',
                                                     'T10', 'T11', 'T12', 'T13',
                                                     'T20', 'T21', 'T22', 'T23'])
                                    recorded_traj_poses_header = True
                                T = input_to_fixed_tf
                                writer.writerow([stamp] + T[:3, :4].flatten().tolist())

    if output_bag:
        output_bag.close()

    return sorted(cloud_stamps)


def save_images(bag_paths, img_topics, reference_stamps, output_img_path, time_step=1.0, save=True, log=False):
    for path in bag_paths:
        assert os.path.exists(path), 'Bag file does not exist: %s' % path
    for topic in img_topics:
        assert topic, 'Image topic is empty: %s' % topic
    for t in reference_stamps:
        assert isinstance(t, rospy.Time), 'Time stamp is not a rospy.Time: %s' % t
    assert output_img_path, 'Output image path is empty: %s' % output_img_path
    assert time_step > 0, 'Time period is not positive: %.3f' % time_step

    cv_bridge = CvBridge()
    dir = os.path.dirname(bag_paths[0])
    name, _ = os.path.splitext(os.path.basename(bag_paths[0]))

    img_stamps = {}
    for bag_path in bag_paths:
        with Bag(bag_path, 'r') as bag:
            # save images at cloud timestamps
            for rgb_topic in img_topics:
                camera = rgb_topic.split('/')[1]
                img_stamps[camera] = []
                for i in tqdm(range(len(reference_stamps)), desc='Saving images from topic "%s"' % rgb_topic):
                    # get the closest image at points time
                    msg, closest_stamp = get_closest_msg(bag=bag, topic=rgb_topic, time_moment=reference_stamps[i].to_sec(),
                                                         time_window=2*time_step, max_time_diff=time_step)
                    if msg is None:
                        print('No image found for topic "%s" at %.3f s.' % (rgb_topic, reference_stamps[i].to_sec()))
                        img_stamps[camera].append(None)
                        continue

                    img_stamps[camera].append(closest_stamp)
                    # convert msg to cv2 image
                    img_raw = rgb_msg_to_cv2(msg, cv_bridge)
                    if save:
                        if log:
                            print('Saving image from topic "%s" at %.3f s.' % (rgb_topic, reference_stamps[i].to_sec()))
                        # save images
                        path = output_img_path.format(dir=dir, name=name,
                                                      secs=reference_stamps[i].secs, nsecs=reference_stamps[i].nsecs,
                                                      camera=camera)
                        os.makedirs(os.path.dirname(path), exist_ok=True)
                        cv2.imwrite(path, img_raw)

    # make sure that all cameras have the same number of recorded timestamps
    assert all(len(img_stamps[camera]) == len(reference_stamps) for camera in img_stamps)

    return img_stamps


def save_timestamps(cloud_stamps, img_stamps, bag_paths):
    # save cloud and image timestamps in the following format: lidar_stamp, camera1_stamp, camera2_stamp, ...
    dir = os.path.dirname(bag_paths[0])
    name, _ = os.path.splitext(os.path.basename(bag_paths[0]))
    path = os.path.join(dir, name, 'timestamps.csv')
    with open(path, 'w') as f:
        cameras = list(img_stamps.keys())
        writer = csv.writer(f)
        writer.writerow(['lidar'] + cameras)
        for i in range(len(cloud_stamps)):
            cloud_time = cloud_stamps[i].to_sec()
            img_times = []
            for camera in cameras:
                img_time = img_stamps[camera][i]
                if img_time is not None:
                    img_times.append(img_time.to_sec())
                else:
                    img_times.append(None)
            row = [cloud_time] + img_times
            writer.writerow(row)


def process(bag_paths, cloud_topics, lidar_frame, camera_topics, camera_info_topics, fixed_frame, robot_frame,
            exclude_times, discard_empty, input_step, input_start, input_end, discard_model, robot_model,
            distance_horizon, time_horizon, time_step, output_path, output_img_path, output_bag_path, output_traj_path,
            output_global_poses_path, output_topic, output_period, visualize, save_data, **kwargs):
    for path in bag_paths:
        assert os.path.exists(path), 'Bag file does not exist: %s' % path

    print('Obtaining transforms from bag files...')
    tf_buffer = load_tf_buffer(bag_paths)
    print('Obtaining camera infos from bag file...')
    get_camera_infos(bag_paths, camera_info_topics, save=save_data)
    print('Obtaining lidar to cameras transformations from bag file...')
    get_cams_lidar_transformations(bag_paths, camera_topics, lidar_frame, tf_buffer, save=save_data)
    print(f'Obtaining {robot_frame} to base_footprint transformations from bag file...')
    append_transformation(bag_paths, source_frame=robot_frame, target_frame='base_footprint',
                          save=save_data, tf_buffer=tf_buffer)
    print(f'Obtaining {robot_frame} to {lidar_frame} transformations from bag file...')
    append_transformation(bag_paths, source_frame=robot_frame, target_frame=lidar_frame,
                          save=save_data, tf_buffer=tf_buffer,
                          matrix_name=f'T_{robot_frame}__os_sensor')
    print('Saving clouds and trajectories...')
    cloud_stamps = get_clouds_and_trajs(bag_paths=bag_paths, cloud_topics=cloud_topics, fixed_frame=fixed_frame, robot_frame=robot_frame,
                                        exclude_times=exclude_times, input_step=input_step, input_start=input_start, input_end=input_end,
                                        discard_model=discard_model, robot_model=robot_model, discard_empty=discard_empty,
                                        distance_horizon=distance_horizon, time_horizon=time_horizon, time_step=time_step,
                                        output_path=output_path, output_bag_path=output_bag_path, output_traj_path=output_traj_path,
                                        output_global_poses_path=output_global_poses_path, output_topic=output_topic, output_period=output_period,
                                        visualize=visualize, save_data=save_data, tf_buffer=tf_buffer)
    print('Saving images...')
    img_stamps = save_images(bag_paths, camera_topics, cloud_stamps, output_img_path, time_step=time_step, save=save_data)

    # save cloud and image timestamps in the following format: lidar_stamp, camera1_stamp, camera2_stamp, ...
    dir = os.path.dirname(bag_paths[0])
    name, _ = os.path.splitext(os.path.basename(bag_paths[0]))
    path = os.path.join(dir, name, 'timestamps.csv')
    with open(path, 'w') as f:
        cameras = img_stamps.keys()
        writer = csv.writer(f)
        writer.writerow(['lidar'] + cameras)
        for i in range(len(cloud_stamps)):
            row = [cloud_stamps[i].to_sec()] + [img_stamps[camera][i].to_sec() for camera in cameras]
            writer.writerow(row)

def main():
    args = arg_parser().parse_args()
    print(args)
    print('Processing %i bag files:' % len(args.bag_paths), *args.bag_paths, sep='\n')

    if args.exclude_times:
        args.exclude_times = eval(args.exclude_times)
        args.exclude_times = [[t - args.time_horizon[1], t + args.time_horizon[1]]
                              if isinstance(t, (float, int)) else t
                              for t in args.exclude_times]
        print('Excluding times:', *args.exclude_times, sep='\n')
    if args.discard_model:
        args.discard_model = eval(args.discard_model)
        print('Discard model:', args.discard_model)
    if args.robot_model:
        args.robot_model = eval(args.robot_model)
        print('Robot model:', args.robot_model)

    process(**vars(args))


if __name__ == '__main__':
    main()
